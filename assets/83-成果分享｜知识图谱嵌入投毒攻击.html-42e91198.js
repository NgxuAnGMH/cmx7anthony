import{_ as a}from"./plugin-vue_export-helper-c27b6911.js";import{r,o as i,c as s,a as e,b as t,e as o,d as p}from"./app-cdabc73c.js";const c="/assets/640-1689661702319-30-e100c543.png",_="/assets/640-1689661702319-31-89f9c754.png",d={},g=e("h1",{id:"_83-成果分享-mass-基于语义和隐蔽性约束的知识图谱嵌入投毒攻击",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_83-成果分享-mass-基于语义和隐蔽性约束的知识图谱嵌入投毒攻击","aria-hidden":"true"},"#"),t(" 83-成果分享｜MaSS: 基于语义和隐蔽性约束的知识图谱嵌入投毒攻击")],-1),h={href:"https://dl.acm.org/doi/abs/10.1145/3543507.3583203",target:"_blank",rel:"noopener noreferrer"},l=p('<p>在2023年5月举办的Proceedings of the ACM Web Conference 2023 (WWW 2023)中，我实验室白泽智能团队提出了基于语义和隐蔽性约束的知识图谱嵌入投毒攻击（MaSS: Model-agnostic, Semantic and Stealthy Data Poisoning Attack on Knowledge Graph Embedding），该研究揭示了基于开放式知识图谱的图谱嵌入的数据投毒攻击风险，通过<em>插入恶意事实</em>到开放知识图谱实现相应知识图谱嵌入的控制，同时该攻击方法能绕过现有的检测防御算法。</p><p>随着<em>图嵌入模型技术</em>的不断发展，其相关技术在近年来被越来越多地应用在知识图谱的数据挖掘场景中。例如，在问答系统中，图嵌入模型通过对海量知识图谱中数据的建模，可以有效地挖掘实体之间的潜在关联，从而帮助系统更好地推荐符合要求的答案。为了使得知识图谱的数据量满足图嵌入模型的学习需求，现有系统往往通过<em>公开的数据源</em>来扩充数据集，例如通过自动化爬取维基百科上的信息来构建大规模的知识图谱。然而，这样开放式的数据爬取机制也带来了<em>数据投毒攻击</em>的安全风险，即攻击者可以通过对公开的数据源（例如维基百科）进行篡改（比如插入带有恶意目标的知识，以下称为恶意事实），影响基于该公开数据源的知识图谱，从而进一步影响图嵌入模型的学习和基于相应知识图谱嵌入的下游机器学习模型（如图1所示）。</p><figure><img src="'+c+'" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>图（1）针对知识图谱图嵌入模型的数据投毒攻击示意图</p><p>文章从：</p><p>（1）黑盒假设：攻击者通常无法观测到图嵌入模型的参数甚至结构；</p><p>（2）语义约束：开放式数据库或者知识图谱通常会使用一些错误事实检测模型对异常信息做过滤，想要插入恶意信息需要绕过这些检测方法；</p><p>（3）攻击隐蔽性：当嵌入模型完成训练后，模型部署者会通过验证集来检验图嵌入模型的质量，当攻击者插入的错误事实影响嵌入的质量时比如在验证集上的预测准确度，就会被模型部署者意识到数据源被污染过或被丢弃；</p><p>三个知识图谱嵌入投毒攻击需要考虑的约束出发设计了攻击框架。</p><p>首先，针对<strong>黑盒假设</strong>，基于现有知识图谱嵌入模型可以有效地学习知识图谱的拓扑结构，文章设计了一种<em>基于逻辑推理事实链</em>插入的知识图谱数据投毒攻击框架。知识图谱嵌入模型在有效地学习拓扑结构的时候，就可以捕捉到插入的推理事实链包含的信息，从而得出指定的学习结果。</p><p>基于以上攻击框架，针对第二点，文章引入了知识图谱上实体和关系的先验信息，提出了一种<strong>语义约束</strong>下的推理事实链搜索方法。在知识图谱上，每种关系都可以被表示成已有关系组成的语义逻辑链；对于每个实体，根据其种类其可以相连接的关系是固定的。根据以上实体和关系的约束，使得搜索得到的逻辑链满足语义的同时帮助极大缩小搜索空间。</p><p>最后针对第三点，为了不影响知识图谱嵌入的正常性能，在黑盒攻击框架的基础上，提出了<strong>隐蔽性约束</strong>下的推理事实链排序方法。详细而言，在生成事实链的过程中要使得插入的恶意事实的不能是异常事实，否则将影响其他正常事实的学习。这要求攻击者插入的恶意事实对于嵌入模型的置信度要比较高，<em>接近于正常的事实</em>。为了能在学习嵌入之前获得该这些事实的置信度，文章引入预训练的知识图谱嵌入模型，根据这些模型对待插入逻辑链中的事实进行分别打分并计算总体置信度分数，从而确定最终插入的逻辑链。整体攻击框架如图（2）所示。</p><figure><img src="'+_+'" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>图（2）基于语义和隐蔽性约束的黑盒攻击框架</p><p>大量实验结果验证了提出的理论框架的有效性，黑盒攻击成功率相比于已有研究相对提升了约300%（在三个数据集和五种图嵌入模型上的平均结果）。同时，得益于提出的两种约束（语义性和隐蔽性），攻击所产生的错误事实不仅可以躲避潜在的异常检测算法，同时不会影响图嵌入模型的正常性能，比如在WN18RR数据集上，接近100%的错误事实都不会被异常检测算法检测出来，知识图谱嵌入模型在干净数据上的预测表现几乎没有下降。</p><p>团队介绍</p><p>白泽智能团队负责人为张谧教授，隶属于杨珉教授领衔的复旦大学系统软件与安全实验室的白泽智能团队。该团队主要研究方向为AI系统安全，包括AI供应链安全、数据隐私与模型保护、模型测试与优化、AI赋能安全等研究方向，在S&amp;P、USENIX Security、CCS、TPAMI、ICML、NeurIPS、KDD等网络安全和AI领域国际顶会顶刊已发表论文30余篇。</p>',17),m={href:"https://mi-zhang-fdu.github.io/index.chn.html",target:"_blank",rel:"noopener noreferrer"},f={href:"https://whitzard-ai.github.io/",target:"_blank",rel:"noopener noreferrer"};function u(b,S){const n=r("ExternalLinkIcon");return i(),s("div",null,[g,e("p",null,[e("a",h,[t("MaSS: Model-agnostic, Semantic and Stealthy Data Poisoning Attack on Knowledge Graph Embedding | Proceedings of the ACM Web Conference 2023"),o(n)]),t("。")]),l,e("p",null,[t("张谧教授个人主页："),e("a",m,[t("https://mi-zhang-fdu.github.io/index.chn.html"),o(n)])]),e("p",null,[t("白泽智能团队（Whizard AI）："),e("a",f,[t("https://whitzard-ai.github.io/"),o(n)])])])}const A=a(d,[["render",u],["__file","83-成果分享｜知识图谱嵌入投毒攻击.html.vue"]]);export{A as default};
