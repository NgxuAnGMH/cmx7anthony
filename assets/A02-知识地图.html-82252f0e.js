import{_ as n}from"./plugin-vue_export-helper-c27b6911.js";import{r as i,o as t,c as h,a as e,b as r,e as o,d}from"./app-cdabc73c.js";const c="/assets/12bc980053ea355a201e2b529048e2ff-737d49fe.jpg",s="/assets/v2-8e9b9e9bdfad7a57ce87fcf07ea69497_r-a8b6b47c.jpg",p={},l=d('<h1 id="_02-给你一张知识地图-计算机组成原理应该这么学" tabindex="-1"><a class="header-anchor" href="#_02-给你一张知识地图-计算机组成原理应该这么学" aria-hidden="true">#</a> 02 | 给你一张知识地图，计算机组成原理应该这么学</h1><p>了解了现代计算机的基本硬件组成和背后最基本的冯·诺依曼体系结构，我们就可以正式进入计算机组成原理的学习了。在学习一个一个零散的知识点之前，我整理了一份学习地图，好让你对将要学习的内容有一个总纲层面的了解。</p><figure><img src="'+c+'" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>从这张图可以看出来，<strong>整个计算机组成原理，就是围绕着计算机是如何组织运作展开的</strong>。</p><h2 id="计算机组成原理知识地图" tabindex="-1"><a class="header-anchor" href="#计算机组成原理知识地图" aria-hidden="true">#</a> <strong>计算机组成原理知识地图</strong></h2><p>计算机组成原理的英文叫 Computer Organization。这里的 Organization 是“<code>组织机构</code>”的意思。计算机由很多个不同的部件放在一起，变成了一个“组织机构”。这个组织机构最终能够进行各种计算、控制、读取输入，进行输出，达成各种强大的功能。</p><p>在这张图里面，我们把整个计算机组成原理的知识点拆分成了四大部分，分别是<mark>计算机的基本组成</mark>、<mark>计算机的指令和计算</mark>、<mark>CPU处理器设计</mark>，以及<mark>存储器和 I/O 设备</mark>。</p><h2 id="计算机的基本组成" tabindex="-1"><a class="header-anchor" href="#计算机的基本组成" aria-hidden="true">#</a> 计算机的基本组成</h2><p>首先，我们来看<strong>计算机的基本组成</strong>。</p><p>这一部分，你需要学习计算机是由哪些硬件组成的。</p><ul><li>这些硬件，又是怎么对应到经典的冯·诺依曼体系结构中的，<br> 也就是<code>运算器、控制器、存储器、输入设备和输出设备</code>这五大基本组件。</li><li>除此之外，你还需要了解<code>计算机的两个核心指标，性能和功耗</code>。<br> 性能和功耗也是我们在应用和设计五大基本组件中需要重点考虑的因素。</li></ul><h2 id="计算机的指令和计算" tabindex="-1"><a class="header-anchor" href="#计算机的指令和计算" aria-hidden="true">#</a> 计算机的指令和计算</h2><p>了解了组成部分，接下来你需要掌握<strong>计算机的指令和计算</strong>。</p><h3 id="指令部分" tabindex="-1"><a class="header-anchor" href="#指令部分" aria-hidden="true">#</a> 指令部分</h3><p>在计算机指令部分，你需要搞明白，我们每天撰写的一行行 C、Java、PHP 程序，是怎么在计算机里面跑起来的。</p><ul><li>这里面，你既需要了解我们的<em>程序是怎么通过编译器和汇编器，变成一条条机器指令这样的编译过程</em><br> （如果把编译过程展开的话，可以变成一门完整的<code>编译原理</code>课程），</li><li>还需要知道我们的操作系统是怎么<em>链接、装载、执行</em>这些程序的<br> （这部分知识如果再深入学习，又可以变成一门<code>操作系统</code>课程）。</li><li><em>而这一条条指令执行的控制过程</em>，就是由计算机五大组件之一的<strong>控制器</strong>来控制的。</li></ul><h3 id="计算部分" tabindex="-1"><a class="header-anchor" href="#计算部分" aria-hidden="true">#</a> 计算部分</h3><p>在计算机的计算部分，你要从二进制和编码开始，理解我们的数据在计算机里的表示，以及我们是怎么从数字电路层面，实现加法、乘法这些基本的运算功能的。实现这些运算功能的 ALU（Arithmetic Logic Unit/ALU），也就是算术逻辑单元，其实就是我们计算机五大组件之一的<strong>运算器</strong>。</p><p>这里面有一个在今天看起来特别重要的知识点，就是<em>浮点数（Floating Point）</em>。浮点数是我们在日常运用中非常容易用错的一种数据表示形式。<em>掌握浮点数能让你对数据的编码、存储和计算能够有一个从表到里的深入理解</em>。尤其在 AI 火热的今天，浮点数是机器学习中重度使用的数据表示形式，掌握它更是非常有必要。</p><h2 id="cpu处理器设计" tabindex="-1"><a class="header-anchor" href="#cpu处理器设计" aria-hidden="true">#</a> CPU处理器设计</h2><p>明白计算机指令和计算是如何运转的，我们就可以深入到 <strong>CPU 的设计</strong>中去一探究竟了。</p><h3 id="cpu时钟" tabindex="-1"><a class="header-anchor" href="#cpu时钟" aria-hidden="true">#</a> CPU时钟</h3><p>CPU 时钟可以用来构造寄存器和内存的锁存器和触发器，因此，CPU 时钟应该是我们学习 CPU 的前导知识。搞明白我们为什么需要 <em>CPU 时钟（CPU Clock）</em>，以及寄存器和内存是用什么样的硬件组成的之后，我们可以再来看看，整个计算机的数据通路是如何构造出来的。</p><h3 id="数据通路" tabindex="-1"><a class="header-anchor" href="#数据通路" aria-hidden="true">#</a> 数据通路</h3><p><em>数据通路</em>，其实就是连接了整个运算器和控制器，并最终组成了 CPU。</p><h3 id="面向流水线设计" tabindex="-1"><a class="header-anchor" href="#面向流水线设计" aria-hidden="true">#</a> 面向流水线设计</h3><p>而出于对于性能和功耗的考虑，你要进一步理解和掌握<em>面向流水线设计的</em> CPU、数据和控制冒险，以及分支预测的相关技术。</p><h3 id="异常和中断" tabindex="-1"><a class="header-anchor" href="#异常和中断" aria-hidden="true">#</a> 异常和中断</h3><p>既然 CPU 作为控制器要和输入输出设备通信，那么我们就要知道<em>异常和中断发生的机制</em>。</p><h3 id="指令并行" tabindex="-1"><a class="header-anchor" href="#指令并行" aria-hidden="true">#</a> 指令并行</h3><p>在 CPU 设计部分的最后，我会讲一讲<em>指令的并行执行</em>，看看如何直接在 CPU 层面，通过 SIMD 来支持并行计算。</p><h2 id="存储器-io设备" tabindex="-1"><a class="header-anchor" href="#存储器-io设备" aria-hidden="true">#</a> 存储器 &amp; IO设备</h2><p>最后，我们需要看一看，计算机五大组成部分之一，<strong>存储器的原理</strong>。通过存储器的层次结构作为基础的框架引导，你需要掌握从上到下的 <code>CPU 高速缓存、内存、SSD 硬盘和机械硬盘</code>的工作原理，<em>它们之间的性能差异</em>，以及实际应用中利用这些设备会遇到的挑战。</p><p>存储器其实很多时候又扮演了输入输出设备的角色，所以你需要进一步了解，</p><ol><li>CPU 和这些存储器之间是如何进行通信的，</li><li>以及我们最重视的性能问题是怎么一回事；</li><li>理解什么是 IO_WAIT，</li><li>如何通过 DMA 来提升程序性能。</li></ol><p>对于存储器，我们不仅需要它们能够正常工作，还要确保里面的数据不能丢失。于是你要掌握我们是如何通过 <code>RAID、Erasure Code、ECC 以及分布式 HDFS</code>，这些不同的技术，<em>来确保数据的完整性和访问性能</em>。</p><h2 id="学习计算机组成原理-究竟有没有好办法" tabindex="-1"><a class="header-anchor" href="#学习计算机组成原理-究竟有没有好办法" aria-hidden="true">#</a> <strong>学习计算机组成原理，究竟有没有好办法？</strong></h2><p>相信这个学习地图，应该让你对计算机组成这门课要学些什么，有了一些了解。不过这个地图上的知识点繁多，应该也给你带来了不小的挑战。</p><p>我上一节也说过，相较于整个计算机科学中的其他科目，<em>计算机组成原理更像是整个计算机学科里的“纲要”</em>。这门课里任何一个知识点深入挖下去，都可以变成计算机科学里的一门核心课程。比如说，</p><ol><li>程序怎样从高级代码变成指令在计算机里面运行，对应着“<code>编译原理</code>”和“<code>操作系统</code>”这两门课程；</li><li>计算实现背后则是“<code>数字电路</code>”；</li><li>如果要深入 CPU 和存储器系统的优化，必然要深入了解“<code>计算机体系结构</code>”。</li></ol><p>因此，为了帮你更快更好地学计算机组成，我为你总结了三个学习方法，帮你更好地掌握这些知识点，并且能够学为所用，让你在工作中能够用得上。</p><h3 id="学会提问自己来串联知识点" tabindex="-1"><a class="header-anchor" href="#学会提问自己来串联知识点" aria-hidden="true">#</a> 学会提问自己来串联知识点</h3><p>首先，<strong>学会提问自己来串联知识点</strong>。学完一个知识点之后，你可以从下面两个方面，问一下自己。</p><ol><li>我写的程序，是怎样从输入的代码，变成运行的程序，并得到最终结果的？</li><li>整个过程中，计算器层面到底经历了哪些步骤，有哪些地方是可以优化的？</li></ol><p>无论是程序的编译、链接、装载和执行，以及计算时需要用到的逻辑电路、ALU，乃至 CPU 自发为你做的流水线、指令级并行和分支预测，还有对应访问到的硬盘、内存，以及加载到高速缓存中的数据，这些都对应着我们学习中的一个个知识点。<em>建议你自己脑子里过一遍，最好是口头表述一遍或者写下来</em>，这样对你彻底掌握这些知识点都会非常有帮助。</p><h3 id="写一些示例程序来验证知识点" tabindex="-1"><a class="header-anchor" href="#写一些示例程序来验证知识点" aria-hidden="true">#</a> 写一些示例程序来验证知识点</h3><p>其次，**写一些示例程序来验证知识点。**计算机科学是一门实践的学科。计算机组成中的大量原理和设计，都对应着“性能”这个词。因此，通过把对应的知识点，变成一个个性能对比的示例代码程序记录下来，是把这些知识点融汇贯通的好方法。因为，相比于强记硬背知识点，<em>一个有着明确性能对比的示例程序</em>，会在你脑海里留下更深刻的印象。当你想要回顾这些知识点的时候，一个程序也更容易提示你把它从脑海深处里面找出来。</p><h3 id="通过和计算机硬件发展的历史做对照" tabindex="-1"><a class="header-anchor" href="#通过和计算机硬件发展的历史做对照" aria-hidden="true">#</a> 通过和计算机硬件发展的历史做对照</h3><p>最后，<strong>通过和计算机硬件发展的历史做对照</strong>。计算机的发展并不是一蹴而就的。从第一台电子计算机 ENIAC（Electronic Numerical Integrator And Computer，电子数值积分计算机）的发明到现在，已经有 70 多年了。现代计算机用的各个技术，都是跟随实际应用中遇到的挑战，一个个发明、打磨，最后保留下来的。这当中不仅仅有学术层面的碰撞，更有大量商业层面的交锋。<em>通过了解充满戏剧性和故事性的计算机硬件发展史</em>，让你更容易理解计算机组成中各种原理的由来。</p><p>比如说，奔腾 4 和 SPARC 的失败，以及 ARM 的成功，能让我们记住 <code>CPU 指令集的繁与简、权衡性能和功耗的重要性</code>，而现今高速发展的机器学习和边缘计算，又给计算机硬件设计带来了新的挑战。</p><h2 id="给松鼠症患者的学习资料" tabindex="-1"><a class="header-anchor" href="#给松鼠症患者的学习资料" aria-hidden="true">#</a> <strong>给松鼠症患者的学习资料</strong></h2><p>学习总是要花点笨功夫的。最有效的办法还是“读书百遍，其义自见”。对于不够明白的知识点，多搜索，多看不同来源的资料，多和朋友、同事、老师一起交流，一定能够帮你掌握好想要学习的知识点。</p><p>在这个专栏之前，计算机组成原理，已经有很多优秀的图书和课程珠玉在前了。为了覆盖更多知识点的细节，这些书通常都有点厚，课程都会有点长。不过作为专栏的补充阅读材料，却是最合适不过了。</p><p>因此，每一讲里，我都会留下一些“<strong>补充阅读</strong>”的材料。如果你想更进一步理解更多深入的计算机组成原理的知识，乃至更多相关的其他核心课程的知识，多用一些业余时间来看一看，读一读这些“补充阅读”也一定不会让你对花在上面的时间后悔的。</p><p>下面给你推荐一些我自己看过、读过的内容。我在之后的文章里推荐的“补充阅读”，大部分都是来自这些资料。你可以根据自己的情况来选择学习。</p><h3 id="入门书籍" tabindex="-1"><a class="header-anchor" href="#入门书籍" aria-hidden="true">#</a> <strong>入门书籍</strong></h3><p>我知道，订阅这个专栏的同学，有很多是非计算机科班出身，我建议你先对计算机组成原理这门课有个基本概念。建立这个概念，有两种方法，第一，你可以把我上面那张地图的核心内容记下来，对这些内容之间的关系先有个大致的了解。</p><p>第二，我推荐你阅读两本书，准确地说，这其实是两本小册子，因为它们<em>非常轻薄、好读，而且图文并茂</em>，非常适合初学者和想要入门组成原理的同学。一本是《<code>计算机是怎样跑起来的</code>》，另一本是《<code>程序是怎样跑起来的</code>》。我要特别说一下后面这本，它可以说是一个入门微缩版本的“计算机组成原理”。</p><p>除此之外，计算机组成中，<em>硬件层面的基础实现</em>，比如寄存器、ALU 这些电路是怎么回事，你可以去看一看 Coursera 上的北京大学免费公开课《<code>Computer Organization</code>》。这个视频课程的视频部分也就 10 多个小时。在学习专栏相应章节的前后去浏览一遍，相信对你了解<em>程序在电路层面</em>会变成什么样子有所帮助。</p><h3 id="深入学习书籍" tabindex="-1"><a class="header-anchor" href="#深入学习书籍" aria-hidden="true">#</a> <strong>深入学习书籍</strong></h3><p>对于想要深入掌握计算机组成的同学，我推荐你去读一读《<code>计算机组成与设计：硬件 / 软件接口</code>》和经典的《<code>深入理解计算机系统</code>》这两本书。后面这本被称为 CSAPP 的经典教材，网上也有配套的视频课程。我在这里给你推荐两个不同版本的链接（<em>Bilibili 版</em>和<em>Youtube 版</em> ）。不过这两本都在 500 页以上，坚持啃下来需要不少实践经验。</p><blockquote><p>南京大学袁春风老师的《计算机系统基础》一书也很不错，主干内容和csapp一脉相承，在中国大学mooc上也有公开课，不喜欢翻译版的同学可以学习这个本土教程，和老师讲的内容也非常贴切。</p></blockquote><p>计算机组成原理还有一本的经典教材，就是来自操作系统大神塔能鲍姆（Andrew S. Tanenbaum）的《<code>计算机组成：结构化方法</code>》。这本书的组织结构和其他教材都不太一样，<em>适合作为一个辅助的参考书来使用</em>。</p><p>如果在学习这个专栏的过程中，引发了你对于计算机体系结构的兴趣，你还可以深入读一读《<code>计算机体系结构：量化研究方法</code>》。</p><h3 id="课外阅读" tabindex="-1"><a class="header-anchor" href="#课外阅读" aria-hidden="true">#</a> <strong>课外阅读</strong></h3><p>在上面这些教材之外，对于资深程序员来说，来自 Redhat 的 <strong>What Every Programmer Should Know About Memory</strong> 是写出高性能程序不可不读的经典材料。而 LMAX 开源的 Disruptor，则是通过实际应用程序，来理解计算机组成原理中各个知识点的最好范例了。</p><p>《<code>编码：隐匿在计算机软硬件背后的语言</code>》和《<code>程序员的自我修养：链接、装载和库</code>》是理解计算机硬件和操作系统层面代码执行的优秀阅读材料。</p>',67),m={href:"https://www.zhihu.com/question/467281352/answer/1967082273",target:"_blank",rel:"noopener noreferrer"},g=e("figure",null,[e("img",{src:s,alt:"img",tabindex:"0",loading:"lazy"}),e("figcaption",null,"img")],-1),u=e("p",null,"鹏城实验室",-1),b={href:"https://www.zhihu.com/question/409298856",target:"_blank",rel:"noopener noreferrer"},f=d('<h2 id="总结延伸" tabindex="-1"><a class="header-anchor" href="#总结延伸" aria-hidden="true">#</a> <strong>总结延伸</strong></h2><p>学习不是死记硬背，学习材料也不是越多越好。到了这里，<em>希望你不要因为我给出了太多可以学习的材料，结果成了“松鼠症”患者，<code>光囤积材料，却没有花足够多的时间去学习这些知识</code></em>。</p><p>我工作之后一直在持续学习，在这个过程中，我发现最有效的办法，<strong>不是短时间冲刺，而是有节奏地坚持，希望你能够和专栏的发布节奏同步推进，做好思考题，并且多在留言区和其他朋友一起交流</strong>，就更容易能够“<code>积小步而至千里</code>”，在程序员这个职业上有更长足的发展。</p><p>好了，对于学习资料的介绍就到这里了。希望在接下来的几个月里，你能和我一起走完这趟“计算机组成”之旅，从中收获到知识和成长。</p><h2 id="课后思考" tabindex="-1"><a class="header-anchor" href="#课后思考" aria-hidden="true">#</a> <strong>课后思考</strong></h2><p>今天我为你梳理计算机组成的知识地图，也讲了我认为学习这个专栏的一些方法，听了这么多，那么你打算怎么学习这个专栏呢？</p><p>欢迎你在留言区写下你的学习目标和学习计划，和大家一起交流，也欢迎你把今天的文章分享给你的朋友，互相督促，共同成长。</p><blockquote><p>徐老师好，请教一个困扰自己很久的问题：线程切换是如何触发的，就是这个触发时间点是怎么产生的(也即触发线程调度的时间点)，是通过中断么？如果是中断，那么这个中断又是怎么发生的？<br> 作者回复: 杨怀同学你好，这个问题还真是一两句话讲不清楚。线程切换更多是 操作系统 层面实现的问题。我推荐你可以去看 刘超 老师在极客时间的专栏《趣谈Linux操作系统》。我这里简单讲一下，线程切换不是由中断触发的，而是由操作系统控制在用户态触发进行切换的。切换并没有确定的时间。<br><em>而我们在组成原理里面说的中断</em>，一般指的是硬件的中断，是硬件设备会向我们的CPU发出信号，这个是直接通过硬件电路层面来触发。就好像一个电路引脚的信号从高电平变成了低电平，导致CPU收到的电信号就发生了变化，通常是改变了特定寄存器里面的值（中断寄存器），再触发一系列的处理逻辑。</p><hr><p>非科班出身，做 Java 也有三四年了。期间也看不少的源码，基本上是看了就忘，主要还是理论知识储备不够，不管是什么代码，背后都有一套理论在支持。有时候看了好久都搞不明白为什么要这么实现，<em>但突然有一天你发现前人的理论其实总结的已经非常到位，代码只不过实现而已，这时候会突然有也不过如此的感觉</em>。<strong>比如之前读 AQS，觉得好复杂，<code>后来了解了信号量和管程</code>，才明白 AQS 不过是管程在 Java 中的应用，synchronized 同样如此，<code>以前以为自己好像看懂了</code>，但其实并没有</strong>。<br> 对于这门课程，我可能和大家不太一样，目前不太会深入学习，毕竟和上层的应用还是比较远。<strong>我的目标主要是建立一个完整的体系，主要会侧重<code>存储与IO系统</code>这部分学习</strong>。因为指令怎么运行、CPU怎么运行，我不太关心，但存储和IO系统却<em>开发中常常遇到的问题</em>。比如高速缓存带来的可见性问题，指令重排带来的有序性问题，<em>这些都是并发编程的根源</em>。还比如磁盘顺序读写要比随机读写快得多，这是 Kafka 为什么这么快的原因之一。</p><hr><p>我打算先把两个薄小册子看下 跟着把这个课学完 2遍以上<br> 作者回复: “<code>宰相必起于州部，猛将必发于卒伍</code>”，从易到难，好好学习。</p></blockquote>',8);function _(C,x){const a=i("ExternalLinkIcon");return t(),h("div",null,[l,e("blockquote",null,[e("p",null,[e("a",m,[r("能否客观地比较龙芯处理器和香山 RISC-V 处理器，各有哪些优势？ - 知乎 (zhihu.com)"),o(a)])]),g,u,e("p",null,[e("a",b,[r("如何评价中国科学院大学「一生一芯」计划？对国产芯片的发展意味着什么？ - 知乎 (zhihu.com)"),o(a)])])]),f])}const k=n(p,[["render",_],["__file","A02-知识地图.html.vue"]]);export{k as default};
