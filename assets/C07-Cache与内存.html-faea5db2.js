import{_ as o}from"./plugin-vue_export-helper-c27b6911.js";import{r as t,o as p,c as r,a,b as e,e as n,d as c}from"./app-cdabc73c.js";const i="/assets/0d0d85383416f2f8841aeebe7021a88e-1d66839d.jpg",d="/assets/1b41056cce55b17a2366d7b9dd922aed-b78a8063.jpg",l="/assets/474189597993406a01a2ae171b754756-182b36f1.jpg",h="/assets/976f5cf91bc656e2a876235a5d2efabd-5d1d451e.jpg",C="/assets/b19d638e9a37290c1ea1feebce2d7e61-81ce9ddb.jpg",u="/assets/bb1fc473f93089a1414a4e01f888dae2-f58e177f.jpg",m="/assets/030bd3e97c93bdef900abc0c6a72b9b0-f41e673a.jpg",b="/assets/d43c10bbb1a1159d9da7d3b14a3cfyy0-ec300d40.jpg",k={},g=c(`<h1 id="_07-cache与内存-程序放在哪儿" tabindex="-1"><a class="header-anchor" href="#_07-cache与内存-程序放在哪儿" aria-hidden="true">#</a> 07 | Cache与内存：程序放在哪儿？</h1><p>你好，我是 LMOS。</p><p>在前面的课程里，我们已经知道了 CPU 是如何执行程序的，也研究了程序的地址空间，这里我们终于到了程序的存放地点——内存。</p><p>你知道什么是 Cache 吗？在你心中，真实的内存又是什么样子呢？今天我们就来重新认识一下 Cache 和内存，这对我们利用 Cache 写出高性能的程序代码和实现操作系统管理内存，有着巨大的帮助。</p><p>通过这节课的内容，我们一起来看看内存到底是啥，它有什么特性。有了这个认识，你就能更加深入地理解我们看似熟悉的局部性原理，从而搞清楚，为啥 Cache 是解决内存瓶颈的神来之笔。最后，我还会带你分析 x86 平台上的 Cache，规避 Cache 引发的一致性问题，并让你掌握获取内存视图的方法。</p><p>那话不多说，带着刚才的问题，我们正式进入今天的学习吧！</p><h2 id="从一段-经典-代码看局部性原理" tabindex="-1"><a class="header-anchor" href="#从一段-经典-代码看局部性原理" aria-hidden="true">#</a> 从一段“经典”代码看局部性原理</h2><p>不知道，你还记不记得 C 语言打印九九乘法表的代码，想不起来也没关系，下面我把它贴出来，代码很短，也很简单，就算你自己写一个也用不了一分钟，如下所示。</p><div class="language-c line-numbers-mode" data-ext="c"><pre class="language-c"><code><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;stdio.h&gt;</span></span>
<span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
    <span class="token keyword">int</span> i<span class="token punctuation">,</span>j<span class="token punctuation">;</span>
    <span class="token keyword">for</span><span class="token punctuation">(</span>i<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">;</span>i<span class="token operator">&lt;=</span><span class="token number">9</span><span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        
        <span class="token keyword">for</span><span class="token punctuation">(</span>j<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">;</span>j<span class="token operator">&lt;=</span>i<span class="token punctuation">;</span>j<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
            <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">&quot;%d*%d=%2d  &quot;</span><span class="token punctuation">,</span>i<span class="token punctuation">,</span>j<span class="token punctuation">,</span>i<span class="token operator">*</span>j<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">&quot;\\n&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>我们当然不是为了研究代码本身，这个代码非常简单，这里我们主要是观察这个结构，代码的结构主要是<strong>顺序、分支、循环</strong>，这三种结构可以写出现存所有算法的程序。</p><p>我们常规情况下写的代码是顺序和循环结构居多。上面的代码中有两重循环，内层循环的次数受到外层循环变量的影响。就是这么简单，但是越简单的东西越容易看到本质。</p><p>可以看到，这个代码大数时间在执行一个乘法计算和调用一个 printf 函数，而程序一旦编译装载进内存中，它的地址就确定了。也就是说，CPU 大多数时间在访问相同或者与此相邻的地址，换句话说就是：<strong>CPU 大多数时间在执行相同的指令或者与此相邻的指令</strong>。这就是大名鼎鼎的<strong>程序局部性原理</strong>。</p><h2 id="内存" tabindex="-1"><a class="header-anchor" href="#内存" aria-hidden="true">#</a> 内存</h2><p>明白了程序的局部性原理之后，我们再来看看内存。你或许感觉这跨越有点大，但是只有明白了内存的结构和特性，你才能明白程序局部性原理的应用场景和它的重要性。</p><p>内存也可称为主存，不管硬盘多大、里面存放了多少程序和数据，只要程序运行或者数据要进行计算处理，就必须先将它们装入内存。我们先来看看内存长什么样（你也可以上网自行搜索），如下图所示。</p><img src="`+i+'" alt="img" style="zoom:10%;"><p>从上图可以看到在 PCB 板上有内存颗粒芯片，主要是用来存放数据的。SPD 芯片用于存放内存自身的容量、频率、厂商等信息。还有最显眼的金手指，用于连接数据总线和地址总线，电源等。</p><p>其实从专业角度讲，内存应该叫 <strong>DRAM</strong>，即<mark>动态随机存储器</mark>。内存储存颗粒芯片中的存储单元是由电容和相关元件做成的，电容存储电荷的多、少代表数字信号 0 和 1。</p><p>而随着时间的流逝，电容存在漏电现象，这导致电荷不足，就会让存储单元的数据出错，所以 DRAM 需要周期性刷新，以保持电荷状态。DRAM 结构较简单且集成度很高，通常用于制造内存条中的储存颗粒芯片。</p><p>虽然内存技术标准不断更新，但是储存颗粒的内部结构没有本质改变，还是电容存放电荷，标准看似更多，实际上只是提升了位宽、工作频率，以及传输时预取的数据位数。</p><p><strong>比如 DDR SDRAM，即双倍速率同步动态随机存储器</strong>，它使用 2.5V 的工作电压，数据位宽为 64 位，核心频率最高为 166MHz。下面简称 <mark>DDR 内存</mark>，它表示每一个时钟脉冲传输两次数据，分别在时钟脉冲的上升沿和下降沿各传输一次数据，因此称为双倍速率的 SDRAM。</p><p>后来的 DDR2、DDR3、DDR4 也都在核心频率和预取位数上做了提升。最新的 DDR4 采用 1.2V 工作电压，数据位宽为 64 位，预取 16 位数据。DDR4 取消了双通道机制，一条内存即为一条通道，工作频率最高可达 4266MHz，单根 DDR4 内存的数据传输带宽最高为 34GB/s。</p><p>其实我们无需过多关注内存硬件层面的技术规格标准，重点需要关注的是，<strong><code>内存的速度</code>还有<code>逻辑上</code>内存和系统的连接方式和结构</strong>，这样你就能意识到内存有多慢，还有是什么原因导致内存慢的。</p><p>我们还是画幅图说明吧，如下图所示。</p><img src="'+d+'" alt="img" style="zoom:15%;"><p>DDR内存逻辑结构连接图</p><p>结合图片我们看到，控制内存刷新和内存读写的是<mark>内存控制器</mark>，而内存控制器集成在<mark>北桥芯片</mark>中。传统方式下，北桥芯片存在于系统主板上，而现在由于芯片制造工艺的升级，芯片集成度越来越高，<strong>所以北桥芯片被就集成到 CPU 芯片中了，同时这也大大提升了 CPU 访问内存的性能</strong>。</p><p>而作为软件开发人员，从逻辑上我们只需要把内存看成<strong>一个巨大的字节数组</strong>就可以，而<mark>内存地址</mark>就是<mark>这个数组的下标</mark>。</p><h2 id="cpu-到内存的性能瓶颈" tabindex="-1"><a class="header-anchor" href="#cpu-到内存的性能瓶颈" aria-hidden="true">#</a> CPU 到内存的性能瓶颈</h2><p>尽管 CPU 和内存是同时代发展的，但 CPU 所使用技术工艺的材料和内存是不同的，侧重点也不同，价格也不同。如果内存使用 CPU 的工艺和材料制造，那内存条的昂贵程度会超乎想象，没有多少人能买得起。</p><p>由于这些不同，导致了 CPU 和内存条的数据吞吐量天差地别。尽管最新的 DDR4 内存条带宽高达 34GB/s，然而这相比 CPU 的数据吞吐量要慢上几个数量级。再加上多核心 CPU 同时访问内存，会导致总线争用问题，数据吞吐量会进一步下降。</p><p>CPU 要数据，内存一时给不了怎么办？CPU 就得等，通常 CPU 会让总线插入等待时钟周期，直到内存准备好，到这里你就会发现，无论 CPU 的性能多高都没用，而<strong>内存才是决定系统整体性能的关键</strong>。显然依靠目前的理论直接提升内存性能，达到 CPU 的同等水平，这是不可行的，得想其它的办法。</p><blockquote><p>由于处理器与内存工艺的差别导致速率差别巨大，而又注意到程序运行存在局部性原理，于是就开发出**<code>在处理器内部的 cache 部件</code>**来优化内存读写性能问题。但这也引入了新的问题，</p><ul><li>硬件上，<strong>cache 模块需要解决数据的一致性问题</strong>；</li><li>软件上，<strong>需要注意尽量利用局部性原理，提高 cache 命中率从而达到最好的程序运行效率</strong>。</li></ul><p>恍然大悟，原来这就是要求我们写<code>高复用性代码</code>的原因，针对经常会用到的功能封装成通用函数或库，供整个程序调用，这些通用函数装载入cache后，因为其高复用性长久的存在于cache中，cpu自然就跑得更快。</p><p><strong><mark>超線程技術</mark>是指<code>一個物理核芯中</code>集成了<code>兩套寄存器</code>，除此之外的其他部件，比如译码器、alu等都還是一套。</strong></p><p>Cache的使用對軟件是透明的，不需要軟件開發人員干預。</p></blockquote><h2 id="cache" tabindex="-1"><a class="header-anchor" href="#cache" aria-hidden="true">#</a> Cache</h2><p>让我们重新回到前面的场景中，回到程序的局部性原理，它告诉我们：CPU 大多数时间在访问相同或者与此相邻的地址。那么，我们立马就可以想到用一块<strong>小而快</strong>的储存器，放在 CPU 和内存之间，就可以利用程序的局部性原理来缓解 CPU 和内存之间的性能瓶颈。这块<strong>小而快</strong>的储存器就是 <mark>Cache，即高速缓存</mark>。</p><p>Cache 中存放了内存中的一部分数据，CPU 在访问内存时要先访问 Cache，若 Cache 中有需要的数据就直接从 Cache 中取出，若没有则需要从内存中读取数据，并同时把这块数据放入 Cache 中。但是由于程序的局部性原理，在一段时间内，CPU 总是能从 Cache 中读取到自己想要的数据。</p><p>Cache 可以集成在 CPU 内部，也可以做成独立的芯片放在总线上，现在 x86 CPU 和 ARM CPU 都是集成在 CPU 内部的。其逻辑结构如下图所示。</p><img src="'+l+'" alt="img" style="zoom:15%;"><p>Cache结构框架图</p><p>Cache 主要由<mark>高速的静态储存器</mark>、<mark>地址转换模块</mark>和 <mark>Cache 行替换模块</mark>组成。</p><p>Cache 会把自己的高速静态储存器和内存分成大小相同的行，一行大小通常为 <code>32 字节</code>或者 <code>64 字节</code>。</p><p>Cache 和内存交换数据的最小单位是一行，为方便管理，在 Cache 内部的高速储存器中，<code>多个行又会形成一组</code>。</p><p>除了正常的数据空间外，Cache 行中还有一些标志位，如脏位、回写位，访问位等，这些位会被 <mark>Cache 的替换模块</mark>所使用。</p><p>Cache 大致的逻辑工作流程如下。</p><p>1.CPU 发出的地址由 Cache 的地址转换模块分成 3 段：组号，行号，行内偏移。</p><p>2.Cache 会根据组号、行号查找高速静态储存器中对应的行。如果找到即命中，用行内偏移读取并返回数据给 CPU，否则就分配一个新行并访问内存，把内存中对应的数据加载到 Cache 行并返回给 CPU。写入操作则比较直接，分为回写和直通写，回写是写入对应的 Cache 行就结束了，直通写则是在写入 Cache 行的同时写入内存。</p><p>3.如果没有新行了，就要进入行替换逻辑，即找出一个 Cache 行写回内存，腾出空间，替换行有相关的算法，<strong><code>替换算法</code>是为了让替换的代价最小化</strong>。例如，找出一个没有修改的 Cache 行，这样就不用把它其中的数据回写到内存中了，还有找出存在时间最久远的那个 Cache 行，因为它大概率不会再访问了。</p><p>以上这些逻辑都由 <mark>Cache 硬件</mark>独立实现，软件不用做任何工作，对软件是透明的。</p><h2 id="cache-带来的问题" tabindex="-1"><a class="header-anchor" href="#cache-带来的问题" aria-hidden="true">#</a> Cache 带来的问题</h2><p>Cache 虽然带来性能方面的提升，但同时也给和硬件和软件开发带来了问题，那就是数据一致性问题。</p><p>为了搞清楚这个问题，我们必须先搞清楚 Cache 在硬件层面的结构，下面我画了 x86 CPU 的 Cache 结构图：</p><img src="'+h+'" alt="img" style="zoom:15%;"><p>x86 CPU的Cache结构图</p><p>这是一颗最简单的双核心 CPU，它有三级 Cache，</p><ul><li>第一级 Cache <strong>是指令和数据分开的</strong>，</li><li>第二级 Cache <strong>是独立于 CPU 核心的</strong>，</li><li>第三级 Cache <strong>是所有 CPU 核心共享的</strong>。</li></ul><p>下面来看看 <mark>Cache 的一致性问题</mark>，主要包括这三个方面.</p><p>\\1. <strong>一个 CPU 核心中</strong>的指令 Cache 和数据 Cache 的一致性问题。</p><p>\\2. <strong>多个 CPU 核心各自</strong>的 2 级 Cache (之间)的一致性问题。</p><p>\\3. CPU 的 3 级 Cache 与设备内存，如 DMA、网卡帧储存，显存之间的一致性问题。这里我们不需要关注这个问题。</p><h3 id="_1级-指令-数据" tabindex="-1"><a class="header-anchor" href="#_1级-指令-数据" aria-hidden="true">#</a> 1级 指令/数据</h3><p>我们先来看看 CPU 核心中的<strong>指令 Cache</strong> 和<strong>数据 Cache</strong> 的一致性问题，对于程序代码运行而言，指令都是经过指令 Cache，而指令中涉及到的数据则会经过数据 Cache。</p><p>所以，对自修改的代码（即修改运行中代码指令数据，变成新的程序）而言，比如我们修改了内存地址 A 这个位置的代码（典型的情况是 Java 运行时编译器），这个时候我们是通过储存的方式去写的地址 A，所以新的指令会进入数据 Cache。</p><p>但是我们接下来去执行地址 A 处的指令的时候，指令 Cache 里面可能命中的是修改之前的指令。所以，这个时候软件需要把数据 Cache 中的数据写入到内存中，然后让指令 Cache 无效，<strong>重新加载内存中的数据</strong>。</p><h3 id="_2级-cache" tabindex="-1"><a class="header-anchor" href="#_2级-cache" aria-hidden="true">#</a> 2级 Cache</h3><p>再来看看多个 CPU 核心各自的 2 级 Cache 的一致性问题。从上图中可以发现，两个 CPU 核心共享了一个 3 级 Cache。比如第一个 CPU 核心读取了一个 A 地址处的变量，第二个 CPU 也读取 A 地址处的变量，那么第二个 CPU 核心是不是需要从内存里面经过第 3、2、1 级 Cache 再读一遍，这个显然是没有必要的。</p><p>在硬件上 Cache 相关的控制单元，可以把第一个 CPU 核心的 A 地址处 Cache 内容直接复制到第二个 CPU 的第 2、1 级 Cache，这样两个 CPU 核心都得到了 A 地址的数据。不过如果这时第一个 CPU 核心改写了 A 地址处的数据，而第二个 CPU 核心的 2 级 Cache 里面还是原来的值，数据显然就不一致了。</p><p>为了解决这些问题，硬件工程师们开发了多种协议，典型的<mark>多核心 Cache 数据同步协议</mark>有 MESI 和 MOESI。MOESI 和 MESI 大同小异，下面我们就去研究一下 MESI 协议。</p><h2 id="cache-的-mesi-协议" tabindex="-1"><a class="header-anchor" href="#cache-的-mesi-协议" aria-hidden="true">#</a> Cache 的 MESI 协议</h2><blockquote><p>补充一下MESI协议，MESI分别代表了高速缓存行的四种状态：<br> 最开始只有一个核读取了A数据，此时状态为E独占，数据是干净的，<br> 后来另一个核又读取了A数据，此时状态为S共享，数据还是干净的，<br> 接着其中一个核修改了数据A，此时会向其他核广播数据已被修改，让其他核的数据状态变为I失效，而本核的数据还没回写内存，状态则变为M已修改，等待后续刷新缓存后，数据变回E独占，其他核由于数据已失效，读数据A时需要重新从内存读到高速缓存，此时数据又共享了。</p></blockquote><p>MESI 协议定义了 4 种基本状态：M、E、S、I，即修改（Modified）、独占（Exclusive）、共享（Shared）和无效（Invalid）。下面我结合示意图，给你解释一下这四种状态。</p><h3 id="m-修改-modified" tabindex="-1"><a class="header-anchor" href="#m-修改-modified" aria-hidden="true">#</a> M 修改（Modified）</h3><p>1.M 修改（Modified）：<strong>当前 Cache 的内容有效，数据已经被修改而且与内存中的数据不一致，数据只在当前 Cache 里存在</strong>。比如说，内存里面 X=5，而 CPU 核心 1 的 Cache 中 X=2，Cache 与内存不一致，CPU 核心 2 中没有 X。</p><img src="'+C+'" alt="img" style="zoom:15%;"><p>MESI协议-M</p><h3 id="e-独占-exclusive" tabindex="-1"><a class="header-anchor" href="#e-独占-exclusive" aria-hidden="true">#</a> E 独占（Exclusive）</h3><p>2.E 独占（Exclusive）：<strong>当前 Cache 中的内容有效，数据与内存中的数据一致，数据只在当前 Cache 里存在</strong>；类似 RAM 里面 X=5，同样 CPU 核心 1 的 Cache 中 X=5（Cache 和内存中的数据一致），CPU 核心 2 中没有 X。</p><img src="'+u+'" alt="img" style="zoom:15%;"><p>MESI协议-E</p><h3 id="s-共享-shared" tabindex="-1"><a class="header-anchor" href="#s-共享-shared" aria-hidden="true">#</a> S 共享（Shared）</h3><p>3.S 共享（Shared）：<strong>当前 Cache 中的内容有效，Cache 中的数据与内存中的数据一致，数据在多个 CPU 核心中的 Cache 里面存在</strong>。例如在 CPU 核心 1、CPU 核心 2 里面 Cache 中的 X=5，而内存中也是 X=5 保持一致。</p><img src="'+m+`" alt="img" style="zoom:15%;"><h3 id="无效-invalid" tabindex="-1"><a class="header-anchor" href="#无效-invalid" aria-hidden="true">#</a> 无效（Invalid）</h3><p>4.无效（Invalid）：<strong>当前 Cache 无效</strong>。前面三幅图 Cache 中没有数据的那些，都属于这个情况。</p><h3 id="cache硬件" tabindex="-1"><a class="header-anchor" href="#cache硬件" aria-hidden="true">#</a> Cache硬件</h3><p>最后还要说一下 Cache 硬件，<strong>它会监控所有 CPU 上 Cache 的操作，根据相应的操作使得 Cache 里的数据行在上面这些状态之间切换</strong>。Cache 硬件通过这些状态的变化，就能安全地控制各 Cache 间、各 Cache 与内存之间的数据一致性了。</p><h3 id="小结" tabindex="-1"><a class="header-anchor" href="#小结" aria-hidden="true">#</a> 小结</h3><p>这里不再深入探讨 MESI 协议了，感兴趣的话你可以自行拓展学习。这里只是为了让你明白，有了 Cache 虽然提升了系统性能，却也带来了很多问题，好在这些问题都由硬件自动完成，对软件而言是透明的。</p><p>不过看似对软件透明，这却是有代价的，因为硬件需要耗费时间来处理这些问题。如果我们编程的时候不注意，不能很好地规避这些问题，就会引起硬件去维护大量的 Cache 数据同步，这就会使程序运行的效能大大下降。</p><h2 id="开启-cache" tabindex="-1"><a class="header-anchor" href="#开启-cache" aria-hidden="true">#</a> 开启 Cache</h2><p>前面我们研究了大量的 Cache 底层细节和问题，就是为了使用 Cache，目前 Cache 已经成为了现代计算机的标配，但是 x86 CPU 上默认是关闭 Cache 的，需要在 CPU 初始化时将其开启。</p><p>在 x86 CPU 上开启 Cache 非常简单，只需要将 CR0 寄存器中 CD、NW 位同时清 0 即可。CD=1 时表示 Cache 关闭，NW=1 时 CPU 不维护内存数据一致性。所以 <strong>CD=0、NW=0 的组合</strong>才是开启 Cache 的正确方法。</p><p>开启 Cache 只需要用四行汇编代码，代码如下：</p><div class="language-assembly line-numbers-mode" data-ext="assembly"><pre class="language-assembly"><code>mov eax, cr0
;开启 CACHE    
btr eax,29 ;CR0.NW=0
btr eax,30  ;CR0.CD=0
mov cr0, eax
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="获取内存视图" tabindex="-1"><a class="header-anchor" href="#获取内存视图" aria-hidden="true">#</a> 获取内存视图</h2><p>作为系统软件开发人员，与其了解内存内部构造原理，不如了解系统内存有多大。这个作用更大。</p><p>根据前面课程所讲，给出一个物理地址并不能准确地定位到内存空间，内存空间只是映射物理地址空间中的一个子集，物理地址空间中可能有空洞，有 ROM，有内存，有显存，有 I/O 寄存器，所以获取内存有多大没用，关键是<strong>要获取哪些物理地址空间是可以读写的内存</strong>。</p><p>物理地址空间是由北桥芯片控制管理的，那我们是不是要找北桥要内存的地址空间呢？当然不是，在 x86 平台上还有更方便简单的办法，那就是 BIOS 提供的实模式下中断服务，就是 int 指令后面跟着一个常数的形式。</p><p>由于 PC 机上电后由 BIOS 执行硬件初始化，中断向量表是 BIOS 设置的，所以执行中断自然执行 BIOS 服务。这个中断服务是 int 15h，但是它需要一些参数，就是在执行 int 15h 之前，对特定寄存器设置一些值，代码如下。</p><div class="language-assembly line-numbers-mode" data-ext="assembly"><pre class="language-assembly"><code>_getmemmap:
  xor ebx,ebx ;ebx设为0
  mov edi,E80MAP_ADR ;edi设为存放输出结果的1MB内的物理内存地址
loop:
  mov eax,0e820h ;eax必须为0e820h
  mov ecx,20 ;输出结果数据项的大小为20字节：8字节内存基地址，8字节内存长度，4字节内存类型
  mov edx,0534d4150h ;edx必须为0534d4150h
  int 15h ;执行中断
  jc error ;如果flags寄存器的C位置1，则表示出错
  add edi,20;更新下一次输出结果的地址
  cmp ebx,0 ;如ebx为0，则表示循环迭代结束
  jne loop  ;还有结果项，继续迭代
    ret
error:;出错处理
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>上面的代码是在迭代中执行中断，每次中断都输出一个 20 字节大小数据项，最后会形成一个该数据项（结构体）的数组，可以用 C 语言结构表示，如下。</p><div class="language-c line-numbers-mode" data-ext="c"><pre class="language-c"><code><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">RAM_USABLE</span> <span class="token expression"><span class="token number">1</span> </span><span class="token comment">//可用内存</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">RAM_RESERV</span> <span class="token expression"><span class="token number">2</span> </span><span class="token comment">//保留内存不可使用</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">RAM_ACPIREC</span> <span class="token expression"><span class="token number">3</span> </span><span class="token comment">//ACPI表相关的</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">RAM_ACPINVS</span> <span class="token expression"><span class="token number">4</span> </span><span class="token comment">//ACPI NVS空间</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">RAM_AREACON</span> <span class="token expression"><span class="token number">5</span> </span><span class="token comment">//包含坏内存</span></span>
<span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token class-name">s_e820</span><span class="token punctuation">{</span>
    <span class="token class-name">u64_t</span> saddr<span class="token punctuation">;</span>    <span class="token comment">/* 内存开始地址 */</span>
    <span class="token class-name">u64_t</span> lsize<span class="token punctuation">;</span>    <span class="token comment">/* 内存大小 */</span>
    <span class="token class-name">u32_t</span> type<span class="token punctuation">;</span>    <span class="token comment">/* 内存类型 */</span>
<span class="token punctuation">}</span><span class="token class-name">e820map_t</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="重点回顾" tabindex="-1"><a class="header-anchor" href="#重点回顾" aria-hidden="true">#</a> 重点回顾</h2><p>又到了课程尾声，内存和 Cache 的学习就告一段落了。今天我们主要讲了四部分内容，局部性原理、内存结构特性、Cache 工作原理和 x86 上的应用。我们一起来回顾一下这节课的重点。</p><p>首先从一个场景开始，我们了解了程序通常的结构。通过观察这种结构，我们发现 CPU 大多数时间在访问相同或者与此相邻的地址，执行相同的指令或者与此相邻的指令。这种现象就是程序<strong>局部性原理</strong>。</p><p>然后，我们研究了内存的结构和特性。了解它的工艺标准和内部原理，知道内存容量相对可以做得较大，程序和数据都要放在其中才能被 CPU 执行和处理。但是内存的速度却远远赶不上 CPU 的速度。</p><p>因为内存和 CPU 之间性能瓶颈和程序局部性原理，所以才开发出了 Cache（即高速缓存），它由高速静态储存器和相应的控制逻辑组成。</p><p>Cache 容量比内存小，速度却比内存高，它在 CPU 和内存之间，CPU 访问内存首先会访问 Cache，如果访问命中则会大大提升性能，然而它却带来了问题，那就是<strong>数据的一致性问题</strong>，为了解决这个问题，工程师又开发了 Cache<strong>一致性协议 MESI</strong>。这个协议由 Cache 硬件执行，对软件透明。</p><p>最后，我们掌握了 x86 平台上开启 Cache 和获取物理内存视图的方法。</p><p>因为这节课也是我们硬件模块的最后一节，可以说<strong>没有硬件平台知识，写操作系统就如同空中建楼</strong>，通过这个部分的学习，就算是为写操作系统打好了地基。为了让你更系统地认识这个模块，我给你整理了这三节课的知识导图。</p><img src="`+b+'" alt="img" style="zoom:25%;"><h2 id="思考题" tabindex="-1"><a class="header-anchor" href="#思考题" aria-hidden="true">#</a> 思考题</h2><p>请你思考一下，如何写出让 CPU 跑得更快的代码？由于 Cache 比内存快几个数量级，所以这个问题也可以转换成：如何写出提高 Cache 命中率的代码？</p><h2 id="【】课后讨论" tabindex="-1"><a class="header-anchor" href="#【】课后讨论" aria-hidden="true">#</a> 【】课后讨论</h2><p>如何写出让 CPU 跑得更快的代码？可以从以下几方面入手：<br> 1、遵从80-20法则，程序80%的时间在运行20%或更少的代码，<code>针对热代码进行优化，才容易产出效果</code>；<br> 2、遵从数据访问的局部性法则，<code>按数据存放顺序访问内存</code>的效率远高于乱序访问内存的效率，也就是<code>尽量帮助CPU做好数据Cache的预测工作</code>。<br> 同样根据Cache大小，<code>做好数据结构的优化工作，进行数据压缩或数据填充</code>，也是提升Cache效率的好方式；<br> 3、遵从指令访问的局部性法则，<code>减少跳转指令</code>，同样是尽量帮助CPU做好数据Cache的预测工作；<br> 现代CPU都有一些预测功能【如分支预测】，利用好CPU的这些功能，也会提升Cache命中率；<br> 4、避免计算线程在多个核心之间漂移，避免缓存重复加载，<code>可以绑定核心</code>【物理核即可，不用到逻辑核】，提高效率；<br> 5、<code>去除伪共享缓存</code>：在多核环境下，减少多个核心对同一区域内存的读写并发操作，减少内存失效的情况的发生；<br><mark>开始跑题</mark><br> 6、<code>合理提高进程优先级，减少进程间切换</code>，可以变相提供Cache提速的效果<br> 7、<code>关闭Swap</code>，可以变相提供内存提速、Cache提速的效果；<br> 8、<code>使用Intel自家的编译器，开启性能优化</code>，很多时候可以提速运算效率；<br> 9、<code>使用C语言</code>，而不是更高级的语言，很多时候可以提速运算效率；<br> 10、<code>直接使用昂贵的寄存器作为变量</code>，可以变相提供加速效果；<br> 作者回复: 大神你好，你以前是做性能优化的吧 ，这些问题说的很对</p><hr><p>在CSAPP第六章对存储器层次架构有详细的探讨，感兴趣的同学可以查阅一下，这里我简单总结一下当做思考题答案。<br> 一个编写良好的计算机程序常常具有良好的局部性，这被称为局部性原理，对硬件和软件都有极大的影响。<br> 局部性可分为两种，<code>1.数据引用局部性; 2.指令局部性</code>。CPU对数据和指令都存在高速缓存，<br> 1 当缓存中的<code>数据</code>大面积命中时，则该代码拥有良好的空间局部性;<br> 2 当缓存中的<code>指令</code>大面积命中时，也该代码拥有良好的时间局部性。<br> 别忘了，CPU对于指令和数据的操作都需要花时间，那如果二者如果都大面积的缓存命中，可以减少非常多的内存访问操作，<strong>对于CPU来说，内存访问就是性能瓶颈所在</strong>。<br> 因此编写高速缓存友好的代码是必要的，高手与小白往往只有一步之遥！<br> 基本方法大致如下:<br> 1.让最常见的情况运行得快，<strong>核心函数中的核心部分，是影响性能的关键点</strong>，它们占据了程序的大部分运行时间，所以要把注意力放在它们身上。<br> 2.尽量减少每个循环内部的缓存不命中数量，<strong>循环是缓存工作的重点，一个循环容易带来性能问题，而它恰好也容易被优化成空间、时间局部性良好的代码</strong>。<br> 欢迎大家一起交流指正~</p><hr>',117),v={href:"https://blog.csdn.net/zhanyd/article/details/102631248",target:"_blank",rel:"noopener noreferrer"},P=a("hr",null,null,-1),_={href:"https://blog.csdn.net/u013570834/article/details/117635229?utm_source=app&app_version=4.9.2",target:"_blank",rel:"noopener noreferrer"},U=a("br",null,null,-1),f=a("br",null,null,-1),x=a("code",null,"所以我们尽量避免 goto 与非本地跳转",-1),M=a("br",null,null,-1),y=a("code",null,"所以数组的遍历方式对cache的命中率影响极大",-1),S=a("br",null,null,-1),A=a("code",null,"我们应该关注的如何能用条件传送的方式避免分支判断！",-1),E=a("br",null,null,-1),I=c("<hr><p>1.<code>减少使用带有jmp指令的代码</code>，提高指令cache的局部性（不过cpu貌似有分支预测器来优化jmp指令带来的性能损耗）<br> 2.<code>对于需要连续访问的数据</code>，可以将其放在一块（数组？）以提高数据cache的局部性<br> 3.对于需要被多个CPU执行写操作的多个数据，可以根据<mark>cache line的大小</mark>对这些数据进行<mark>padding操作</mark>，来降低缓存一致性协议带来的读写内存频率</p><hr><p>提高Cache的命中率可以从<code>优化指令布局</code>和<code>优化数据布局</code>两个方面开展。比如<strong>减少频繁的跳转，数据集中连续存放</strong>等。</p><hr><p>回答一下思考题. 因为<strong>缓存行</strong>是固定的，32或64个字节，<strong>只能在写入内存的数据上尽量补齐</strong>，比如一个int 占4个字节(java), 32位系统的对象头占8个字节，这样再多写5个int就对齐（32字节）一个缓冲行了，jdk也提供了一个 annotation 即 @Contended 来解决，另外内存队列disruptor也用同样的方式优化了同样的问题，但是如此这数据，势必会造成资源浪费，如何权衡这2者还请老师分享一下经验</p><p><strong>可以参考Java 实现的高性能队列 Disruptor 框架 ，充分利用缓存行的特性，将每个对象包装成64byte的倍数，避免伪共享。尽可能按照连续内存的方式来存储，确保能被缓存加载。</strong></p><p>作者回复: 是，你考虑的很深刻，说够笑话加内存 加服务器 有时候时间和空间是不可以兼得的</p><hr><p><strong>如果<code>写出代码对内存的使用单位</code>是和<code>Cache行</code>相一致</strong>，这样可以优化Cache调度，是一种用空间换时间的思路。</p><hr><p>尽量让程序少跳转，比如在if else分支结构中，<strong>提高if的条件成立的可能性</strong>。在循环需要对变量操作时，<strong>应尽量考虑到这些变量的空间存储位置</strong>，还有<strong>尽量使用局部变量</strong>？作者回复: 对对对 你的学习非常认真 善于思考</p><hr><p>总结收获：<br> 1.程序局部性原理。一段时间内CPU执行的指令是同一地址或者相邻地址，对应相同指令或邻近指令。<br> 2.CPU, Cache和内存。CPU的速度高出内存几个数量级，为了提升CPU性能，根据程序局部性原理，设计出了在二者之间插入Cache的解决方案。<br> 3.Cache虽然解决了效率问题，但是带来了数据一致性问题；硬件MESI协议就是用来解决这个问题的，纯硬件操作，对软件透明。<br> 4.物理地址由很多模块组成：内存，显存，网卡等IO设备都是；对软件来说的重点是如何获取内存的地址和大小。x86 CPU通过BIOS的中断程序迭代获取全部内存类型、地址和大小。<br> 思考题：写出让 CPU 跑得更快的代码（提高 Cache 命中率）的方法，从局部性原理入手，代码设计上遵循高内聚低耦合的原则，减少函数间调用，这样可以让业务功能强相关的代码指令被加载到cache，<strong>只在调用外部接口时cache miss</strong>。</p><hr>",15),D={href:"https://www.scss.tcd.ie/Jeremy.Jones/VivioJS/caches/MESIHelp.htm",target:"_blank",rel:"noopener noreferrer"};function R(j,w){const s=t("ExternalLinkIcon");return p(),r("div",null,[g,a("p",null,[e("我以前写过一篇关于缓存局部性原理的文章，有兴趣的同学可以看看： "),a("a",v,[e("https://blog.csdn.net/zhanyd/article/details/102631248"),n(s)])]),P,a("p",null,[e("程序代码优化 基于csapp做的整理 "),a("a",_,[e("https://blog.csdn.net/u013570834/article/details/117635229?utm_source=app&app_version=4.9.2"),n(s)]),U,e(" 1.gcc 编译器优化很蠢并不会猜测程序员编码的意图，只会做非常保守的优化"),f,e(" 2.循环对于具有很好的时间局部性，"),x,M,e(" 3.数组在内存中行优先排列，"),y,S,e(" 4.分支预测失败虽然会带来极大的惩罚，但这不是我们关注的重点，"),A,E,e(" 5.根据阿姆达尔定律，加速大的部分永远比加速小的要有效，所以我们可以根据对程序的分析来做具体的优化")]),I,a("p",null,[e("结合这个动画可以比较好理解MESI: "),a("a",D,[e("https://www.scss.tcd.ie/Jeremy.Jones/VivioJS/caches/MESIHelp.htm"),n(s)])])])}const O=o(k,[["render",R],["__file","C07-Cache与内存.html.vue"]]);export{O as default};
