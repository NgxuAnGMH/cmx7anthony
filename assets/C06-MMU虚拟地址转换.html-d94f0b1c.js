import{_ as r}from"./plugin-vue_export-helper-c27b6911.js";import{o as a,c as s,d as e}from"./app-cdabc73c.js";const o="/assets/b0e93b744dfdc62c4a3ce8816b25b1fc-5ad97861.jpg",n="/assets/d582ff647549b8yy986d90e697d33499-dd564239.jpg",t="/assets/9b19677448ee973c4f3yya6b3af7b4d0-2300479d.jpg",p="/assets/b41a2bb00e19e662b34a1b7b7c0ae288-0fcb871d.jpg",c="/assets/2df904c8ba75065e1491138d63820yyf-23c4683a.jpg",d="/assets/00b7f1ef4a1c4f6fc9e6b69109ae0bf8-60dcd40c.jpg",i="/assets/361c48e1876a412f9ff9f29bf2dbecc9-3e735095.jpg",m="/assets/76932c52a7b6109854f2de72d71bba52-07d0e44c.jpg",g="/assets/9a4afdc60b790c3e2b7e94b0c7fd4208-0370e5bf.jpg",l="/assets/ecdea93c2544cf9c1d84461b602b03c9-2410e747.jpg",b="/assets/e342246f5cfa21c5b5173b9e494bdc55-af35146a.jpg",M="/assets/68bf70d8bcae7802e5291140ac1ec6ea-4d1e3ef8.jpg",u="/assets/457f6965d0f25bf64bfb9ec698ab7e0b-6950cc9d.jpg",h={},k=e('<h1 id="_06-虚幻与真实-程序中的地址如何转换" tabindex="-1"><a class="header-anchor" href="#_06-虚幻与真实-程序中的地址如何转换" aria-hidden="true">#</a> 06 | 虚幻与真实：程序中的地址如何转换？</h1><p>你好，我是 LMOS。</p><p>从前面的课程我们得知，CPU 执行程序、处理数据都要和内存打交道，这个打交道的方式就是内存地址。</p><p>读取指令、读写数据都需要首先告诉内存芯片：hi，内存老哥请你把 0x10000 地址处的数据交给我……hi，内存老哥，我已经计算完成，请让我把结果写回 0x200000 地址的空间。这些地址存在于代码指令字段后的常数，或者存在于某个寄存器中。</p><img src="'+o+`" alt="img" style="zoom:15%;"><p>今天，我们就来专门研究一下程序中的地址。说起程序中的地址，不知道你是否好奇过，为啥系统设计者要引入虚拟地址呢？</p><p>我会先带你从一个多程序并发的场景热身，一起思考这会导致哪些问题，为什么能用虚拟地址解决这些问题。</p><p>搞懂原理之后，我还会带你一起探索<strong>虚拟地址和物理地址的关系和转换机制</strong>。在后面的课里，你会发现，我们最宝贵的内存资源正是通过这些机制来管理的。</p><h2 id="从一个多程序并发的场景说起" tabindex="-1"><a class="header-anchor" href="#从一个多程序并发的场景说起" aria-hidden="true">#</a> 从一个多程序并发的场景说起</h2><p>设想一下，如果一台计算机的内存中只运行一个程序 A，这种方式正好用前面 CPU 的实模式来运行，因为程序 A 的地址在链接时就可以确定，例如从内存地址 0x8000 开始，<strong>每次运行</strong>程序 A 都装入内存 0x8000 地址处开始运行，没有其它程序干扰。</p><p>现在改变一下，内存中又放一道程序 B，程序 A 和程序 B 各自运行一秒钟，如此循环，直到其中之一结束。这个新场景下就会产生一些问题，当然这里我们只关心内存相关的这几个核心问题。</p><p>\\1. 谁来保证程序 A 跟程序 B <strong>没有内存地址的冲突</strong>？换句话说，就是程序 A、B 各自放在什么内存地址，这个问题是由 A、B 程序协商，还是由操作系统决定。</p><p>\\2. 怎样保证程序 A 跟程序 B <strong>不会互相读写各自的内存空间</strong>？这个问题相对简单，用保护模式就能解决。</p><p>\\3. 如何解决<strong>内存容量</strong>问题？程序 A 和程序 B，在不断开发迭代中程序代码占用的空间会越来越大，导致内存装不下。</p><p>\\4. 还要考虑一个<strong>扩展后的复杂情况</strong>，如果不只程序 A、B，还可能有程序 C、D、E、F、G……它们分别由不同的公司开发，而每台计算机的内存容量不同。这时候，又对我们的内存方案有怎样的影响呢？</p><blockquote><p>要想完美地解决以上最核心的 4 个问题，一个较好的方案是：让所有的程序都各自享有一个从 0 开始到最大地址的空间，这个地址空间是独立的，是该程序私有的，其它程序既看不到，也不能访问该地址空间，这个地址空间和其它程序无关，和具体的计算机也无关。</p></blockquote><p>事实上，计算机科学家们早就这么做了，这个方案就是<strong>虚拟地址</strong>，下面我们就来看看它。</p><h2 id="虚拟地址" tabindex="-1"><a class="header-anchor" href="#虚拟地址" aria-hidden="true">#</a> 虚拟地址</h2><p>正如其名，这个地址是虚拟的，自然而然地和具体环境进行了解耦，这个环境包括系统软件环境和硬件环境。</p><p>虚拟地址是逻辑上存在的一个数据值，比如 0~100 就有 101 个整数值，这个 0~100 的区间就可以说是一个虚拟地址空间，该虚拟地址空间有 101 个地址。</p><p>我们再来看看最开始 Hello World 的例子，我们用 objdump 工具反汇编一下 Hello World <mark>二进制可执行文件</mark>，就会得到如下的代码片段：</p><div class="language-assembly line-numbers-mode" data-ext="assembly"><pre class="language-assembly"><code>00000000000004e8 &lt;_init&gt;:
 4e8:  48 83 ec 08            sub    $0x8,%rsp
 4ec:  48 8b 05 f5 0a 20 00   mov    0x200af5(%rip),%rax        # 200fe8 &lt;__gmon_start__&gt;
 4f3:  48 85 c0               test   %rax,%rax
 4f6:  74 02                  je     4fa &lt;_init+0x12&gt;
 4f8:  ff d0                  callq  *%rax
 4fa:  48 83 c4 08            add    $0x8,%rsp
 4fe:  c3                     retq 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>上述代码中，左边第一列数据就是虚拟地址，第三列中是程序指令，如：“mov 0x200af5(%rip),%rax，je 4fa，callq *%rax”指令中的数据都是虚拟地址。</p><p>事实上，所有的应用程序开始的部分都是这样的。这正是因为<strong>每个应用程序的<code>虚拟地址空间</code>都是相同且独立的</strong>。</p><blockquote><p><strong>那么这个地址是由谁产生的呢？</strong></p><p>答案是<mark>链接器</mark>，其实我们开发软件经过编译步骤后，<strong>就需要链接成可执行文件才可以运行</strong>，而链接器的主要工作就是把多个代码模块组装在一起，并解决模块之间的引用，即**<code>处理程序代码间的地址引用，形成程序运行的静态内存空间视图</code>**。</p></blockquote><p>只不过这个地址是虚拟而统一的，而根据操作系统的不同(可执行文件的格式不同)，这个虚拟地址空间的定义也许不同，应用软件开发人员无需关心，由开发工具链给自动处理了。<strong>由于这虚拟地址是独立且统一的</strong>，所以各个公司开发的各个应用完全不用担心自己的内存空间被占用和改写。</p><h2 id="物理地址" tabindex="-1"><a class="header-anchor" href="#物理地址" aria-hidden="true">#</a> 物理地址</h2><p>虽然虚拟地址解决了很多问题，但是虚拟地址只是逻辑上存在的地址，无法作用于硬件电路的，程序装进内存中想要执行，就需要和内存打交道，从内存中取得指令和数据。而内存只认一种地址，那就是<strong>物理地址</strong>。</p><p>什么是物理地址呢？物理地址在逻辑上也是一个数据，只不过这个数据会被==<strong>地址译码器</strong>等电子器件<mark>变成电子信号，放在</mark>地址总线<mark>上，地址总线电子信号的各种组合就可以选择到</mark>内存的储存单元==了。</p><p>但是地址总线上的信号（即物理地址），也可以选择到<strong>别的设备中的储存单元</strong>，如<mark>显卡中的显存</mark>、<mark>I/O 设备中的寄存器</mark>、<mark>网卡上的网络帧缓存器</mark>。不过如果不做特别说明，我们说的物理地址就是指<strong>选择内存单元的地址</strong>。</p><h2 id="虚拟地址到物理地址的转换-必须分页" tabindex="-1"><a class="header-anchor" href="#虚拟地址到物理地址的转换-必须分页" aria-hidden="true">#</a> 虚拟地址到物理地址的转换/必须分页</h2><p>明白了虚拟地址和物理地址之后，我们发现虚拟地址必须转换成物理地址，这样程序才能正常执行。要转换就必须要转换机构，它相当于一个函数：p=f(v)，输入虚拟地址 v，输出物理地址 p。</p><p>那么要怎么实现这个函数呢？</p><p>用软件方式实现太低效，用硬件实现没有灵活性，<strong>最终就用了<code>软硬件结合的方式</code>实现</strong>，它就是 <mark>MMU（内存管理单元）</mark>。MMU 可以接受软件给出的地址对应关系数据，进行地址转换。</p><p>我们先来看看逻辑上的 MMU 工作原理框架图。如下图所示：</p><img src="`+n+'" alt="img" style="zoom:15%;"><p>MMU工作原理图</p><p>上图中展示了 MMU 通过地址关系转换表，将 0x80000~0x84000 的虚拟地址空间转换成 0x10000~0x14000 的物理地址空间，而<mark>地址关系转换表</mark>本身则是放<strong>物理内存</strong>中的。</p><p>下面我们不妨想一想地址关系转换表的实现. 如果在地址关系转换表中，这样来存放：一个虚拟地址对应一个物理地址。（那不是没区别嘛实模式）</p><p>那么问题来了，32 位地址空间下，4GB 虚拟地址的地址关系转换表就会把整个 32 位物理地址空间用完，这显然不行。</p><p>要是结合前面的保护模式下分段方式呢，地址关系转换表中存放：一个虚拟段基址对应一个物理段基址，这样看似可以，但是因为段长度各不相同，所以依然不可取。</p><p>综合刚才的分析，系统设计者最后采用一个折中的方案，即<strong>把虚拟地址空间和物理地址空间都分成<code>同等大小的块</code>，也称为<mark>页</mark>，按照<mark>虚拟页</mark>和<mark>物理页</mark>进行转换。<strong>根据软件配置不同，这个</strong>页的大小</strong>可以设置为 <code>4KB、2MB、4MB、1GB</code>，这样就进入了现代内存管理模式——<strong><mark>分页模型</mark></strong>。</p><p>下面来看看分页模型框架，如下图所示：</p><img src="'+t+'" alt="img" style="zoom:15%;"><p>分页模型框架图</p><p>结合图片可以看出，一个虚拟页可以对应到一个物理页，由于页大小一经配置就是固定的，所以在地址关系转换表中，只要存放<strong>虚拟页地址对应的物理页地址</strong>就行了。</p><p>我知道，说到这里，也许你仍然没搞清楚 MMU 和地址关系转换表的细节，别急，我们现在已经具备了研究它们的基础，下面我们就去探索它们。</p><h2 id="mmu-内存管理单元-软硬件结合" tabindex="-1"><a class="header-anchor" href="#mmu-内存管理单元-软硬件结合" aria-hidden="true">#</a> MMU 内存管理单元/软硬件结合</h2><p>MMU 即内存管理单元，是用硬件电路逻辑实现的一个地址转换器件，它负责接受虚拟地址和地址关系转换表，以及输出物理地址。</p><p>根据实现方式的不同，MMU 可以是独立的芯片，也可以是集成在其它芯片内部的，比如集成在 CPU 内部，x86、ARM 系列的 CPU 就是将 MMU 集成在 CPU 核心中的。</p><p>SUN 公司的 CPU 是将独立的 MMU 芯片卡在总线上的，有一夫当关的架势。下面我们只研究 x86 CPU 中的 MMU。x86 CPU 要想开启 MMU，就必须先开启保护模式或者长模式，实模式下是不能开启 MMU 的。</p><p>由于<mark>保护模式</mark>的内存模型是<strong>分段模型</strong>，它并不适合于 MMU 的分页模型，所以我们要使用保护模式的<strong>平坦模式</strong>，这样就绕过了分段模型。这个平坦模型和长模式下忽略段基址和段长度是异曲同工的。地址产生的过程如下所示。</p><blockquote><p>分段的平坦模式，就是将段基地址设置为0然后直接加上偏移地址，0 + 段内偏移=线性地址(地址是线性的代表大小相等)=逻辑地址，分段机制等于没有使用（检查等还是使用的），而是直接使用了分页(约等于固定大小的分页模式)</p></blockquote><img src="'+p+'" alt="img" style="zoom:15%;"><p>CPU地址转换图</p><p>上图中，程序代码中的虚拟地址，经过 CPU 的分段机制产生了线性地址(间隔大小相等/相当于分页)，平坦模式和长模式下线性地址和虚拟地址是相等的。</p><p>如果不开启 MMU，在保护模式下可以关闭 MMU，这个线性地址就是物理地址。因为长模式下的分段<strong>弱化了地址空间的隔离</strong>，所以开启 MMU 是必须要做的，开启 MMU 才能访问内存地址空间。</p><h2 id="mmu-页表-地址关系转换表-工作流程" tabindex="-1"><a class="header-anchor" href="#mmu-页表-地址关系转换表-工作流程" aria-hidden="true">#</a> MMU 页表/地址关系转换表/工作流程</h2><p>现在我们开始研究<mark>地址关系转换表</mark>，其实它有个更加专业的名字——<strong>页表</strong>。它描述了虚拟地址到物理地址的转换关系，也可以说是虚拟页到物理页的映射关系，所以称为页表。</p><p>为了增加灵活性和节约物理内存空间（<strong>因为页表是放在物理内存中的</strong>），所以页表中并不存放虚拟地址和物理地址的对应关系，只存放物理页面的地址，<strong>MMU</strong> 以虚拟地址为<strong>索引</strong>去查表返回<strong>物理页面地址</strong>，而且页表是分级的，总体分为三个部分：一个<mark>顶级页目录</mark>，多个<mark>中级页目录</mark>，最后才是<mark>页表</mark>，逻辑结构图如下.</p><img src="'+c+'" alt="img" style="zoom:15%;"><p>MMU页表原理图</p><p>从上面可以看出，<strong><code>一个虚拟地址</code>被分成从左至右<code>四个位段</code></strong>。</p><ol><li>第一个位段索引<mark>顶级页目录</mark>中一个项，该项指向一个中级页目录，</li><li>然后用第二个位段去索引<mark>中级页目录</mark>中的一个项，该项指向一个页目录/页表</li><li>再用第三个位段去索引<mark>页目录/页表</mark>中的项，该项指向一个物理页地址，</li><li>最后用第四个位段作<mark>该物理页内的偏移</mark>去访问物理内存。</li></ol><p><strong>这就是 MMU 的工作流程。</strong></p><h2 id="_32位-保护模式下的分页" tabindex="-1"><a class="header-anchor" href="#_32位-保护模式下的分页" aria-hidden="true">#</a> 32位-保护模式下的分页</h2><p>前面的内容都是理论上帮助我们了解分页模式原理的，分页模式的<strong>灵活性、通用性、安全性</strong>，是现代操作系统内存管理的基石，更是事实上的标准内存管理模型，现代商用操作系统都必须以此为基础实现虚拟内存功能模块。</p><p>因为我们的主要任务是开发操作系统，而开发操作系统就落实到真实的硬件平台上去的，下面我们就来研究 x86 CPU 上的分页模式。</p><p>首先来看看<mark>保护模式</mark>下的分页，保护模式下只有 32 位地址空间，最多 4GB-1 大小的空间。</p><p>根据前面得知 32 位虚拟地址经过分段机制之后得到线性地址，又因为通常使用<mark>平坦模式</mark>，所以线性地址和虚拟地址是相同的。</p><p>保护模式下的分页大小通常有两种，一种是 4KB 大小的页，一种是 4MB 大小的页。<strong>分页大小的不同，会导致<code>虚拟地址位段的分隔和页目录的层级</code>不同，但虚拟页和物理页的大小始终是等同的。</strong></p><h3 id="_1-保护模式下的分页——4kb-页" tabindex="-1"><a class="header-anchor" href="#_1-保护模式下的分页——4kb-页" aria-hidden="true">#</a> 1 保护模式下的分页——4KB 页</h3><p>该分页方式下，32 位虚拟地址被分为三个位段：<strong>1 页目录索引、2 页表索引、3 页内偏移</strong>，只有一级页目录，其中包含 1024 个条目 ，每个条目指向一个页表，每个页表中有 1024 个条目。其中一个条目就指向一个物理页，每个物理页 4KB。这正好是 4GB 地址空间。如下图所示。</p><img src="'+d+'" alt="img" style="zoom:15%;"><p>保护模式下的4KB分页</p><p>上图中 <mark>CR3</mark> 就是 CPU 的一个 32 位的寄存器，<mark>MMU</mark> 就是根据这个寄存器找到<mark>页目录</mark>的。</p><blockquote><p>地址总线/操作系统/为32位. 内存采取分页管理, 页的大小固定为 4KB=4096B -&gt; 2<sup>12</sup>.<br> 1.真正体现页的大小的地方是&quot;页内偏移&quot;这个部分, 因此这里对应是12位.<br> 2.那物理页或逻辑页, 32位地址中的剩余部分, 只能对应也只需20位.</p></blockquote><p>下面，我们看看当前分页模式下的 CR3、页目录项、页表项的格式。</p><ul><li>CR3(页目录表物理基址) + <code>[虚拟地址 1 页目录索引]</code> -&gt; 页目录表项 / 页表物理基址</li><li>页目录表项(页表物理基址) + <code>[虚拟地址 2 页表索引]</code> -&gt; 页表项 / 4KB物理页的基址</li><li>页表项(4KB物理页的基址) + <code>[虚拟地址 3 页内偏移]</code> -&gt; 目标位置</li></ul><img src="'+i+'" alt="img" style="zoom:15%;"><p>可以看到，<strong>页目录项、页表项都是 4 字节 32 位</strong>，1024 个项正好是 4KB（刚好一个页），因此它们的地址始终是 4KB 对齐的，<strong>所以低 12 位才可以另作它用</strong>，形成了页面的相关属性，<code>如是否存在、是否可读可写、是用户页还是内核页、是否已写入、是否已访问等</code>。</p><h3 id="_2-保护模式下的分页——4mb-页" tabindex="-1"><a class="header-anchor" href="#_2-保护模式下的分页——4mb-页" aria-hidden="true">#</a> 2 保护模式下的分页——4MB 页</h3><p>该分页方式下，32 位虚拟地址被分为两个位段：<strong>1 页表索引、2 页内偏移</strong>，只有一级页目录，其中包含 1024 个条目。其中一个条目指向一个物理页，每个物理页 4MB，正好为 4GB 地址空间(4096MB=4GB)，如下图所示。</p><blockquote><p>同样道理, 4MB=4194304bit -&gt; 2<sup>22</sup>. 页内偏移对应22位.</p></blockquote><img src="'+m+'" alt="img" style="zoom:15%;"><p>保护模式下的4MB分页</p><p>CR3 还是 32 位的寄存器，只不过不再指向顶级页目录了，而是指向一个 4KB 大小的页表，这个页表依然要 4KB 地址对齐，其中包含 1024 个页表项，格式如下图。</p><ul><li>CR3(页表物理基址) + <code>[虚拟地址 1 页表索引]</code> -&gt; 页表项 / 4MB物理页的基址</li><li>因为CR3+页表索引, 找到的是4KB的页表, 因此仍然页表物理基址20位.(剩下是这4KB页面的页内偏移, 12位)</li><li>页表项(4MB物理页的基址) + <code>[虚拟地址 2 页内偏移]</code> -&gt; 目标位置</li></ul><img src="'+g+'" alt="img" style="zoom:15%;"><p>可以发现，4MB 大小的页面下，<strong>页表项还是 4 字节 32 位，但只需要用高 10 位来保存物理页面的基地址就可以</strong>。因为每个物理页面都是 4MB，所以低 22 位始终为 0，为了兼容 4MB 页表项低 8 位和 4KB 页表项一样，只不过第 7 位变成了 PS 位，且必须为 1，而 PAT 位移到了 12 位。</p><h2 id="_64位-长模式下的分页" tabindex="-1"><a class="header-anchor" href="#_64位-长模式下的分页" aria-hidden="true">#</a> 64位-长模式下的分页</h2><p>如果开启了长模式，<strong>则必须同时开启分页模式</strong>，因为长模式弱化了分段模型，而分段模型也确实有很多不足，不适应现在操作系统和应用软件的发展。</p><p>同时，<strong>长模式也扩展了 CPU 的位宽</strong>，使得 CPU 能使用 64 位的超大内存地址空间。所以，<strong>长模式下的虚拟地址必须等于线性地址且为 64 位</strong>。</p><p>长模式下的分页大小通常也有两种，4KB 大小的页和 2MB 大小的页。</p><h3 id="_1-长模式下的分页——4kb-页" tabindex="-1"><a class="header-anchor" href="#_1-长模式下的分页——4kb-页" aria-hidden="true">#</a> 1 长模式下的分页——4KB 页</h3><p>该分页方式下，64 位虚拟地址被分为 6 个位段，分别是：<strong>1 保留位段，2 顶级页目录索引、3 页目录指针索引、4 页目录索引、5 页表索引、6 页内偏移</strong>，</p><ul><li>顶级页目录、页目录指针、页目录、页表各占有 4KB 大小，</li><li>其中各有 512 个条目，每个条目 8 字节 64 位大小，如下图所示。</li></ul><img src="'+l+'" alt="img" style="zoom:15%;"><p>长模式下的4KB分页</p><p>上面图中 <mark>CR3</mark> 已经变成 64 位的 CPU 的寄存器，它指向一个<mark>顶级页目录</mark>，里面的<mark>顶级页目项</mark>指向<mark>页目录(表)指针</mark>，依次类推。</p><p>需要注意的是，虚拟地址 48 到 63 这 16 位是根据<strong>第 47 位</strong>来决定的，47 位为 1，它们就为 1，反之为 0，这是因为 x86 CPU 并没有实现全 64 位的<code>地址总线</code>，而是只实现了 48 位，但是 CPU 的寄存器却是 64 位的。</p><blockquote><p>这种最高有效位填充的方式，即使后面扩展 CPU 的地址总线也不会有任何影响，</p></blockquote><p>下面我们去看看当前分页模式下的 CR3、顶级页目录项、页目录指针项、页目录项、页表项的格式，我画了一张图帮你理解。</p><ul><li>(按理来说)51位置应为48, 这是因为设计上多插入了3个状态位或描述位?</li></ul><img src="'+b+'" alt="img" style="zoom:15%;"><p>由上图可知，长模式下的 4KB 分页下，由<strong>一个顶层目录、二级中间层目录, 和一层页表</strong>组成了 64 位地址翻译过程。</p><p>顶级页目录项指向页目录指针页，页目录指针项指向页目录页，页目录项指向页表页，页表项指向一个 4KB 大小的物理页，各级页目录项中和页表项中依然存在各种属性位，这在图中已经说明。<strong>其中的 <code>XD 位</code>，可以控制代码页面是否能够运行。</strong></p><h3 id="_2-长模式下的分页——2mb-页" tabindex="-1"><a class="header-anchor" href="#_2-长模式下的分页——2mb-页" aria-hidden="true">#</a> 2 长模式下的分页——2MB 页</h3><p>在这种分页方式下，64 位虚拟地址被分为 5 个位段 ：<strong>1 保留位段、2 顶级页目录索引、3 页目录指针索引、4 页目录索引，5 页内偏移</strong>，</p><p>顶级页目录、页目录指针、页目录各占有 4KB 大小，其中各有 512 个条目，每个条目 8 字节 64 位大小。</p><img src="'+M+'" alt="img" style="zoom:15%;"><p>长模式下的2MB分页</p><p>可以发现，长模式下 2MB 和 4KB 分页的区别是，2MB 分页下是页目录项直接指向了 2MB 大小的物理页面，放弃了<strong>页表项</strong>，然后把虚拟地址的低 21 位作为页内偏移，21 位正好索引 2MB 大小的地址空间。</p><blockquote><p>2MB的物理页面可以分成2<sup>21</sup>B部分.</p></blockquote><p>下面我们还是要去看看 2MB 分页模式下的 CR3、顶级页目录项、页目录指针项、页目录项的格式，格式如下图。</p><img src="'+u+`" alt="img" style="zoom:15%;"><p>上图中没有了页表项，取而代之的是，页目录项中直接存放了 2MB 物理页基地址。<strong>由于物理页始终 2MB 对齐，所以其地址的低 21 位为 0，用于存放页面属性位。</strong></p><h2 id="开启-mmu" tabindex="-1"><a class="header-anchor" href="#开启-mmu" aria-hidden="true">#</a> 开启 MMU</h2><p>要使用分页模式就必先开启 MMU，但是开启 MMU 的前提是 CPU 进入保护模式或者长模式，开启 CPU 这两种模式的方法，我们在前面第五节课已经讲过了，下面我们就来开启 MMU，步骤如下：</p><p>\\1. 使 CPU 进入保护模式或者长模式。</p><p>\\2. 准备好页表数据，这包含顶级页目录，中间层页目录，页表，假定我们已经编写了代码，在物理内存中生成了这些数据。</p><p>\\3. 把顶级页目录的物理内存地址赋值给 CR3 寄存器。</p><div class="language-c line-numbers-mode" data-ext="c"><pre class="language-c"><code>mov eax<span class="token punctuation">,</span> PAGE_TLB_BADR <span class="token punctuation">;</span>页表物理地址
mov cr3<span class="token punctuation">,</span> eax
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>\\4. 设置 CPU 的 CR0 的 PE 位为 1，这样就开启了 MMU。</p><div class="language-c line-numbers-mode" data-ext="c"><pre class="language-c"><code><span class="token punctuation">;</span>开启 保护模式和分页模式
mov eax<span class="token punctuation">,</span> cr0
bts eax<span class="token punctuation">,</span> <span class="token number">0</span>    <span class="token punctuation">;</span>CR0<span class="token punctuation">.</span>PE <span class="token operator">=</span><span class="token number">1</span>
bts eax<span class="token punctuation">,</span> <span class="token number">31</span>   <span class="token punctuation">;</span>CR0<span class="token punctuation">.</span>P <span class="token operator">=</span> <span class="token number">1</span>
mov cr0<span class="token punctuation">,</span> eax 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="mmu-地址转换失败" tabindex="-1"><a class="header-anchor" href="#mmu-地址转换失败" aria-hidden="true">#</a> MMU 地址转换失败</h2><p>MMU 的主要功能是根据页表数据把虚拟地址转换成物理地址，但有没有可能转换失败？</p><p>绝对有可能，例如，页表项中的数据为空，用户程序访问了超级管理者的页面，向只读页面中写入数据。这些都会导致 MMU 地址转换失败。</p><p>MMU 地址转换失败了怎么办呢？失败了既不能放行，也不是 reset，MMU 执行的操作如下。</p><p>1.MMU 停止转换地址。</p><p>2.MMU 把转换失败的虚拟地址写入 CPU 的 CR2 寄存器。</p><p>3.MMU 触发 CPU 的 14 号中断，使 CPU 停止执行当前指令。</p><p>4.CPU 开始执行 14 号中断的处理代码，代码会检查原因，处理好页表数据返回。</p><p>5.CPU 中断返回继续执行 MMU 地址转换失败时的指令。</p><blockquote><p>这里你只要先明白这个流程就好了，后面课程讲到内存管理的时候我们继续探讨。</p></blockquote><h2 id="重点回顾" tabindex="-1"><a class="header-anchor" href="#重点回顾" aria-hidden="true">#</a> 重点回顾</h2><p>又到了课程的尾声，把心情放松下来，我们一起来回顾这节课的重点。</p><p>首先，我们从一个场景开始热身，发现多道程序同时运行有很多问题，都是内存相关的问题，内存需要<strong>隔离和保护</strong>。从而提出了虚拟地址与物理地址分离，让应用程序从实际的物理内存中解耦出来。</p><p>虽然虚拟地址是个非常不错的方案，但是虚拟地址必须转换成物理地址，才能在硬件上执行。为了执行这个转换过程，才开发出了 <mark>MMU（内存管理单元）</mark>，MMU<strong>增加了转换的灵活性</strong>，它的实现方式是**<code>硬件</code>执行转换过程，但又依赖于<code>软件</code>提供的地址转换表。**</p><p>最后，我们下落到具体的硬件平台，研究了 x86 CPU 上的 MMU。</p><p>x86 CPU 上的 MMU 在其保护模式和长模式下提供 4KB、2MB、4MB 等页面转换方案，我们详细分析了它们的<strong>页表格式</strong>。同时，也搞清楚了<strong>如何开启 MMU，以及 MMU 地址转换失败后执行的操作。</strong></p><h2 id="思考题" tabindex="-1"><a class="header-anchor" href="#思考题" aria-hidden="true">#</a> 思考题</h2><p>在分页模式下，操作系统是如何对应用程序的地址空间进行隔离的？</p><p>欢迎你在留言区和我交流互动。如果这节课对你有启发的话，也欢迎你转发给朋友、同事，说不定就能帮他解决疑问。</p><p>我是 LMOS，我们下节课见！</p><h2 id="课后讨论" tabindex="-1"><a class="header-anchor" href="#课后讨论" aria-hidden="true">#</a> 课后讨论</h2><p>又是信息量爆炸的一节，不过读下来也是挺爽的。这里我替很多同学说明一下，虚拟地址中的<code>页内偏移</code>才是决定<code>页大小</code>和<code>多级目录</code>的核心点，**页内偏移必须与页大小保持一致，这样才能保证寻址可以找到页内的每一个地址。**对于思考题，其实也比较简单，文中也谈到了，实模式下多个任务共享所有地址空间太危险，因此才有了保护模式，保护模式下的分页模式是一个巨大的创新。 对于每个进程而言，它会误认为(被操作系统欺骗)自己独有所有地址空间，因此它访问地址是不会考虑任何问题的，可是这个地址是虚拟地址，待被MMU翻译后会得到对应的页表，<strong>而这个页表由操作系统管理，不同的进程拥有不同的页表，也因此产生了进程地址空间隔离，但是多个进程也是可以共享某个页表，这也是进程通信(IPC)的根本手段。</strong></p><hr><p>配合之前的现代操作系统的学习有一些收获不知道对或不对<br> 虚拟内存实际上是存储器地址空间抽象的一种实现。从进程的角度看起来就好像自己独占了整个内存，<mark>链接器</mark>链接编译产物的时候只需要从0地址开始做变量和函数地址的替换，不需要关心自己是否会把其他进程的内存单元给污染。<strong>地址空间是进程可以访问的所有内存单元的集合</strong><br><mark>而虚拟内存的实现带来的好处主要有</mark><br> 1.利用程序的局部性原理，使用时间换空间，通过不断地淘汰/加载页表项就可以模拟出巨大的内存。<br> 2.使用mmu并行计算的能力，减少了基址寄存器和界限寄存器的add和compare操作。<br><mark>但是软件开发是没有银弹的，虚拟内存同时也带来了一些实现上的挑战</mark><br> 1.从虚拟内存到物理内存的映射必须要尽可能快，不然访存的时候反而会成为指令执行速度的瓶颈，这点现代操作系统大多通过在内核中维护一个<strong>tlb</strong>做<code>页表-页框的映射缓存</code>表来实现，这里是空间换时间。<br> 2.随着虚拟内存的增加，比如要表示4GB的虚拟内存，以4KB的页面大小为例，共需要4GB/4KB= <code>2^20</code>,而每个页表项需要32位即是4个字节大小，一个进程的页表总共为<code>2^20*4</code> = 4194304（字节） = 4MB。<br> 假设4核cpu同时运行不同的进程，操作系统在内核中至少需要维护16MB的页表。看起好像很小对不对，大家可以尝试按64位内存总线去换算。所以为了避免一次性加载大量页表到内存中，会采用<strong>多级页表</strong>策略。如老师文中描述的，一次只加载一级页表到内存中，并且可以选择淘汰上一级页表，<code>通过多次映射的方法来避免大页表</code>，到这里又是时间换空间了。<br> 而对于老师说的，mmu无法映射物理地址时，有几种原因<br> 1.访问了受内核保护的页面，或者访问了只读的页面（比如c语言中存储字符串字面量和const变量的段），此时内核会抛出段错误<br> 2.页面和页框没有产生映射关系，但是数据页已经被其他进程加载到内存中了，此时只需要建立页面和页框的映射关系，称为<strong>次级缺页中断</strong><br> 3.页面和页框没有产生映射关系，数据页也没有被加载到内存中（在磁盘上），此时需要发生磁盘io从磁盘中加载页到内存中，还需要建立页面和页框的映射关系，称为<strong>严重缺页中断</strong>。<br> 除了第一点，第二第三都会以内核降低自身运行速度来修复，也就是老师说的，<strong>通过中断形成页表映射</strong>，然后再重新执行引起中断的命令（此时数据页已经在内存中并且建立映射关系了）。</p><hr><p>多个进程隔离应该是操作系统进行任务切换时会改写<mark>CPU的页表基地址寄存器</mark>为当前被运行进程的页表基地址吧！</p><hr><p>有个疑问，现代CPU都是多核的，那么一个4核的CPU是共享一个MMU，还是每个核心都有自己的MMU，有4个MMU呢？<br> 作者回复: 都 有自己的</p><hr><p>我的理解就是多级页表，从第一个跳到最后一个。最后的页内偏移对应了我们所说的4KB/2MB/4MB页表。可以配合《深入理解计算机系统》第9章以及youtube上老师的讲解进行观看。<br> 作者回复: 嗯嗯 理解不错</p><hr><p>细节太多,之前没有接触过比较难以理解,先抓大的,三种模式出现的原因和解决的问题,后续用到再回来深挖细节.<br> 本节收获:<br><mark>实模式(16位处理能力+20位地址线---&gt;1MB)</mark><br> 早期cpu是为了支持单道程序而实现的,单道程序可以掌控所有的计算资源.<br> 并且早期软件规模不大,内存资源很少,仅支持16位地址空间,分段的内存模型.<br> 对指令不加限制地允许,对内存没有保护隔离作用<br><mark>保护模式(32位处理能力)</mark><br> 多道程序的出现,内存需求量不断增加,需要操作系统来协调.<br> 保护模式包含特权级,对指令以及访问的资源进行控制---&gt;段与段之间的访问和中断的响应<br><mark>长模式(64位处理能力)</mark><br> 弱化段化模式管理,忽略段基址和段长度.<br> 保留权限级别的检查,地址检查交给MMU.<br><mark>为什么长模式弱化分段:</mark><br> 分段是将用户程序地址空间分成若干个<strong>大小不等</strong>的段,能反映程序的<strong>逻辑结构</strong>，便于段的<strong>共享与保护</strong>.<br> 分页是将用户程序的地址空间被划分成若干<strong>固定大小</strong>的区域,能有效地提高<strong>内存的利用率</strong>.<br> 分段和分页的区别在于粒度更细了,让程序的换入换出可以<strong>以页为单位</strong>了.</p>`,157),U=[k];function B(f,_){return a(),s("div",null,U)}const C=r(h,[["render",B],["__file","C06-MMU虚拟地址转换.html.vue"]]);export{C as default};
