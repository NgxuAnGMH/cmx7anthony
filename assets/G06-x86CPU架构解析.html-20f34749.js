import{_ as o}from"./plugin-vue_export-helper-c27b6911.js";import{r as d,o as c,c as t,a as e,b as a,e as p,d as i}from"./app-cdabc73c.js";const s="/assets/fa6c2b6166d02ac37637d7da4e4b579b-58bfaf4e.jpeg",n="/assets/3afda18fc38e7e53604e9ebf9cb42023-c6c11977.jpeg",h="/assets/548dfd163066d061d1e882c73e7c2b8a-ffa2f9f0.jpg",l="/assets/2dc8237e996e699a0361a6b5ffd4871c-6d5c5910.jpeg",m="/assets/08ea4adb633f114d788d5c6a9dae0f47-63c8f917.jpeg",g="/assets/e3f4f64e6dfe5591b7d8ef346e8e8884-0709d9d6.jpeg",k="/assets/b40a64dd5ca1dc1efd8957525e904634-d0232dac.jpg",u="/assets/ab203e85dd8468051eca238c3ebd81f7-c1399690.jpg",b="/assets/d08ec3163c80a5dd94e488a71588f8a4-47b55d93.jpg",C="/assets/e2e92f2239fe9b4c024d300046536d76-eba5df07.jpeg",S={},x=i('<h1 id="_06-x86架构-有了开放的架构-才能打造开放的营商环境" tabindex="-1"><a class="header-anchor" href="#_06-x86架构-有了开放的架构-才能打造开放的营商环境" aria-hidden="true">#</a> 06 | x86架构：有了开放的架构，才能打造开放的营商环境</h1><p>做生意的人最喜欢开放的营商环境，也就是说，我的这家公司，只要符合国家的法律，到哪里做生意，都能受到公平的对待，这样就不用为了适配各个地方的规则煞费苦心，只要集中精力优化自己的服务就可以了。</p><p>作为 Linux 操作系统，何尝不是这样。如果下面的硬件环境千差万别，就会很难集中精力做出让用户易用的产品。毕竟天天适配不同的平台，就已经够头大了。<code>x86 架构就是这样一个开放的平台</code>。今天我们就来解析一下它。</p><h2 id="计算机的工作模式是什么样的" tabindex="-1"><a class="header-anchor" href="#计算机的工作模式是什么样的" aria-hidden="true">#</a> 计算机的工作模式是什么样的？</h2><p>还记得咱们攒电脑时买的那堆硬件吗？虽然你可以根据经验，把那些复杂的设备和连接线安装起来，但是你真的了解它们为什么要这么连接吗？</p><p>现在我就把硬件图和计算机的逻辑图对应起来，带你看看计算机的工作模式。</p><img src="'+s+'" alt="img" style="zoom:25%;"><h3 id="cpu" tabindex="-1"><a class="header-anchor" href="#cpu" aria-hidden="true">#</a> CPU</h3><p>对于一个计算机来讲，最核心的就是 <strong><mark>CPU</mark></strong>（Central Processing Unit，<code>中央处理器</code>）。这是这台计算机的大脑，所有的设备都围绕它展开。</p><p>对于公司来说，CPU 是真正干活的，将来执行项目都要靠它。</p><p>CPU 就相当于咱们公司的程序员，我们常说，二十一世纪最缺的是什么？是人才！所以，大量水平高、干活快的程序员，才是营商环境中最重要的部分。</p><h3 id="io桥芯片" tabindex="-1"><a class="header-anchor" href="#io桥芯片" aria-hidden="true">#</a> IO桥芯片</h3><p>CPU实质上只与IO桥芯片交互? 通过汇合而成的统一系统总线. 而IO桥芯片与各种 内存总线, IO总线 等相连.</p><h3 id="总线-系统-内存-i-o" tabindex="-1"><a class="header-anchor" href="#总线-系统-内存-i-o" aria-hidden="true">#</a> 总线 - 系统 内存 I/O</h3><p>CPU 和其他设备连接，要靠一种叫做==<strong>总线</strong>（Bus）<mark>的东西，其实就是主板上密密麻麻的集成电路，这些东西组成了 <code>CPU</code> 和<code>其他设备</code>的</mark>高速通道==。</p><h3 id="内存" tabindex="-1"><a class="header-anchor" href="#内存" aria-hidden="true">#</a> 内存</h3><p>在这些设备中，最重要的是==<strong>内存</strong>（Memory）==。因为单靠 CPU 是没办法完成计算任务的，很多复杂的计算任务都需要将<code>中间结果</code>保存下来，然后基于中间结果<code>进行进一步的计算</code>。CPU 本身没办法保存这么多中间结果，<code>这就要依赖内存了</code>。</p><p>内存就相当于办公室，我们要看看方不方便租到办公室，有没有什么创新科技园之类的。有了共享的、便宜的办公位，公司就有注册地了。</p><h3 id="总线上的设备驱动" tabindex="-1"><a class="header-anchor" href="#总线上的设备驱动" aria-hidden="true">#</a> 总线上的设备驱动</h3><p>当然总线上还有一些其他设备，例如<mark>显卡</mark>会连接显示器、<mark>磁盘控制器</mark>会连接硬盘、<mark>USB 控制器</mark>会连接键盘和鼠标等等。</p><h2 id="cpu-内存" tabindex="-1"><a class="header-anchor" href="#cpu-内存" aria-hidden="true">#</a> CPU &lt;-&gt; 内存==+++==</h2><p>CPU 和内存是完成计算任务的核心组件，所以这里我们重点介绍一下 <strong>CPU 和内存是如何配合工作的</strong>。</p><p>CPU 其实也不是单纯的一块，它包括三个部分，<mark>运算单元</mark>、<mark>数据单元</mark>和<mark>控制单元</mark>。</p><h3 id="运算单元-做操作-专心操作及运算" tabindex="-1"><a class="header-anchor" href="#运算单元-做操作-专心操作及运算" aria-hidden="true">#</a> 运算单元 - 做操作 - 专心操作及运算</h3><p>**<mark>运算单元</mark>**只管算，例如<code>做加法、做位移等等</code>。但是，它不知道应该算哪些数据，运算结果应该放在哪里。</p><h3 id="数据单元-数据段-通用数据寄存器" tabindex="-1"><a class="header-anchor" href="#数据单元-数据段-通用数据寄存器" aria-hidden="true">#</a> 数据单元 - 数据段 - 通用数据寄存器</h3><p>运算单元计算的数据如果每次都要经过总线，到内存里面现拿，这样就太慢了，所以就有了**<mark>数据单元</mark>**。</p><ul><li>数据单元包括 <strong>CPU 内部</strong>的==<strong>缓存</strong><mark>和</mark><strong>寄存器组</strong>==，空间很小，但是速度飞快，<code>可以暂时存放数据和运算结果</code>。</li></ul><h3 id="控制单元-代码段-指令指针寄存器" tabindex="-1"><a class="header-anchor" href="#控制单元-代码段-指令指针寄存器" aria-hidden="true">#</a> 控制单元 - 代码段 - 指令指针寄存器</h3><p>有了放数据的地方，也有了算的地方，还需要有个指挥到底做什么运算的地方，这就是**<mark>控制单元</mark>**。</p><ul><li>控制单元是一个<code>统一的指挥中心</code>，它可以获得下一条指令，然后执行这条指令。</li><li>这个指令会指导<code>运算单元</code>取出<code>数据单元</code>中的某几个数据，计算出个结果，然后放在<code>数据单元</code>的某个地方。</li></ul><h3 id="图示说明" tabindex="-1"><a class="header-anchor" href="#图示说明" aria-hidden="true">#</a> +++ 图示说明</h3><img src="'+n+'" alt="img" style="zoom:25%;"><h2 id="工作流程-执行指令" tabindex="-1"><a class="header-anchor" href="#工作流程-执行指令" aria-hidden="true">#</a> 工作流程 - 执行指令==+++==</h2><p>每个项目(<code>应用</code>)都有一个项目执行计划书(<code>本地文件中的代码程序</code>)，里面是一行行项目执行的指令(<code>一行行代码</code>)，这些都是放在档案库(<code>文件管理系统</code>)里面的。每个进程(<code>开启的活动实体</code>)都有一个程序(<code>经编译而成的可执行文件</code>)放在硬盘上，是二进制的，再里面就是一行行的指令，会操作一些数据。</p><h3 id="vas-数据段-代码段-load" tabindex="-1"><a class="header-anchor" href="#vas-数据段-代码段-load" aria-hidden="true">#</a> (VAS) 数据段 / 代码段 - LOAD</h3><p>进程一旦运行，比如图中两个进程 A 和 B，会有独立的内存空间(<code>VAS虚拟地址空间</code>)，互相隔离，程序会分别加载到进程 A 和进程 B 的内存空间里面，形成各自的<code>代码段</code>。当然真实情况肯定比我说的要复杂的多，进程的内存虽然隔离<code>但不连续</code>，除了简单的区分<code>代码段</code>和<code>数据段</code>，还会<code>分得更细</code>。</p><p>程序运行的过程中要操作的数据和产生的计算结果，都会放在<code>数据段</code>里面。<strong>那 CPU 怎么执行这些程序，操作这些数据，产生一些结果，并写入回内存呢？</strong></p><h3 id="控制单元-代码段-指令指针寄存器-1" tabindex="-1"><a class="header-anchor" href="#控制单元-代码段-指令指针寄存器-1" aria-hidden="true">#</a> 控制单元 - 代码段 - 指令指针寄存器</h3><p>CPU 的<code>控制单元</code>里面，有一个**<mark>指令指针寄存器</mark><strong>，它里面存放的是<code>下一条指令</code>在内存中的地址。<code>控制单元</code>会不停地将<code>代码段</code>的指令拿进来，先放入</strong><mark>指令寄存器</mark>**。</p><p>当前的指令分两部分，<strong>一部分是做什么操作</strong>，例如是加法还是位移；<strong>一部分是操作哪些数据</strong>。</p><p>要执行这条指令，就要把第一部分交给<code>运算单元</code>，第二部分交给<code>数据单元</code>。</p><h3 id="运算单元-做操作-专心操作及运算-1" tabindex="-1"><a class="header-anchor" href="#运算单元-做操作-专心操作及运算-1" aria-hidden="true">#</a> 运算单元 - 做操作 - 专心操作及运算</h3><p>代码 &amp; 数据 = 指令 &amp; 变量</p><p>之间就是要进行操作及运算</p><h3 id="数据单元-数据段-通用数据寄存器-1" tabindex="-1"><a class="header-anchor" href="#数据单元-数据段-通用数据寄存器-1" aria-hidden="true">#</a> 数据单元 - 数据段 - 通用数据寄存器</h3><p><code>数据单元</code>根据数据的地址，从<code>数据段</code>里读到**<mark>数据寄存器</mark><strong>里，就可以参与运算了。运算单元做完运算，产生的结果会暂存在<code>数据单元</code>的</strong><mark>数据寄存器</mark>**里。最终，会有指令将数据写回内存中的<code>数据段</code>。</p><h3 id="进程切换-保存必要数据-段寄存器" tabindex="-1"><a class="header-anchor" href="#进程切换-保存必要数据-段寄存器" aria-hidden="true">#</a> 进程切换 - 保存必要数据 - 段寄存器</h3><p>你可能会问，上面算来算去执行的都是进程 A 里的指令，那进程 B 呢？CPU 里有两个寄存器，专门保存<strong>当前处理进程</strong>的<code>代码段</code>的起始地址，以及<code>数据段</code>的起始地址。这里面写的都是进程 A，那当前执行的就是进程 A 的指令，等切换成进程 B，就会执行 B 的指令了，这个过程叫作**<code>进程切换</code>**（Process Switch）。这是一个<code>多任务系统</code>的必备操作，我们后面有专门的章节讲这个内容，这里你先有个印象。</p><blockquote><p>如果需要切换进程呢？每个进程都分<mark>代码段</mark>和<mark>数据段</mark>，为了指向不同进程的地址空间，有四个 16 位的==<strong>段</strong>寄存器==，分别是 <code>CS、DS、SS、ES</code>。</p><ul><li><p>其中，<mark>CS</mark> 就是==<strong>代码段</strong>寄存器（Code Segment Register）==，通过它可以找到<code>代码在内存中的位置</code>；<br> 代码段起始地址, 偏移量在控制单元中</p></li><li><p><mark>DS</mark> 是==<strong>数据段</strong>的寄存器==，通过它可以找到<code>数据在内存中的位置</code>。<br> 数据段起始地址, 偏移量在数据单元中</p></li><li><p><mark>SS</mark> 是==<strong>栈</strong>寄存器（Stack Register）==。栈是<code>程序运行中</code>一个特殊的数据结构，<br> 存取只能从一端进行，秉承后进先出的原则，push 就是入栈，pop 就是出栈。</p></li></ul></blockquote><blockquote><p>进程上下文:</p><ol><li>[进程的起始地址] 寄存器1 代码段 / 寄存器2 数据段</li><li>当前PC程序计数器</li><li>【通用】【状态】等寄存器的值</li><li>用户栈</li><li>内核栈</li><li>内核管理的数据结构</li><li>内存中的一些内容</li></ol><p>等等</p></blockquote><h3 id="来来回回-地址总线-数据总线" tabindex="-1"><a class="header-anchor" href="#来来回回-地址总线-数据总线" aria-hidden="true">#</a> 来来回回 - 地址总线 &amp; 数据总线</h3><p>到这里，你会发现，<code>CPU</code> 和<code>内存</code>来来回回传数据，靠的都是总线。其实总线上主要有两类数据，</p><ul><li>一个是地址数据，也就是我想拿内存中哪个位置的数据，这类总线叫==<strong>地址总线</strong>（Address Bus）==；</li><li>另一类是真正的数据，这类总线叫==<strong>数据总线</strong>（Data Bus）==。</li></ul><p>所以说，总线其实有点像连接 <code>CPU</code> 和<code>内存</code>这两个设备的<code>高速公路</code>，说总线到底是多少位，就类似说高速公路有几个车道。但是这两种总线的位数意义是不同的。</p><h4 id="地址总线-cpu访问内存时的范围大小" tabindex="-1"><a class="header-anchor" href="#地址总线-cpu访问内存时的范围大小" aria-hidden="true">#</a> ## 地址总线 - CPU访问内存时的范围大小</h4><p><code>地址总线的位数</code>，决定了能访问的地址范围到底有多广。</p><ul><li>例如只有两位，那 CPU 就只能认 00，01，10，11 四个位置，超过四个位置，就区分不出来了。</li><li>位数越多，<strong>CPU 能够访问的位置就越多</strong>，能管理的内存的范围也就越广。</li></ul><h4 id="数据总线-cpu从内存可读取数据大小" tabindex="-1"><a class="header-anchor" href="#数据总线-cpu从内存可读取数据大小" aria-hidden="true">#</a> ## 数据总线 - CPU从内存可读取数据大小</h4><p><code>而数据总线的位数</code>，决定了一次能拿多少个数据进来。</p><ul><li>例如只有两位，那 CPU 一次只能从内存拿两位数。要想拿八位，就要拿四次。</li><li>位数越多，<strong>CPU 一次拿的数据就越多</strong>，访问速度也就越快。</li></ul><h2 id="x86架构-成为开放平台历史中的重要一笔" tabindex="-1"><a class="header-anchor" href="#x86架构-成为开放平台历史中的重要一笔" aria-hidden="true">#</a> <strong>x86架构 成为开放平台历史中的重要一笔</strong></h2><p>那 CPU 中总线的位数有没有个标准呢？如果没有标准，那操作系统作为软件就很难办了，因为软件层没办法实现通用的运算逻辑。这就像很多非标准的元器件一样，你烧你的电路板，我烧我的电路板，谁都不能用彼此的。</p><h3 id="cpu总线位数-需要统一标准" tabindex="-1"><a class="header-anchor" href="#cpu总线位数-需要统一标准" aria-hidden="true">#</a> CPU总线位数/需要统一标准</h3><p>早期的 IBM 凭借大型机技术成为计算机市场的领头羊，直到后来个人计算机兴起，苹果公司诞生。但是，那个时候，无论是大型机还是个人计算机，每家的 CPU 架构都不一样。如果一直是这样，个人电脑、平板电脑、手机等等，都没办法形成统一的体系，就不会有我们现在通用的计算机了，更别提什么云计算、大数据这些统一的大平台了。</p><p>好在历史将 <mark>x86 平台</mark>推到了**<code>开放、统一、兼容</code>**的位置。我们继续来看 IBM 和 x86 的故事。</p><p>IBM 开始做 IBM PC 时，一开始并没有让最牛的华生实验室去研发，而是交给另一个团队。一年时间，软硬件全部自研根本不可能完成，于是他们采用了英特尔的 8088 芯片作为 CPU，使用微软的 MS-DOS 做操作系统。</p><p>谁能想到 IBM PC 卖得超级好，好到因为垄断市场而被起诉。IBM 就在被逼的情况下公开了一些技术，使得后来无数 IBM-PC 兼容机公司的出现，也就有了后来占据市场的惠普、康柏、戴尔等等。</p><h3 id="标准-开放-兼容" tabindex="-1"><a class="header-anchor" href="#标准-开放-兼容" aria-hidden="true">#</a> 标准/开放/兼容</h3><p>能够开放自己的技术是一件了不起的事。从技术和发展的层面来讲，它会使得一项技术大面积铺开，<strong><code>形成行业标准</code></strong>。就比如现在常用的 Android 手机，如果没有开放的 Android 系统，我们也没办法享受到这么多不同类型的手机。</p><p>对于当年的 PC 机来说，其实也是这样。英特尔的技术因此成为了行业的开放事实标准。由于这个系列开端于 8086，因此称为 <code>x86 架构</code>。</p><p>后来英特尔的 CPU 数据总线和地址总线越来越宽，处理能力越来越强。但是一直不能忘记三点，<strong><code>一是标准，二是开放，三是兼容</code></strong>。因为要想如此大的一个软硬件生态都基于这个架构，符合它的标准，如果是封闭或者不兼容的，那谁都不答应。</p><img src="'+h+'" alt="img" style="zoom:25%;"><p>说完了 x86 的历史，我们再来看 x86 中最经典的一款处理器，8086 处理器。虽然它已经很老了，但是咱们现在操作系统中的很多特性都和它有关，并且一直保持兼容。</p><blockquote><p>8086 是 16 位操作系统（实模式）</p><p>80386 是 32 位操作系统（保护模式）</p><p>原来 x86 架构是指 8086 ，而 x86 是代表 32 位操作系统是因为 80386，原来这两个 x86 不是同一个意思啊</p></blockquote><h2 id="x86架构-cpu-内部详细组成" tabindex="-1"><a class="header-anchor" href="#x86架构-cpu-内部详细组成" aria-hidden="true">#</a> x86架构 CPU 内部详细组成</h2><p>我们把 CPU 里面的组件放大之后来看。你可以看我画的这幅图。</p><img src="'+l+'" alt="img" style="zoom:25%;"><h3 id="数据单元-通用寄存器-数据段偏移量" tabindex="-1"><a class="header-anchor" href="#数据单元-通用寄存器-数据段偏移量" aria-hidden="true">#</a> 数据单元 - 通用寄存器 - 数据段偏移量</h3><p>我们先来看数据单元。</p><p>为了暂存数据，8086 处理器内部有 8 个 16 位的<mark>通用寄存器</mark>，也就是刚才说的 CPU 内部的数据单元，分别是 <code>AX、BX、CX、DX、SP、BP、SI、DI</code>。这些寄存器主要用于<code>在计算过程中暂存数据</code>。</p><p>这些寄存器比较灵活，其中 <code>AX、BX、CX、DX</code> 可以分成两个 8 位的寄存器来使用，分别是 <code>AH、AL、BH、BL、CH、CL、DH、DL</code>，其中 H 就是 <mark>High（高位）</mark>，L 就是 ==Low（低位）==的意思。</p><p>这样，比较长的数据也能暂存，比较短的数据也能暂存。你可能会说 16 位并不长啊，你可别忘了，那是在计算机刚刚起步的时代。</p><h3 id="控制单元-ip-寄存器-代码段偏移量" tabindex="-1"><a class="header-anchor" href="#控制单元-ip-寄存器-代码段偏移量" aria-hidden="true">#</a> 控制单元 - IP 寄存器 - 代码段偏移量</h3><p>接着我们来看控制单元。</p><p><mark>IP 寄存器</mark>就是<mark>指令指针寄存器（Instruction Pointer Register)</mark>，指向代码段中下一条指令的位置。CPU 会根据它来不断地将指令从内存的代码段中，加载到 CPU 的指令队列中，然后交给运算单元去执行。</p><h3 id="段寄存器-代码段-数据段-栈-起始地址" tabindex="-1"><a class="header-anchor" href="#段寄存器-代码段-数据段-栈-起始地址" aria-hidden="true">#</a> 段寄存器 - 代码段/数据段/栈 - 起始地址</h3><p>如果需要切换进程呢？每个进程都分<mark>代码段</mark>和<mark>数据段</mark>，为了指向不同进程的地址空间，有四个 16 位的==<strong>段</strong>寄存器==，分别是 <code>CS、DS、SS、ES</code>。</p><ul><li><p>其中，<mark>CS</mark> 就是==<strong>代码段</strong>寄存器（Code Segment Register）==，通过它可以找到<code>代码在内存中的位置</code>；<br> 代码段起始地址, 偏移量在控制单元中</p></li><li><p><mark>DS</mark> 是==<strong>数据段</strong>的寄存器==，通过它可以找到<code>数据在内存中的位置</code>。<br> 数据段起始地址, 偏移量在数据单元中</p></li><li><p><mark>SS</mark> 是==<strong>栈</strong>寄存器（Stack Register）==。栈是<code>程序运行中</code>一个特殊的数据结构，<br> 存取只能从一端进行，秉承后进先出的原则，push 就是入栈，pop 就是出栈。</p></li></ul><img src="'+m+'" alt="img" style="zoom:25%;"><p><code>凡是与函数调用相关的操作，都与栈紧密相关。</code>例如，A 调用 B，B 调用 C。当 A 调用 B 的时候，要执行 B 函数的逻辑，因而 A 运行的相关信息就会被 push 到栈里面。当 B 调用 C 的时候，同样，B 运行相关信息会被 push 到栈里面，然后才运行 C 函数的逻辑。当 C 运行完毕的时候，先 pop 出来的是 B，B 就接着调用 C 之后的指令运行下去。B 运行完了，再 pop 出来的就是 A，A 接着运行，直到结束。</p><h3 id="内存加载到cpu中-准备执行-的过程" tabindex="-1"><a class="header-anchor" href="#内存加载到cpu中-准备执行-的过程" aria-hidden="true">#</a> 内存加载到CPU中(准备执行) 的过程</h3><p>如果运算中需要加载内存中的数据，需要通过 <mark>DS(<strong>数据段寄存器</strong>)</mark> 找到内存中的数据，加载到<mark>通用寄存器</mark>中，应该如何加载呢？</p><blockquote><p>对于一个段，有一个**<code>起始的地址</code><strong>，而段内的具体位置，我们称为</strong><code>偏移量</code>**（Offset）。</p><p>例如 8 号会议室的第三排，8 号会议室就是起始地址，第三排就是偏移量。</p></blockquote><p>在 <mark>CS(<strong>代码段寄存器</strong>)</mark> 和 <mark>DS(<strong>数据段寄存器</strong>)</mark> 中都存放着一个<strong>段的<code>起始地址</code></strong>。</p><ul><li><strong><code>代码段</code>的偏移量</strong>在 <mark>IP 寄存器</mark>中，<mark>控制单元</mark></li><li><strong><code>数据段</code>的偏移量</strong>会放在<mark>通用寄存器</mark>中。<mark>数据单元</mark></li></ul><h3 id="起因由来-起始地址-偏移量" tabindex="-1"><a class="header-anchor" href="#起因由来-起始地址-偏移量" aria-hidden="true">#</a> 起因由来: 起始地址 + 偏移量</h3><p>这时候问题来了，<mark>CS(<strong>代码段寄存器</strong>)</mark> 和 <mark>DS(<strong>数据段寄存器</strong>)</mark> 都是 16 位的，也就是说，<mark>起始地址</mark>都是 16 位的，<mark>IP 寄存器</mark>和<mark>通用寄存器</mark>都是 16 位的，<mark>偏移量</mark>也是 16 位的，但是 8086 的<mark>地址总线</mark>地址是 20 位。怎么凑够这 20 位呢？</p><blockquote><p>方法就是“<strong><code>起始地址 *16+ 偏移量</code></strong>”，也就是把 CS 和 DS 中的值左移 4 位，变成 20 位的，加上 16 位的偏移量，</p><p>这样就可以得到最终 20 位的数据地址。</p></blockquote><h3 id="地址总线-能够区分的内存空间" tabindex="-1"><a class="header-anchor" href="#地址总线-能够区分的内存空间" aria-hidden="true">#</a> [地址总线]能够区分的内存空间</h3><p>从这个计算方式可以算出，无论真正的内存多么大，对于只有 20 位<mark>地址总线</mark>的 8086 来讲，<code>能够 区分出 的地址也就</code> 2^20=1M，超过这个空间就访问不到了。这又是为啥呢？如果你想访问 1M+X 的地方，这个位置已经超过 20 位了，由于地址总线只有 20 位，在总线上超过 20 位的部分根本是发不出去的，所以发出去的还是 X，最后还是会访问 1M 内的 X 的位置。</p><h3 id="偏移量位数-段的大小最大" tabindex="-1"><a class="header-anchor" href="#偏移量位数-段的大小最大" aria-hidden="true">#</a> [偏移量位数]段的大小最大</h3><p><code>那 一个段 最大 能有多大呢</code>？因为偏移量只能是 16 位的，所以一个段最大的大小是 2^16=64k。</p><p>是不是好可怜？对于 8086CPU，最多只能访问 1M 的<code>内存空间</code>，还要分成多个段，<code>每个段</code>最多 64K。尽管我们现在看来这不可想象得小，根本没法儿用，但是在当时其实够用了。</p><h2 id="再来说-32-位处理器-80386" tabindex="-1"><a class="header-anchor" href="#再来说-32-位处理器-80386" aria-hidden="true">#</a> <strong>再来说 32 位处理器 80386</strong></h2><blockquote><p>8086 是 16 位操作系统（实模式）</p><p>80386 是 32 位操作系统（保护模式）</p><p>原来 x86 架构是指 8086 ，而 x86 是代表 32 位操作系统是因为 80386，原来这两个 x86 不是同一个意思啊</p></blockquote><p>当然，后来计算机的发展日新月异，内存越来越大，<code>总线也越来越宽</code>。在 32 位处理器中，<code>有 32 根地址总线</code>(每一根就是一位 0/1)，可以访问 2^32=4G 的内存。使用原来的模式肯定不行了，但是又不能完全抛弃原来的模式，因为这个架构是开放的。</p><p>“开放”，意味着有大量其他公司的软硬件是基于这个架构来实现的，不能为所欲为，想怎么改怎么改，一定要和原来的架构兼容，而且要一直兼容，这样大家才愿意跟着你这个开放平台一直玩下去。如果你朝令夕改，那其他厂商就惨了。</p><p>如果是不开放的架构，那就没有问题。硬件、操作系统，甚至上面的软件都是自己搞的，你想怎么改就可以怎么改。</p><p>我们下面来说说，在开放架构的基础上，如何保持兼容呢？</p><h3 id="满足兼容-通用寄存器-ip寄存器" tabindex="-1"><a class="header-anchor" href="#满足兼容-通用寄存器-ip寄存器" aria-hidden="true">#</a> 满足兼容: 通用寄存器 IP寄存器</h3><p>首先，<mark>通用寄存器</mark>有扩展，可以将 8 个 16 位的扩展到 8 个 32 位的，但是依然可以保留 16 位的和 8 位的使用方式。你可能会问，为什么高 16 位不分成两个 8 位使用呢？因为这样就不兼容了呀！</p><blockquote><p>老师您好，我想问下为什么高16位分成两个8位就不兼容列呀。</p><p>作者回复: 没有人写程序用高位的。</p></blockquote><p>其中，指向下一条指令的<mark>指令指针寄存器 IP</mark>，就会扩展成 32 位的，同样也兼容 16 位的。</p><h3 id="cpu中的寄存器汇总" tabindex="-1"><a class="header-anchor" href="#cpu中的寄存器汇总" aria-hidden="true">#</a> CPU中的寄存器汇总</h3><img src="'+g+'" alt="img" style="zoom:25%;"><h4 id="通用寄存器-数据单元-数据段" tabindex="-1"><a class="header-anchor" href="#通用寄存器-数据单元-数据段" aria-hidden="true">#</a> +++ 通用寄存器 &lt;-&gt; 数据单元/数据段</h4><ol><li>AH&amp;AL=AX（accumulator）累加寄存器</li><li>BH&amp;BL=BX（base）基址寄存器</li><li>CH&amp;CL=CX（count）计数寄存器</li><li>DH&amp;DL=DX（data）数据寄存器</li><li>SP（Stack Pointer）堆栈指针寄存器 (段的起始地址)</li><li>BP（Base Pointer）基址指针寄存器</li><li>SI（Source Pointer）源变址寄存器</li><li>DI（Destination Index）目的变址寄存器</li></ol><h4 id="指令寄存器-控制单元-代码段" tabindex="-1"><a class="header-anchor" href="#指令寄存器-控制单元-代码段" aria-hidden="true">#</a> +++ 指令寄存器 &lt;-&gt; 控制单元/代码段</h4><p>IP（Instruction Pointer）指令指针寄存器</p><blockquote><p>把大一时候老师讲的计算机组成原理，和汇编串起来了，内存中有一个个运行的进程，进程中有若干个运行的程序，程序由代码段和数据段组成，而要加载在硬盘上的代码，就得找cpu的控制单元指令寄存器，而要加载数据就得用数据单元中的指令找数据，而数据需要运算，则需要运算单元，而cpu就是控制单元，运算单元，数据单元组成，从代码运行角度看，代码运行一直在cpu，内存，硬盘来回切换，从微观的角度看，cpu是如何调度把有限的资源加以利用的。</p></blockquote><h4 id="段选择子寄存器-运算单元需要" tabindex="-1"><a class="header-anchor" href="#段选择子寄存器-运算单元需要" aria-hidden="true">#</a> +++ 段选择子寄存器 &lt;--&gt; 运算单元需要</h4><blockquote><p>如果需要切换进程呢？每个进程都分<mark>代码段</mark>和<mark>数据段</mark>，为了指向不同进程的地址空间，有四个 16 位的==<strong>段</strong>寄存器==，分别是 <code>CS、DS、SS、ES</code>。</p><ul><li><p>其中，<mark>CS</mark> 就是==<strong>代码段</strong>寄存器（Code Segment Register）==，通过它可以找到<code>代码在内存中的位置</code>；<br> 代码段起始地址, 偏移量在控制单元中</p></li><li><p><mark>DS</mark> 是==<strong>数据段</strong>的寄存器==，通过它可以找到<code>数据在内存中的位置</code>。<br> 数据段起始地址, 偏移量在数据单元中</p></li><li><p><mark>SS</mark> 是==<strong>栈</strong>寄存器（Stack Register）==。栈是<code>程序运行中</code>一个特殊的数据结构，<br> 存取只能从一端进行，秉承后进先出的原则，push 就是入栈，pop 就是出栈。</p></li></ul></blockquote><p>我们写的程序，不论是分段（逻辑关系）来说，主要分为几部分：</p><ul><li><p>CS（Code Segment）代码段寄存器</p></li><li><p>DS（Data Segment）数据段寄存器</p></li><li><p>SS（Stack Segment）堆栈段/栈寄存器 (栈顶指针)，管理一切的函数调用？</p></li><li><p>ES（Extra Segment）附加段寄存器</p></li></ul><p>但其中 CS DS 都是段的<strong>起始地址</strong>，不足以定位，因此设计成存放对应的<strong>偏移量</strong>到：</p><ul><li>CS的偏移量存放在IP中</li><li>DS的偏移量存放在通用寄存器中（都可）</li></ul><blockquote><p>可以理解为二进制可执行文件，代码段数据段，进程的VAS虚拟空间相关。</p><p>当执行一个程序的时候，会加载ELF格式可执行文件，加载的时候会设置指令指针。</p><ul><li><code>多线程共享同一个进程内存空间(VAS)</code>，所以==<strong>代码段的起始地址</strong>==还是一样的。</li><li>只不过每个线程执行不同的func，==指令指针寄存器(<strong>代码段的偏移量</strong>)==会不一样，在内核中，<code>线程也是有独立的task_struct</code></li></ul><p>寄存器是有限的，如果把程序编译成汇编看的话，再大的数据，也是要转换为对寄存器的操作。当然寄存器里面可以包含对内存的访问地址，这样内存里面的数据就很多了。</p></blockquote><h3 id="重新定义-段选择子寄存器-虚拟内存" tabindex="-1"><a class="header-anchor" href="#重新定义-段选择子寄存器-虚拟内存" aria-hidden="true">#</a> 重新定义: 段选择子寄存器 --&gt; 虚拟内存?</h3><p>而改动比较大，有点不兼容的就是==<strong>段寄存器</strong>（Segment Register）==。</p><p>因为原来的模式其实有点不伦不类，因为它没有把 16 位当成一个段的起始地址，也没有按 8 位或者 16 位扩展的形式，而是根据当时的硬件，弄了一个不上不下的 20 位的地址。这样每次都要左移四位，也就意味着段的起始地址不能是任何一个地方，只是能整除 16 的地方。</p><p>如果新的段寄存器都改成 32 位的，明明 4G 的内存全部都能访问到，还左移不左移四位呢？</p><p><code>那我们索性就重新定义一把吧</code>。</p><h4 id="页表-段描述符-选择子" tabindex="-1"><a class="header-anchor" href="#页表-段描述符-选择子" aria-hidden="true">#</a> ## 页表?/段描述符/选择子</h4><p><strong>CS、SS、DS、ES 仍然是 16 位的，<code>但是不再是</code>段的起始地址。段的起始地址<code>放在内存的某个地方</code>。</strong></p><ul><li>这个地方是一个表格（进程独有的页表/描述VAS），表格中的一项一项是==<strong>段描述符</strong>（Segment Descriptor）<mark>。这里面才是真正的</mark>段的起始地址==。</li><li>而<mark>段寄存器 CS、SS、DS、ES</mark> 里面保存的是在这个表格中的哪一项，称为==<strong>选择子</strong>（Selector）==。</li></ul><blockquote><p>这样，将一个从段寄存器直接拿到的段起始地址，</p><p>就变成了先间接地从<mark>段寄存器</mark>找到<code>表格中的一项(选择子)</code>，再从==表格中的一项(选择子)==中拿到<code>(段描述符)段起始地址</code>。</p><p>CS DS 仍然是 代码段 数据段 起始地址 相关的寄存器</p><p>段描述符(段起始地址) -&gt; 存放 32 位地址</p></blockquote><p>由于 CPU 的扩展导致了 32 位的段基地址和段内偏移，(再加上引入虚拟内存机制，为了方便统一管理)还有一些其它信息，所以 16 位的段寄存器肯定放不下。放不下就要找内存借空间，然后把<strong>描述一个段的信息</strong>封装成特定格式的**<mark>段描述符</mark>**，<strong>放在内存中</strong>，其格式如下。</p><img src="'+k+'" alt="b40a64dd5ca1dc1efd8957525e904634" style="zoom:15%;"><p>保护模式段描述符</p><p>一个段描述符有 64 位 8 字节数据，里面包含了段基地址、段长度、段权限、段类型（可以是<code>系统段、代码段、数据段</code>）、段是否可读写，可执行等。虽然数据分布有点乱，这是由于历史原因造成的。</p><p>多个<mark>段描述符</mark>在内存中形成<mark>全局段描述符表</mark>，该表的基地址和长度由 <mark>CPU 和 GDTR 寄存器</mark>指示。如下图所示。</p><img src="'+u+'" alt="ab203e85dd8468051eca238c3ebd81f7" style="zoom:15%;"><p>全局段描述符表</p><p>我们一眼就可以看出，<mark>段寄存器</mark>中不再存放<strong>段基地址</strong>，而是<strong>具体段描述符的索引</strong>，访问一个内存地址时，段寄存器中的<strong>索引</strong>首先会结合 <strong>GDTR 寄存器</strong>找到内存中的<strong>段描述符</strong>，再根据其中的段信息判断能不能访问成功。</p><h4 id="描述符高速缓存器" tabindex="-1"><a class="header-anchor" href="#描述符高速缓存器" aria-hidden="true">#</a> ## 描述符高速缓存器</h4><p>这样段起始地址就会很灵活了。<strong>当然为了快速拿到<code>段起始地址</code></strong>，段寄存器会从内存中拿到它并放入 CPU 的<mark>描述符高速缓存器</mark>中。</p><blockquote><p>首先先建立一个观念，CPU里面的比内存快很多，内存比硬盘快很多。原来段的起始地址是放在寄存器里面的，所以速度就比在内存里面快很多，但是到了保护模式下，段起始地址放到内存里面了，就慢了，怎么办呢？将内存中的段描述符拿到CPU内的高速缓存中，就又快了。</p></blockquote><p>这样就不兼容了，咋办呢？好在后面这种模式灵活度非常高，可以保持将来一直兼容下去。前面的模式出现的时候，没想到自己能够成为一个标准，所以设计就没这么灵活。</p><h4 id="段选择子" tabindex="-1"><a class="header-anchor" href="#段选择子" aria-hidden="true">#</a> ##段选择子</h4><p>如果你认为升级保护模式后 CS、DS、ES、SS、FS、GS 这些段寄存器，里面存放的就是一个内存段的描述符索引，那你可就草率了，其实它们是由<strong>影子寄存器、段描述符索引、描述符表索引、权限级别</strong>组成的。如下图所示。</p><img src="'+b+'" alt="img" style="zoom:15%;"><p>保护模式段选择子</p><p>上图中<strong>影子寄存器</strong>是靠<mark>硬件</mark>来操作的，对系统程序员不可见，是硬件为了<strong>减少性能损耗</strong>而设计的一个段描述符的高速缓存，不然每次内存访问都要去内存中查表，那性能损失是巨大的，影子寄存器也正好是 64 位，里面存放了 <strong><code>8 字节</code>段描述符<code>数据</code></strong>。</p><p>低三位之所以能放 <code>TI</code> 和 <code>RPL</code>，是因为段描述符 8 字节对齐，每个索引低 3 位都为 0，我们不用关注 LDT，只需要使用 GDT 全局描述符表，所以 TI 永远设为 0。</p><p>通常情况下，CS 和 SS 中 <code>RPL</code> 就组成了 <code>CPL</code>（当前权限级别），所以常常是 RPL=CPL，进而 CPL 就表示发起访问者要以什么权限去访问目标段，当 CPL 大于目标段 DPL 时，则 CPU 禁止访问，只有 CPL 小于等于目标段 DPL 时才能访问。（R0高权限 R3低权限）</p><h3 id="实模式-保护模式" tabindex="-1"><a class="header-anchor" href="#实模式-保护模式" aria-hidden="true">#</a> 实模式 / 保护模式</h3><p>因而到了 32 位的系统架构下，我们将前一种模式称为**<code>实模式</code><strong>（Real Pattern），后一种模式称为</strong><code>保护模式</code>**（Protected Pattern）。</p><p><code>当系统刚刚启动的时候</code>，CPU 是处于<mark>实模式</mark>的，这个时候和原来的模式是兼容的。也就是说，哪怕你买了 32 位的 CPU，也支持在原来的模式下运行，只不过快了一点而已。</p><p><code>当需要更多内存的时候</code>，你可以遵循一定的规则，进行一系列的操作，然后切换到<mark>保护模式</mark>，就能够用到 32 位 CPU 更强大的能力。</p><p><strong>这也就是说，不能无缝兼容，但是通过切换模式兼容，也是可以接受的。</strong></p><p>在接下来的几节，我们就来看一下，CPU 如何从启动开始，逐渐从实模式变为保护模式的。</p><blockquote><p>可以理解为，CPU和操作系统的一起干活的模式，</p><ul><li>在实模式下，两者约定好了这些寄存器是干这个的，总线是这样的，内存访问是这样的，</li><li>在保护模式下，两者约定好了这些寄存器是干那个的，总线是那样的，内存访问是那样的。</li></ul><p>这样操作系统给CPU下命令，CPU按照约定好的，就能得到操作系统预料的结果，操作系统也按照约定好的，将一些数据结构，例如段描述符表放在一个约定好的地方，这样CPU就能找到。两者就可以配合工作了。</p><p>实模式和保护模式的区别不知道理解的对不对：</p><ol><li>实模式下, 地址总线最大可寻地址空间大小仍为1M</li><li>实模式下, 虽然 通用寄存器 和 IP寄存器 在32CPU里已经扩展成32位, 但仍然只使用低16位</li><li>实模式下, CS,DS,SS,ES寄存器仍保存 段起始地址, 而在保护模式下实际指向的是 段描述符位置</li><li>实模式下, <code>没有特权等级和访问边界校验</code></li><li>实模式下, 是直接对物理地址进行寻址, <code>没有虚拟地址和分页</code></li></ol></blockquote><h2 id="总结时刻" tabindex="-1"><a class="header-anchor" href="#总结时刻" aria-hidden="true">#</a> <strong>总结时刻</strong></h2><p>这一节，我们讲了 x86 架构。在以后的操作系统讲解中，我们也是主要基于 x86 架构进行讲解，只有了解了底层硬件的基本工作原理，将来才能理解操作系统的工作模式。</p><p>x86 架构总体来说还是很复杂的，其中和操作系统交互比较密切的部分，我画了个图。在这个图中，建议你重点牢记这些寄存器的作用，以及段的工作模式，后面我们马上就能够用到了。</p><img src="'+C+'" alt="img" style="zoom:25%;"><h2 id="课堂练习" tabindex="-1"><a class="header-anchor" href="#课堂练习" aria-hidden="true">#</a> <strong>课堂练习</strong></h2><p>操作这些底层的寄存器往往需要使用汇编语言，操作系统的一些底层的模块也是用汇编语言写的，因而你需要简单回顾一些汇编语言中的一些简单的命令的作用。所以，今天给你留个练习题，简单了解一下这些命令。</p><p>mov, call, jmp, int, ret, add, or, xor, shl, shr, push, pop, inc, dec, sub, cmp。</p><p>欢迎留言和我分享你的疑惑和见解，也欢迎你收藏本节内容，反复研读。你也可以把今天的内容分享给你的朋友，和他一起学习、进步。</p><h2 id="课后讨论" tabindex="-1"><a class="header-anchor" href="#课后讨论" aria-hidden="true">#</a> 课后讨论</h2><p>move a b : 把b值赋给a,使a=b</p><p>call和ret : call调用子程序，子程序以ret结尾</p><p>jmp : 无条件跳</p><p>int : 中断指令</p><p>add a b : 加法,a=a+b</p><p>or : 或运算</p><p>xor : 异或运算</p><p>shl : 逻辑左移 ?</p><p>sal : 算术左移 ?</p><p>ahr : 算术右移</p><p>push xxx : 压xxx入栈</p><p>pop xxx : xxx出栈</p><p>inc : 加1</p><p>dec : 减1</p><p>sub a b : a=a-b</p><p>cmp : 减法比较，修改标志位</p>',188),P={href:"http://www.cs.virginia.edu/~evans/cs216/guides/x86.html",target:"_blank",rel:"noopener noreferrer"},f=e("p",null,"《汇编从零开始到C语言》",-1),U=e("p",null,"结合《深入理解计算机系统》第三章，受益匪浅。这本书值得推荐",-1),_=e("p",null,"微软的IDE visual studio，可以查看C语言编译后的汇编语言，内存，寄存器，非常方便。",-1),D=e("p",null,[a("x86是甜蜜的历史包袱，它的兼容性让它一统市场，但是当时很多性能上更好的尝试在商业上都失败了，因为兼容性的问题客户不买单？"),e("br"),a(" 作者回复: 是的，所以兼容比优雅要重要")],-1);function B(I,A){const r=d("ExternalLinkIcon");return c(),t("div",null,[x,e("p",null,[a("Guide to x86 Assembly: "),e("a",P,[a("http://www.cs.virginia.edu/~evans/cs216/guides/x86.html"),p(r)])]),f,U,_,D])}const R=o(S,[["render",B],["__file","G06-x86CPU架构解析.html.vue"]]);export{R as default};
