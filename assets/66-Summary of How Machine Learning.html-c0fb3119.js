import{_ as i}from"./plugin-vue_export-helper-c27b6911.js";import{r as n,o as p,c as s,a as e,b as a,e as t,d as o}from"./app-cdabc73c.js";const d="/assets/640-1691377887638-90-71ecbd71.png",c="/assets/640-1691377887639-91-a4282d20.png",g="/assets/640-1691377887639-92-af617569.png",h="/assets/640-1691377887639-93-8b60e346.png",m="/assets/640-1691377887639-94-4d4142c6.png",l="/assets/640-1691377887639-95-0191b3a6.png",f={},u=e("h1",{id:"_66-summary-of-how-machine-learning",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_66-summary-of-how-machine-learning","aria-hidden":"true"},"#"),a(" 66-Summary of How Machine Learning")],-1),_={href:"https://www.s3.eurecom.fr/docs/usenixsec22_marcelli.pdf",target:"_blank",rel:"noopener noreferrer"},b=o('<p>文章首次实现了<em>二进制代码相似度计算</em>研究领域的一个系统性measurement。作者对当前领域的论文的现状进行了一个深入研究，从中选取了共10种具有代表性的方法，通过一个公共的基础框架重新实现了这些原本在不同基础上实现的方法，在共同的数据集上训练和测试，从而较为公正的评估这些方法的效果。通过这些实验数据，回答了此领域内哪些方向值得研究、不同函数特征在最终效果上起了什么作用等研究问题。</p><h2 id="一、背景" tabindex="-1"><a class="header-anchor" href="#一、背景" aria-hidden="true">#</a> <strong>一、背景</strong></h2><p>二进制函数相似度旨在准确计算两端二进制代码之间的相似性程度，将一对函数的二进制表示作为输入，并生成一个捕捉它们之间“相似性”的数值作为输出。这个问题一般是很有挑战性的。事实上，软件通常使用不同的工具链、不同的编译器优化设置和flag进行编译，并且，在一些场景(如物联网设备)中，软件被编译到不同的架构，这使得一般的二进制相似性计算方法无效。</p><p>二进制函数相似度在不同的系统安全研究领域中起着至关重要的作用，因为许多研究问题都需要将函数相似度的度量作为核心部分。例如，逆向工程师经常处理被静态链接(没有符号)的被分离的二进制文件，而二进制代码相似性方法可以用于<em>将未知的函数与先前生成的数据库中的函数匹配</em>，从而节省大量的逆向工程工作时间。</p><h2 id="二、系统性研究" tabindex="-1"><a class="header-anchor" href="#二、系统性研究" aria-hidden="true">#</a> <strong>二、系统性研究</strong></h2><h3 id="_1、函数表示方法总结" tabindex="-1"><a class="header-anchor" href="#_1、函数表示方法总结" aria-hidden="true">#</a> 1、函数表示方法总结</h3><p>二进制函数本质上是对应于特定于体系结构的机器代码和数据的字节流。从这个原始输入开始，研究人员使用了许多方法来提取高级信息，这些方法按照抽象级别排序如下：</p><ol><li>原始数据</li><li>汇编</li><li>规范化汇编</li><li>中间层表示IR</li><li>函数结构（控制流图）</li><li>数据流分析</li><li>动态分析</li><li>符号执行和分析</li></ol><h3 id="_2、计算相似度方法总结" tabindex="-1"><a class="header-anchor" href="#_2、计算相似度方法总结" aria-hidden="true">#</a> 2、计算相似度方法总结</h3><p>文章将现有评估二进制函数相似度的技术分为两类：直接比较和间接比较。</p><p><strong>直接比较</strong>：采用函数的原始输入数据进行比较，或者对函数实现某种特征提取然后进行比较。特征提取方案通常需要学习和训练模型。此类模型用于输出一对函数之间的相似度。</p><p><strong>间接比较</strong>：此类技术将输入特征映射为一个“浓缩”的低维表示（embeding），可以很容易地通过距离度量(如欧氏距离或余弦距离)进行比较。这些解决方案允许<em>有效的一对多比较</em>。</p><p>文章选取了三类最具代表性的二进制函数相似度比较方法：</p><p><strong>模糊哈希</strong>：不同于传统密码哈希，它们被特意设计成相似的输入值映射到相似的哈希。</p><p><strong>Code embedding</strong>：试图采用现有的自然语言处理(NLP)技术，通过将<mark>汇编代码</mark>作为文本处理来解决二进制函数相似问题。</p><p><strong>Graph embedding</strong>：基于<mark>功能控制流图</mark>来捕获特性，而且这些特性是能够跨架构的。这些embedding可以通过自定义算法或更复杂的机器学习技术生成，如<em>图神经网络(GNN)</em>。Graph embedding还经常将每个基本块的信息编码到图的相应节点中，以增加更多的表达能力。</p><p>PS：embedding是深度学习领域的一个术语，将target表示成特征向量的形式。</p><h3 id="_3、参考的论文和选择的方法" tabindex="-1"><a class="header-anchor" href="#_3、参考的论文和选择的方法" aria-hidden="true">#</a> 3、参考的论文和选择的方法</h3><p>下图展示了作者选取的论文以及作者，标识说明：[S]安全，[PL]编程语言，[ML]机器学习，[SE]软件工程。[Mono]和[Cross]单一架构场景还是跨架构场景。</p><figure><img src="'+d+'" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>作者在综合考虑了现实的可用性、代表性、覆盖社区的范围以及最新的研究趋势，选出了最具代表性的十种方法进行重新实现和评估。</p><h2 id="三、实现与评估" tabindex="-1"><a class="header-anchor" href="#三、实现与评估" aria-hidden="true">#</a> <strong>三、实现与评估</strong></h2><h3 id="实现" tabindex="-1"><a class="header-anchor" href="#实现" aria-hidden="true">#</a> 实现</h3><p>作者在一个公共框架之上重新实现了选取的这些方法的核心模型，具体实现如下：</p><p>在二进制分析阶段，作者使用<mark>IDA Pro 7.3</mark>；</p><p>在特征提取方面，依赖于一组Python脚本，使用了<mark>IDA Pro api</mark>、<mark>Capstone</mark>和<mark>NetworkX</mark>；</p><p>在<mark>Tensorflow1.14</mark>中实现了所有的神经网络模型。</p><p>Trex例外，它是建立在Fairseq之上的，这是一个用于PyTorch的序列建模工具包。</p><p>使用<mark>Gensim3.8</mark>实现Asm2Vec并运行instructionembedding models。</p><h3 id="评估" tabindex="-1"><a class="header-anchor" href="#评估" aria-hidden="true">#</a> 评估</h3><p><strong>数据集设置</strong></p><p>作者创建了两个数据集，Dataset-1和Dataset-2，旨在捕捉现实世界软件的复杂性和可变性，涵盖了二进制函数相似性的不同挑战:</p><p>(i)多种编译器家族和版本，</p><p>(ii)多种编译器优化</p><p>(iii)多种架构和位</p><p>(iv)不同性质的软件(命令行实用程序vs. GUI应用程序)。</p><p><strong>实验设置</strong></p><p>作者在实验阶段设置了六个不同的实验任务，不同的实验任务控制不同的变量进行相互对照。具体如下：</p><p>（1） XO：不同的编译优化设置，<em>但编译器、编译器版本和体系结构相同</em>。</p><p>（2） XC：不同的编译器、编译器版本和编译优化设置，<em>但具有相同的体系结构和位数</em>。</p><p>（3） XC+XB：不同的编译器、编译器版本、编译优化设置和位数，<em>但架构相同</em>。</p><p>前三个任务评估<strong>仅局限于单一体系结构的技术</strong>。</p><p>（4） XA：不同的体系结构和位数，但编译器、编译器版本和编译优化设置相同。</p><p>第四项任务是分析固件映像，因为它们始终使用相同的编译器和编译器选项进行交叉编译。</p><p>（5） XA+XO：不同的体系结构、位数和编译优化设置，但编译器和编译器版本相同。</p><p>第五个任务旨在支持Dataset-2，它只使用一个编译器和编译器版本进行编译。</p><p>（6） XM：任意体系结构、位数、编译器、编译器版本和编译优化设置。</p><p>还考虑了XM的三个子数据集: XM- s、XM- m 和 XM- l，它们分别包括小型函数(少于20个基本块)、中型函数(在20到100之间)和大型函数(超过100个块)。</p><p>每个对照任务都根据两种不同的测试进行综合评估:</p><p>(1) 受试者工作特征曲线(ROC)的AUC值(area under curve, AUC),这是一个总体衡量指标，越接近1表示性能越好。</p><p>(2) 两种常用的排名指标，平均倒数排名(MRR)和不同的K阈值下的召回率(Recall@K)。</p><p>对于第一个测试，作者为每个任务构建了一个包含50k的positive pairs和50k的negative pairs的数据集，在dataset -1和dataset -2上总共有700k个函数对。</p><p>在排名测试中，作者选择了1400对positive pairs和140k对negative pairs，即每一个positive pairs对应100对negative pairs。</p><p>测试覆盖了438,981个独特的二进制函数，并限制至少有5个基本块。在每个任务中，根据相应的约束条件随机抽样。</p><h3 id="实验结果" tabindex="-1"><a class="header-anchor" href="#实验结果" aria-hidden="true">#</a> 实验结果</h3><p><strong>1、模糊哈希间的比较</strong></p><figure><img src="'+c+'" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><figure><img src="'+g+'" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>实验说明了当一次只考虑一个自由变量时，即使是像模糊哈希这样的简单方法也是有效的，当受测函数同时包含多个自由变量时（不同架构、编译器、编译器设置和位数等），模糊哈希这样一种简单的方法不再有效，不能够有效反映出包含不同类别特征的函数间二进制代码相似度。</p><p><strong>2、机器学习方法间以及与模糊哈希的比较</strong></p><figure><img src="'+h+'" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><figure><img src="'+m+'" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>结果表明，在生成函数(即embedding)向量表示的模型中，来自论文[40]Y ujia Li,Chenjie Gu, Thomas Dullien, Oriol Vinyals, and Pushmeet Kohli. Graph matchingnetworks for learning the similarity of graph structured objects. InInternational conference on machine learning,pages 3835–3845. PMLR, 2019.的GNN在所有度量和所有任务中都达到了最佳值。当在AUC指标上比较时，大多数机器学习模型的表现非常相似，但在排名指标(MRR10和recall@1)上有所不同。</p><p><strong>3、腾讯CodeCMR实验</strong></p><figure><img src="'+l+'" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>BinaryAI /CodeCMR模型的所有指标均高于其余的测试模型。如果这些结果被社区的独立研究证实，这可能是一个非常有前途的研究方向。</p><p>作者说BinaryAI/CodeCMR模型引入了一些创新。首先，它将几个构建组件(即一个NLP编码器、一个GNN和两个lstm)合并到一个模型中，并通过使用端到端策略联合训练所有内容。</p><p>其次，他们在论文中表明，训练策略(例如，使用距离加权抽样[73])和损失函数(例如，三元组损失[66])发挥了重要作用，可以产生显著的性能改进。</p><h2 id="四、总结" tabindex="-1"><a class="header-anchor" href="#四、总结" aria-hidden="true">#</a> <strong>四、总结</strong></h2><p>文章首次在二进制函数相似度研究领域中对前人研究成果进行了系统性的Measurement，通过在公共的基础框架上重新实现了挑选的具有代表性的方法，在具有现实意义的数据集上训练和评估这些方法的效果，实现了一个相对公平的评估，然后在文章的discussion部分，经由实验数据得出的结论，回答了为什么机器学习算法在此领域相比模糊哈希更具优势、哪些方向值得研究等研究问题。具体内容见Q&amp;A in Discussion。</p><h2 id="五、q-a-in-discussion" tabindex="-1"><a class="header-anchor" href="#五、q-a-in-discussion" aria-hidden="true">#</a> <strong>五、Q&amp;A in Discussion</strong></h2><p>1、与更简单的模糊哈希方法相比，新的基于机器学习的解决方案的主要贡献是什么?</p><p>深度学习模型提供了一种函数表示的(即embedding)有效方法模型，与模糊哈希方法不同，机器学习模型即使在多个编译变量同时变化时也能获得较高的精度，机器学习模型受益于基于可靠的ground truth之上构建的大型训练数据集。</p><p>2、不同的函数特征集会有什么影响?</p><p>输入的特征类型与机器学习模型的类型，（特别是GNN算法的类型）还有损失函数具有相同的重要性。</p><p>文章发现使用基本块特征(例如ACFG)可以获得更好的结果，而且在人工精心设计的特征在结果上只会带来很小的差别，比如基本块操作码的词袋特征（bag of words)。</p><p>指令层级的embeddings不会提高GNN模型的性能。</p><p>Zeek展示了数据流信息的特征可以获得更好的结果，特别是对于大型函数。</p><p>由于缺乏训练阶段，模糊哈希方法对函数的特征类型更敏感。</p><p>3、不同的方法能更好地完成不同的任务吗?特别是，跨架构的比较是否比使用单一架构更困难?</p><p>作者认为，文章的evaluation表明，无论是在相同的架构中还是在跨架构中，大多数机器学习模型在所有评估实验中表现非常相似，没有必要就特定的任务对他们进行训练，使用最通用的任务数据(XM)就可以使每个任务的总体性能接近最佳。</p><p>在跨架构的问题上，并不是所有的方法都可以用于跨架构的比较:Asm2Vec和the two paragraph2vec模型，受限于特定的无监督培训。同样无法用于跨架构的比较的还有Catalog1。</p><p>4、有没有什么特定的研究方向看起来更有希望成为未来设计新技术的方向?</p><p>文章发现，GNN模型提供了最好的结果，GNN与汇编指令编码器的结合是一个有前途的方向，但仍有数十种不同的变体需要测试。</p><p>表示学习（representationlearning）也是潜在的方向之一，最近的研究中的机器学习模型借助了表示学习的优势，只使用标准化的汇编代码或中间层表示。</p><p>文章还发现结合中间表示和数据流信息的方法的效果也值得加以研究。</p><p>此外，作者还观察到，特征和机器学习模型的选择并不是影响效果的唯一方面。其中一些补充方面，如训练策略和损失函数，在过去很少被讨论，只是最近才被探讨。其它的研究引入了两种可选的损失函数，基于欧几里得边缘的损失函数，以及用于有效最近邻搜索的近似汉明相似函数。在类似的方向，CodeCMR的最新研究表明，由于采用了范数加权抽样方法（一种距离加权抽样）并结合了三元组损失，结果有了显著的改进。</p><p>总体结果表明，对于不同的函数相似度计算任务，仍有对深度学习模型的扩展性和精度的需求。特别是因为深度学习能够通过学习，发展出一种可以适用于多种不同相似度计算任务的函数表达。</p>',88);function k(x,C){const r=n("ExternalLinkIcon");return p(),s("div",null,[u,e("p",null,[a("本文发表于USENIX Secuirty 2022，第一作者是Cisco公司的Andrea Marcelli，论文链接："),e("a",_,[a("https://www.s3.eurecom.fr/docs/usenixsec22_marcelli.pdf"),t(r)])]),b])}const y=i(f,[["render",k],["__file","66-Summary of How Machine Learning.html.vue"]]);export{y as default};
