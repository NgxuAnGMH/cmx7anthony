import{_ as r}from"./plugin-vue_export-helper-c27b6911.js";import{r as t,o as p,c as l,a,b as e,e as s,d as o}from"./app-cdabc73c.js";const i="/assets/9998b67238044aad60d2aa0735b98ebc-2175b642.jpeg",c="/assets/c9ed34b47b0cd33867c581772d8eff8e-14f73901.jpeg",m="/assets/e0e85505e793e804e3b396fc50871cd5-0d3c695c.jpg",d="/assets/596042d111ad9b871045d970a10464ab-68c38f26.jpg",k={},u=o('<h1 id="_48-dma-为什么kafka这么快" tabindex="-1"><a class="header-anchor" href="#_48-dma-为什么kafka这么快" aria-hidden="true">#</a> 48 | DMA：为什么Kafka这么快？</h1><p>过去几年里，整个计算机产业界，都在尝试不停地提升 I/O 设备的速度。把 HDD 硬盘换成 SSD 硬盘，我们仍然觉得不够快；用 PCI Express 接口的 SSD 硬盘替代 SATA 接口的 SSD 硬盘，我们还是觉得不够快，所以，现在就有了傲腾（Optane）这样的技术。</p><p>但是，无论 I/O 速度如何提升，比起 CPU，总还是太慢。SSD 硬盘的 IOPS 可以到 2 万、4 万，但是我们 CPU 的主频有 2GHz 以上，也就意味着每秒会有 20 亿次的操作。</p><p>如果我们对于 I/O 的操作，都是由 CPU 发出对应的指令，然后等待 I/O 设备完成操作之后返回，<em>那 CPU 有大量的时间其实都是在等待 I/O 设备完成操作</em>。</p><p>但是，这个 CPU 的等待，在很多时候，其实并没有太多的实际意义。我们对于 I/O 设备的大量操作，其实都只是把内存里面的数据，传输到 I/O 设备而已。<em>在这种情况下，其实 CPU 只是在傻等而已</em>。特别是当传输的数据量比较大的时候，比如进行大文件复制，如果所有数据都要经过 CPU，实在是有点儿太浪费时间了。</p><p>因此，计算机工程师们，就发明了 <mark>DMA</mark> 技术，也就是<strong>直接内存访问</strong>（Direct Memory Access）技术，来减少 CPU 等待的时间。</p><h2 id="理解-dma-一个协处理器" tabindex="-1"><a class="header-anchor" href="#理解-dma-一个协处理器" aria-hidden="true">#</a> 理解 DMA，一个协处理器</h2><p>其实 DMA 技术很容易理解，本质上，DMA 技术就是我们在主板上放<mark>一块独立的芯片</mark>。在进行内存和 I/O 设备的数据传输的时候，<em>我们不再通过 CPU 来控制数据传输</em>，而直接通过 <strong>DMA 控制器</strong>（DMA Controller，简称 DMAC）。<em>这块芯片</em>，我们可以认为它其实就是一个**<mark>协处理器</mark>**（Co-Processor）。</p><blockquote><p><strong>DMAC 最有价值的地方体现在，当我们要传输的数据特别大、速度特别快，或者传输的数据特别小、速度特别慢的时候。</strong></p></blockquote><p>比如说，我们用千兆网卡或者硬盘<em>传输大量数据的时候</em>，如果都用 CPU 来搬运的话，肯定忙不过来，所以可以选择 DMAC。<em>而当数据传输很慢的时候</em>，DMAC 可以等数据到齐了，再发送信号，给到 CPU 去处理，而不是让 CPU 在那里忙等待。</p><p>好了，现在你应该明白 DMAC 的价值，知道了它适合用在什么情况下。那我们现在回过头来看。我们上面说，DMAC 是一块“协处理器芯片”，这是为什么呢？</p><p>注意，这里面的“协”字。<em>DMAC 是在“<code>协助</code>”CPU，完成对应的数据传输工作</em>。在 DMAC 控制数据传输的过程中，我们还是需要 CPU 的。</p><h2 id="主设备-从设备" tabindex="-1"><a class="header-anchor" href="#主设备-从设备" aria-hidden="true">#</a> 主设备 / 从设备</h2><p>除此之外，DMAC 其实也是<strong>一个特殊的 I/O 设备</strong>，它和 CPU 以及其他 I/O 设备一样，通过连接到总线来进行实际的数据传输。<code>总线上的设备呢</code>，其实有两种类型。</p><ol><li>一种我们称之为<strong>主设备</strong>（Master），</li><li>另外一种，我们称之为<strong>从设备</strong>（Slave）。</li></ol><p><strong>想要<em>主动发起数据传输</em>，必须要是一个<mark>主设备</mark>才可以</strong>，CPU 就是主设备。</p><p><strong>而我们<mark>从设备</mark>（比如硬盘）<em>只能接受数据传输</em></strong>。</p><p>所以，如果通过 CPU 来传输数据，要么是 CPU 从 I/O 设备读数据，要么是 CPU 向 I/O 设备写数据。</p><p>这个时候你可能要问了，那我们的 I/O 设备不能向主设备发起请求么？<strong>可以是可以，不过这个发送的<em>不是数据内容，而是<code>控制信号</code></em></strong>。</p><blockquote><p>I/O 设备可以告诉 CPU，我这里有数据要传输给你，但是实际数据是 CPU 拉走的，而不是 I/O 设备推给 CPU 的。</p></blockquote><img src="'+i+'" alt="img" style="zoom:25%;"><h2 id="dmac-工作流程" tabindex="-1"><a class="header-anchor" href="#dmac-工作流程" aria-hidden="true">#</a> DMAC 工作流程</h2><p>不过，<mark>DMAC</mark> 就很有意思了，它既是一个<mark>主设备</mark>，又是一个<mark>从设备</mark>。<strong>对于 CPU 来说</strong>，它是一个从设备；<strong>对于硬盘这样的 IO 设备来说呢</strong>，它又变成了一个主设备。那使用 DMAC 进行数据传输的过程究竟是什么样的呢？下面我们来具体看看。</p><ol><li><p>首先，CPU 还是作为一个主设备，向 DMAC 设备发起请求。<br> 这个请求，其实就是在 DMAC 里面修改配置寄存器。</p></li><li><p>CPU 修改 DMAC 的配置的时候，会告诉 DMAC 这样几个信息：</p><ul><li><p>首先是<em><em><em>源地址的初始值</em>以及</em>传输时候的地址增减方式</em>**。</p><ul><li>所谓源地址，<code>就是数据要从哪里传输过来</code>。 <ul><li>如果我们要从<strong>内存</strong>里面写入数据到硬盘上，那么就是要读取的数据在内存里面的地址。</li><li>如果是从<strong>硬盘</strong>读取数据到内存里，那就是硬盘的 I/O 接口的地址。</li></ul></li><li>我们讲过总线的时候说过，I/O 的地址可以是<mark>一个内存地址</mark>，也可以是<mark>一个端口地址</mark>。而地址的增减方式就是说，数据是从大的地址向小的地址传输，还是从小的地址往大的地址传输。</li></ul></li><li><p>其次是<em><em><em>目标地址初始值</em>和</em>传输时候的地址增减方式</em>**。</p><ul><li>目标地址自然就是和源地址对应的设备，<code>也就是我们数据传输的目的地</code>。</li></ul></li><li><p>第三个自然是<strong>要传输的数据长度</strong>，也就是我们<code>一共要传输多少数据</code>。</p></li></ul></li><li><p>设置完这些信息之后，DMAC 就会变成一个空闲的状态（Idle）。</p></li><li><p>如果我们要从硬盘上往内存里面加载数据，这个时候，<strong><mark>硬盘</mark>就会向 <mark>DMAC</mark> 发起<em>一个数据传输请求</em></strong>。</p><ul><li>这个请求并不是通过总线，而是通过<em>一个额外的连线</em>。</li></ul></li><li><p>然后，我们的 DMAC 需要再通过<em>一个额外的连线</em>响应这个申请。</p></li><li><p>于是，DMAC 这个芯片，就向==硬盘的接口（电路板/驱动程序）==发起<strong>要总线读的传输请求</strong>。</p><ul><li>数据就从硬盘里面，读到了 <strong>DMAC 的控制器</strong>里面。</li></ul></li><li><p>然后，DMAC 再向我们的<mark>内存</mark>发起<strong>总线写的数据传输请求</strong>，</p><ul><li>把数据写入到<strong>内存</strong>里面。</li></ul></li><li><p>DMAC 会反复进行上面第 6、7 步的操作，直到 DMAC 的寄存器里面设置的<strong>数据长度</strong>传输完成。</p></li><li><p>数据传输完成之后，DMAC 重新回到第 3 步的空闲状态。</p></li></ol><p>所以，整个数据传输的过程中，<em>我们不是通过 CPU 来搬运数据，而是由 <mark>DMAC 这个芯片</mark>来搬运数据</em>。但是 CPU 在这个过程中也是必不可少的。因为传输什么数据，从哪里传输到哪里，其实还是由 CPU 来设置的。这也是为什么，DMAC 被叫作==“协处理器”==。</p><img src="'+c+`" alt="img" style="zoom:25%;"><p>现在的外设里面，很多都内置了 DMAC</p><p>最早，计算机里是没有 DMAC 的，所有数据都是由 CPU 来搬运的。随着人们对于数据传输的需求越来越多，先是出现了主板上独立的 DMAC 控制器。到了今天，各种 I/O 设备越来越多，数据传输的需求越来越复杂，使用的场景各不相同。加之显示器、网卡、硬盘对于数据传输的需求都不一样，<em>所以各个设备里面都有自己的 DMAC 芯片了</em>。</p><h2 id="为什么那么快-一起来看-kafka-的实现原理" tabindex="-1"><a class="header-anchor" href="#为什么那么快-一起来看-kafka-的实现原理" aria-hidden="true">#</a> 为什么那么快？一起来看 Kafka 的实现原理</h2><p>了解了 DMAC 是怎么回事儿，那你可能要问了，这和我们实际进行程序开发有什么关系呢？有什么 API，我们直接调用一下，就能加速数据传输，减少 CPU 占用吗？</p><p>你还别说，过去几年的大数据浪潮里面，还真有一个开源项目很好地利用了 DMA 的数据传输方式，通过 DMA 的方式实现了非常大的性能提升。这个项目就是 <strong>Kafka</strong>。下面我们就一起来看看它究竟是怎么利用 DMA 的。</p><p>Kafka 是一个用来<strong>处理实时数据的管道</strong>，我们常常用它来做<mark>一个消息队列</mark>，或者用来<strong>收集和落地海量的日志</strong>。作为一个处理实时数据和日志的管道，瓶颈自然也在 I/O 层面。</p><p>Kafka 里面会有两种常见的海量数据传输的情况。</p><ol><li>一种是<em>从网络中接收上游的数据</em>，然后需要落地到本地的磁盘上，确保数据不丢失。</li><li>另一种情况呢，则是<em>从本地磁盘上读取出来</em>，通过网络发送出去。</li></ol><p>我们来看一看后一种情况，从磁盘读数据发送到网络上去。如果我们自己写一个简单的程序，最直观的办法，自然是用一个文件读操作，从磁盘上把数据读到内存里面来，然后再用一个 Socket，把这些数据发送到网络上去。</p><div class="language-java line-numbers-mode" data-ext="java"><pre class="language-java"><code><span class="token class-name">File</span><span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span>fileDesc<span class="token punctuation">,</span> buf<span class="token punctuation">,</span> len<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">Socket</span><span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>socket<span class="token punctuation">,</span> buf<span class="token punctuation">,</span> len<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>代码来源</p><p>这段伪代码，来自 IBM Developer Works 上关于 Zero Copy 的文章</p><p>在这个过程中，数据一共发生了四次传输的过程。其中两次是 DMA 的传输，另外两次，则是通过 CPU 控制的传输。下面我们来具体看看这个过程。</p><ol><li>第一次传输，是从硬盘上，读到操作系统内核的缓冲区里。<br> 这个传输是通过 DMA 搬运的。</li><li>第二次传输，需要从内核缓冲区里面的数据，复制到我们应用分配的内存里面。<br> 这个传输是通过 CPU 搬运的。</li><li>第三次传输，要从我们应用的内存里面，再写到操作系统的 Socket 的缓冲区里面去。<br> 这个传输，还是由 CPU 搬运的。</li><li>最后一次传输，需要再从 Socket 的缓冲区里面，写到网卡的缓冲区里面去。<br> 这个传输又是通过 DMA 搬运的。</li></ol><blockquote><p>绿色：内核空间，粉色：用户空间</p></blockquote><h3 id="_1-原先的流程" tabindex="-1"><a class="header-anchor" href="#_1-原先的流程" aria-hidden="true">#</a> 1 原先的流程</h3><img src="`+m+`" alt="img" style="zoom:25%;"><p>这个时候，你可以回过头看看这个过程。我们只是要“搬运”一份数据，结果却整整搬运了四次。而且这里面，<strong><mark>2</mark> 从内核的读缓冲区传输到应用的内存里，<mark>3</mark> 再从应用的内存里传输到 Socket 的缓冲区里</strong>，其实都是把同一份数据在内存里面搬运来搬运去，特别没有效率。</p><p>像 Kafka 这样的应用场景，其实大部分最终利用到的硬件资源，其实又都是在干这个搬运数据的事儿。所以，我们就需要尽可能地减少数据搬运的需求。</p><p>事实上，Kafka 做的事情就是，把这个数据搬运的次数，从上面的四次，变成了两次，并且只有 DMA 来进行数据搬运，而不需要 CPU。</p><div class="language-java line-numbers-mode" data-ext="java"><pre class="language-java"><code><span class="token annotation punctuation">@Override</span>
<span class="token keyword">public</span> <span class="token keyword">long</span> <span class="token function">transferFrom</span><span class="token punctuation">(</span><span class="token class-name">FileChannel</span> fileChannel<span class="token punctuation">,</span> <span class="token keyword">long</span> position<span class="token punctuation">,</span> <span class="token keyword">long</span> count<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span> <span class="token punctuation">{</span>
    <span class="token keyword">return</span> fileChannel<span class="token punctuation">.</span><span class="token function">transferTo</span><span class="token punctuation">(</span>position<span class="token punctuation">,</span> count<span class="token punctuation">,</span> socketChannel<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>如果你层层追踪 Kafka 的代码，你会发现，最终它调用了 <em>Java NIO 库里的 transferTo 方法</em></p><p>Kafka 的代码调用了 Java NIO 库，具体是 <em>FileChannel 里面的 transferTo 方法</em>。我们的数据并没有读到中间的应用内存里面，而是直接通过 Channel，写入到对应的网络设备里。并且，对于 Socket 的操作，也不是写入到 Socket 的 Buffer 里面，而是直接根据<mark>描述符</mark>（Descriptor）直接写入到<mark>网卡的缓冲区</mark>里面。于是，在这个过程之中，<strong>我们只进行了两次数据传输</strong>。</p><h3 id="_2-现在的流程" tabindex="-1"><a class="header-anchor" href="#_2-现在的流程" aria-hidden="true">#</a> 2 现在的流程</h3><img src="`+d+'" alt="img" style="zoom:25%;"><ol><li>第一次，是通过 DMA，从硬盘直接读到操作系统内核的读缓冲区里面。</li><li>第二次，则是根据 Socket 的描述符信息，直接从读缓冲区里面，写入到网卡的缓冲区里面。</li></ol><p>这样，我们同一份数据传输的次数从四次变成了两次，<em>并且没有通过 CPU 来进行数据搬运，所有的数据都是通过 <mark>DMA</mark> 来进行传输的</em>。</p><h3 id="_3-零拷贝" tabindex="-1"><a class="header-anchor" href="#_3-零拷贝" aria-hidden="true">#</a> 3 零拷贝</h3><p>在这个方法里面，我们没有在内存层面去“复制（Copy）”数据，所以这个方法，也被称之为<strong>零拷贝</strong>（Zero-Copy）。</p>',55),h={href:"https://developer.ibm.com/articles/j-zerocopy/",target:"_blank",rel:"noopener noreferrer"},f=a("em",null,"使用了零拷贝能够缩短 65% 的时间，大幅度提升了机器传输数据的吞吐量",-1),C=o('<h2 id="总结延伸" tabindex="-1"><a class="header-anchor" href="#总结延伸" aria-hidden="true">#</a> 总结延伸</h2><p>讲到这里，相信你对 DMA 的原理、作用和效果都有所理解了。那么，我们一起来回顾总结一下。</p><p>如果我们始终让 CPU 来进行各种数据传输工作，会特别浪费。</p><ol><li>一方面，我们的<mark>数据传输工作</mark>用不到多少 CPU 核心的“计算”功能。</li><li>另一方面，<mark>CPU 的运转速度</mark>也比 <mark>I/O 操作</mark>要快很多。</li></ol><p>所以，我们希望能够给 CPU“减负”。</p><p>于是，工程师们就在主板上放上了 <mark>DMAC</mark> 这样<mark>一个协处理器芯片</mark>。通过这个芯片，<em>CPU 只需要告诉 DMAC，我们要<code>传输什么数据，从哪里来，到哪里去</code>，就可以放心离开了</em>。后续的实际数据传输工作，都会由 DMAC 来完成。随着现代计算机各种外设硬件越来越多，光一个通用的 DMAC 芯片不够了，<em>我们在各个外设上都加上了 DMAC 芯片</em>，使得 CPU 很少再需要关心数据传输的工作了。</p><p><strong>在我们实际的系统开发过程中，<em>利用好 DMA 的数据传输机制</em>，也可以大幅提升 I/O 的吞吐率</strong>。最典型的例子就是 Kafka。</p><p>传统地从硬盘读取数据，然后再通过网卡向外发送，我们需要进行<code>四次数据传输</code>，</p><ol><li>其中有两次是发生在内存里的缓冲区和对应的硬件设备之间，我们没法节省掉。</li><li>但是还有两次，完全是通过 CPU 在内存里面进行数据复制。</li></ol><p>在 <code>Kafka</code> 里，通过 <em>Java 的 NIO 里面 FileChannel 的 transferTo 方法</em>调用，<strong>我们可以不用把数据复制到我们应用程序的内存里面。<em>通过 DMA 的方式</em>，我们可以<em>把数据从<code>内存缓冲区</code>直接写到<code>网卡的缓冲区</code>里面</em></strong>。在使用了这样的零拷贝的方法之后呢，我们传输同样数据的时间，可以缩减为原来的 1/3，相当于提升了 3 倍的吞吐率。</p><p>这也是为什么，Kafka 是目前实时数据传输管道的标准解决方案。</p><h2 id="推荐阅读" tabindex="-1"><a class="header-anchor" href="#推荐阅读" aria-hidden="true">#</a> 推荐阅读</h2>',12),g={href:"http://notes.stephenholiday.com/Kafka.pdf",target:"_blank",rel:"noopener noreferrer"},D=a("p",null,"如果你想要进一步去了解 Kafka，也可以订阅极客时间的专栏“Kafka 核心技术与实战”。",-1),M=a("h2",{id:"课后思考",tabindex:"-1"},[a("a",{class:"header-anchor",href:"#课后思考","aria-hidden":"true"},"#"),e(" 课后思考")],-1),A=a("p",null,"你可以自己尝试写一段使用零拷贝和不使用零拷贝传输数据的代码，然后看一看两者之间的性能差异。你可以看看，零拷贝能够带来多少吞吐量提升。",-1),b=a("p",null,"欢迎你把你运行程序的结果写在留言区，和大家一起讨论、分享。你也可以把这个问题分享给你的朋友，一起试一试，看看 DMA 和零拷贝，是否真的可以大幅度提升性能。",-1),_=o("<p>DMAC：我们不加工数据，只是数据的搬运工</p><p>如果我们的应用程序需要对数据做进一步的加工，那还能使用零拷贝吗<br> 作者回复: 那就不能了，我们需要把数据复制到内存里面来，在用户态用程序进行处理。</p><p>看到最后，也没看出kafka快跟dma有关系，倒是跟zero-copy关系大一些，通过砍掉两次内核空间和用户空间的数据拷贝，以及内核态和用户态的切换成本来优化<br> 作者回复: 这样说也对，不过砍完之后数据传输其实都是DMA的过程了。</p><p>其实底层还是调用了linux的系统调用sendfile这个函数来实现零拷贝</p><p>以前只知道kafka通过零拷贝技术提高了吞吐量，但不知道为什么？这下老师通过硬件知识体系理解了相关技术原理，简直太棒了</p><p>将内核态内存映射到用户态，就实现了数据在两态间切换的零拷贝。</p><p>我记得 Nginx 的静态服务器貌似也是零拷贝。市面上常见的web服务器的静态服务器应该都实现了零拷贝吧？<br> 作者回复: 你好，我不是一个Web服务器的专家，所以其他Web服务器我不太清楚。不过Nginx的确是可以通过配置sendfile的开关on/off来控制是不是zero copy的</p><p>超算里面核与核之间的数据拷贝，一般会通过基于IB总线的RDMA来完成，可以避免过cpu内核的开销，希望徐老师能讲一下rDMA<br> 作者回复: coder同学，你好，超算里面的rDMA我还真没有了解过。等我抽空先自己学习一下。</p><p>传统的 sendfile 经历的过程：硬盘 -》kernel buffer -》socket buffer -》 NIC<br> 只有网卡支持 scatter-gather 才是文中所描述的过程：硬盘 -》kernel buffer -》NIC<br> 而且 Linux kernel 2.6.33 版本之后引入了新的系统调用 splice，一种软件实现的零拷贝技术</p><p>如果用mmap内存映射到文件，也可以实现领拷贝，这种方式会使用到DMAC吗？<br> 其他用户：mmap还是会经历 DMA 把数据传输到 kernel buffer，然后 kernel buffer 和应用共享这个 buffer，然后再 send，也会涉及 DMA</p><p>1、CPU是硬件，操作系统是软件。内存也是硬件，数据都是加载到内存里面的。<br> 2、“操作系统内核中的数据”存放在哪里？也是存放在内存里呀。<br> 3、DMAC也是一个硬件，我们这里写的过程，就是直接从硬盘读数据到内存呀。</p><p>看了老师这么多篇文章，印象最深的还是化繁为简的水平，一下点破了问题的核心。比如kafka数据传递效率如此高的原因是调用的是sendfile。当业务量到了一个量级，需要进行各种优化和改进，这个过程很难得，但也是能让人成长最快的地方。</p>",12),P=a("br",null,null,-1),U={href:"https://zhuanlan.zhihu.com/p/357820303",target:"_blank",rel:"noopener noreferrer"},v=a("p",null,"明白了，所以kafka的堆内存要设小",-1),I=a("p",null,"Kafka除了通过JavaNIO的transferTo利用sendfile零拷贝技术（涉及DMA）,在Broker中数据落盘时候还通过Java的MappedByteBuffer实践了另外一种零拷贝技术--Memory Mapped File,加快数据的写入。",-1);function O(x,y){const n=t("ExternalLinkIcon");return p(),l("div",null,[u,a("p",null,[e("IBM Developer Works 里面有一篇文章，专门写过程序来测试过，在同样的硬件下，使用零拷贝能够带来的性能提升。我在这里放上"),a("a",h,[e("这篇文章链接"),s(n)]),e("。在这篇文章最后，你可以看到，无论传输数据量的大小，传输同样的数据，"),f,e("。想要深入了解零拷贝，建议你可以仔细读一读这篇文章。")]),C,a("p",null,[e("学完了这一讲之后，我推荐你阅读一下 Kafka 的论文，"),a("a",g,[e("Kakfa:a Distrubted Messaging System for Log Processing"),s(n)]),e("。Kafka 的论文其实非常简单易懂，是一个很好的让你了解系统、日志、分布式系统的入门材料。")]),D,M,A,b,a("blockquote",null,[_,a("p",null,[e("这章结合这篇文章看，更美味"),P,a("a",U,[e("https://zhuanlan.zhihu.com/p/357820303"),s(n)])]),v,I])])}const z=r(k,[["render",O],["__file","G48-DMA启发Kafka.html.vue"]]);export{z as default};
