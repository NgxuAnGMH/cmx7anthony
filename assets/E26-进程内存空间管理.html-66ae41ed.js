import{_ as e}from"./plugin-vue_export-helper-c27b6911.js";import{o,c as a,d as c}from"./app-cdabc73c.js";const d="/assets/95352d3362a6569133153c1ace5b1833-b21d547a.jpg",s="/assets/f5626dd486fed604c418d8a3a1554164-198b5929.png",r="/assets/7b63dce096e20e31731c354dc6d2e70e-f6ec13e7.jpg",n="/assets/e5c86f61aefdfb4121034c0060ab921b-b082211b.jpg",t="/assets/bb2903b5463fbb211e7390ee48817432-54682859.jpg",i={},l=c(`<h1 id="_26-进程是如何使用操作系统内存的" tabindex="-1"><a class="header-anchor" href="#_26-进程是如何使用操作系统内存的" aria-hidden="true">#</a> 26｜进程是如何使用操作系统内存的？</h1><p>你好，我是于航。</p><p>对于计算机软件的正常运作，内存（Main Memory）所发挥作用的重要性不言而喻。无论是处在“幕后”的操作系统，还是位于“台前”的用户应用程序，它们在运行时都会将所需数据从磁盘等外部存储器转移至内存。实际上，<code>内存</code>和 <code>CPU 芯片上的 L1、L2 等高速缓存</code>，一同构成了计算机中用于支撑程序高效运行的<mark>缓存系统</mark>。</p><p>今天，我们会先从整体的视角看看内存在计算机系统中的作用，然后再一起探究进程是如何在操作系统的控制下与计算机内存交互的。</p><h2 id="计算机内部的缓存系统" tabindex="-1"><a class="header-anchor" href="#计算机内部的缓存系统" aria-hidden="true">#</a> <strong>计算机内部的缓存系统</strong></h2><p>通常，文件会被存放在容量较大的磁盘中。但磁盘作为一种提供数据持久化存储的设备，采用了机械式的数据寻址方式，这就使得它<strong>无法匹配 CPU 在完成相关操作时，所需数据在访问速度上的要求</strong>。而<code>内存</code>则以快于磁盘<code>几万甚至十几万倍</code>的读写效率，承担起了<code>与 CPU 直接交互</code>的重任。</p><p>但随着摩尔定律的不断应验，CPU 与内存两者在数据访问效率的“供需关系”上又出现了问题。因此，现代计算机通过在这两者之间引入更多读写速度更快，容量却更小的高速缓存层，并基于局部性原理，让 CPU 经常使用到的数据可以被更快地再次访问。通过这种方式，<strong>由 L1、L2 等片上高速缓存，以及内存组成的<code>缓存系统</code>，便成为了计算机中用于<code>承载 应用运行时 数据</code>的主要部件</strong>。</p><blockquote><p>网上有一个十分形象的例子，描述了内存在整个计算机系统中的“地位”：假设你作为负责人，每天都在一间专属办公室里处理各种事务。办公室内有一个硕大的档案柜，里面存放着你有权限接触的所有办公材料。当每一次需要处理某个具体事务时，你都会首先将需要的相关材料一次性地从档案柜中全部拣选出来，并将它们陈列在书桌上，然后再继续进行处理。而随着时间的推移，那些经常被翻阅的、相关性较强的材料会被摆放在距离你手边较近的位置，而相关性较弱的材料则会被放在较远的位置。</p></blockquote><p>将这个例子类比到计算机，你会发现两者之间有着类似的行为模式。每一个程序的机器代码（事务）在可以被 CPU（负责人）正常执行前，操作系统都需要先将它们从磁盘（档案柜）“搬移”到内存（书桌）中。而随着程序的不断运行，那些被经常访问的数据便会被存放到较高级别的缓存（较近位置）中。相反，不常用的数据则会被存放在较低级别的缓存（较远位置），甚至驻留在内存中。</p><h2 id="虚拟内存机制-mmu-必须分页" tabindex="-1"><a class="header-anchor" href="#虚拟内存机制-mmu-必须分页" aria-hidden="true">#</a> <strong>虚拟内存机制/MMU/必须分页</strong></h2><p>但是，对计算机而言，程序与内存之间的交互细节远比“办公室日常”要复杂得多。现代操作系统会同时执行十几个甚至几十个程序。因此，如何从有限的内存中合理地为它们分配所需资源，并同时兼顾安全性、高效性，便成为需要考虑的首要问题。</p><p>现代计算机通过名为“<code>虚拟内存</code>”的机制，做到了这一点。下面，我们来进一步看看这个机制的具体工作原理。</p><p>顾名思义，<code>虚拟内存（Virtual Memroy）</code>对应于<code>物理内存（Physical Memory）</code>。其中，前者是由操作系统抽象出来的一个概念，它在后者的基础之上进行了一层抽象，以帮助运行于其上的应用程序合理地分配内存，并管理内存使用。</p><p>因此，如下面的代码所示，我们<code>在应用程序中</code>打印出的各种指针值，它们实际上都对应于<code>虚拟内存中的某个地址</code>，而非实际的物理内存地址（Physical Address，PA）。这些地址被称为“虚拟地址（Virtual Address，VA）”。<code>所有程序</code>可以使用的虚拟地址则构成了<code>虚拟地址空间（VAS）</code>。</p><div class="language-c line-numbers-mode" data-ext="c"><pre class="language-c"><code><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;stdio.h&gt;</span></span>
<span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token keyword">int</span> x <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span>
  <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">&quot;%p&quot;</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>x<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 0x7fff32cf54fc.</span>
  <span class="token function">getchar</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>CPU 在访问内存中的数据时，会借助其芯片上<mark>名为“<strong>内存管理单元</strong>（MMU）”的硬件</mark>，首先将<code>虚拟地址</code>动态翻译为<code>对应的物理地址</code>，然后再进行实际的数据获取。你可以通过下图来直观地理解这个过程。</p><img src="`+d+`" alt="img" style="zoom:25%;"><p><mark>虚拟内存机制</mark>的一个最重要特征，就是<strong>为<code>每一个应用程序进程</code>都抽象出了<code>独立于</code>物理内存的虚拟地址空间</strong>。</p><blockquote><p>这意味着，从<code>进程</code>的角度来看，它可以<code>独享整个计算机上的所有内存(VAS)</code>。</p><p>现代操作系统通常采用 32 或 64 位地址空间，两者分别拥有 2<sup>32</sup> 与 2<sup>64</sup> 个地址。</p></blockquote><p>通过这种方式，编译器在构建应用时，便不需要考虑各二进制数据段应该被实际加载到内存中的何处，<code>所有应用均可使用统一的静态文件结构</code>。</p><p>比如，在 64 位 Linux 系统中，<code>与应用代码相关的 Segment</code> 会从 VAS 的<code>固定地址 0x400000 处</code>开始加载。而<code>其他 Section 内容</code>将在满足一定对齐要求的情况下，按顺序被连续加载到<code>高地址方向的虚拟内存</code>中。</p><blockquote><p>这样，无论是程序在二进制文件内的静态视图，还是被加载到 VAS 后的运行时视图，它们都可以在虚拟内存的隔离下，在表现层有着稳定一致的布局。</p></blockquote><h2 id="查看运行进程的-vas-布局" tabindex="-1"><a class="header-anchor" href="#查看运行进程的-vas-布局" aria-hidden="true">#</a> 查看运行进程的 VAS 布局</h2><p>而通过下面这行命令，我们便可以<code>查看某个运行进程的 VAS 布局情况</code>。注意，其中的 “” 需要被替换为进程对应的 ID。</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">cat</span> /proc/<span class="token operator">&lt;</span>pid<span class="token operator">&gt;</span>/maps
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>这里，我们尝试将本小节开头处的那个 C 程序的 ID 替换到上述命令中。在运行该命令后，可以得到如下图所示的输出结果。</p><p>这里，命令按照地址由低到高的顺序打印出了进程 VAS 内，每一块已经被占用的连续虚拟内存地址，对应的映射信息。如最右侧一列所示，这些内存中的内容或是来自于某个具体文件（/www/workspace/main），或被用作其他用途（[heap]）。</p><img src="`+s+'" alt="img" style="zoom:50%;"><h2 id="vas-中的数据布局-虚拟地址" tabindex="-1"><a class="header-anchor" href="#vas-中的数据布局-虚拟地址" aria-hidden="true">#</a> <strong>VAS 中的数据布局（虚拟地址）</strong></h2><p>将上图中的信息进行归类，我们可以得到如下图所示的 <code>Linux 进程</code>在 <mark>VAS</mark> 内的<code>统一数据布局结构</code>。这里我根据类别，将不同的数据用不同的颜色进行了标注。并且，为了方便你找到这两个图之间的内存段对应关系，我将上图中的一些关键性地址信息也选择性地标注在了下图中。</p><img src="'+r+'" alt="img" style="zoom:25%;"><p>总的来看，Linux 进程 VAS 中的数据，按照地址由低到高的顺序，可以被分为下面这几个主要部分。</p><h3 id="【最低】1-load-segments-代码段数据段" tabindex="-1"><a class="header-anchor" href="#【最低】1-load-segments-代码段数据段" aria-hidden="true">#</a> 【最低】1. LOAD Segments (代码段数据段)</h3><blockquote><p>就是所谓的代码段和数据段, 来自二进制可执行文件, 例如 ELF.</p><ul><li>最初始就装载进来, 即程序的最初始状态</li></ul></blockquote><p><strong><mark>LOAD Segments</mark></strong>：这部分数据被加载到<code>从地址 0x400000 开始</code>的虚拟内存中。其主要内容为应用程序 ELF 二进制文件内定义的各种 LOAD Segment 结构。</p><ul><li>按照顺序，与代码相关的 Text Segment（包含 .text、.rodata 等多个 Section）位于最低地址处，<br> RE 可读可执行：<code>.text(程序机器代码)</code> 和 <code>.rodata(只读常量)</code><br> 【<mark>线程私有</mark>，只读只执行，强调执行】</li><li>紧接着为包含有已初始化和未初始化数据的 Data Segment（包含 .data，.bss 等多个 Section）。<br> RW 可读可写：【<code>全局/静态</code>】<code>.data(已经初始化的)</code> 和 <code>.bss(初始值为0)</code><br> 【<mark>线程共享</mark>，强调可以写，有需要就写】</li></ul><blockquote><p>当执行一个程序的时候，会加载ELF格式可执行文件，加载的时候会设置指令指针。</p><ul><li><code>多线程共享同一个进程内存空间(VAS)</code>，所以==<strong>代码段的起始地址</strong>==还是一样的。</li><li>只不过每个线程执行不同的func，==指令指针寄存器(<strong>代码段的偏移量</strong>)==会不一样，在内核中，<code>线程也是有独立的task_struct</code></li></ul></blockquote><h3 id="_2-【线程共享都相同】堆-heap-向高" tabindex="-1"><a class="header-anchor" href="#_2-【线程共享都相同】堆-heap-向高" aria-hidden="true">#</a> 2. 【线程共享都相同】堆（Heap）向高</h3><p><strong><mark>堆（Heap）</mark></strong>：关于堆内存，我已经在 08 讲 中介绍过。<code>随着动态数据的不断产生</code>，它将向 VAS 的**<code>高地址方向</code>**不断增长。</p><blockquote><ul><li>随着程序运行 动态地扩展和收缩, 存储在 [堆] = 堆区 <ul><li>malloc() = 其实都是在堆区中分配的内存</li><li>保存较长时间, 指明才销毁.</li></ul></li></ul></blockquote><h3 id="_3-共享库数据-内存映射区" tabindex="-1"><a class="header-anchor" href="#_3-共享库数据-内存映射区" aria-hidden="true">#</a> 3. 共享库数据(/内存映射区)</h3><p><strong><mark>共享库数据</mark></strong>：这部分内存中包含有<code>与各类 .so 共享库相关的 数据</code>，程序会<code>在运行时</code>通过<mark>动态链接器</mark>来完成对它们的加载和处理。我会在第 29 讲再为你详细介绍。</p><blockquote><ul><li>相互整合: <code>动态链接</code>/静态链接</li></ul></blockquote><p><mark><strong><code>内存映射区</code></strong></mark>：直接建立物理存储的映射，可以显著提高文件的读取效率！</p><h3 id="_4-【线程私有不相同】栈-stack-向低" tabindex="-1"><a class="header-anchor" href="#_4-【线程私有不相同】栈-stack-向低" aria-hidden="true">#</a> 4. 【线程私有不相同】栈（Stack）向低</h3><p><strong><mark>栈（Stack）</mark></strong>：关于栈内存，我已经在 05 讲 中介绍过。<code>随着各种局部变量的不断产生</code>，它将向 VAS 的**<code>低地址方向</code>**不断增长。</p><blockquote><ul><li>随着程序运行 动态地扩展和收缩, 存储在 [栈] = 用户栈 = 运行栈区 = 线程栈 <ul><li>方法调用() = 本质就是压栈</li><li>函数方法的局部变量, 保存较短时间, 进入另一个函数方法, 自动销毁.</li></ul></li></ul></blockquote><h3 id="_5-用于系统调用加速的内核数据" tabindex="-1"><a class="header-anchor" href="#_5-用于系统调用加速的内核数据" aria-hidden="true">#</a> 5. 用于系统调用加速的内核数据</h3><p><strong><mark>用于系统调用加速的内核数据</mark></strong>：接下来的三个虚拟内存区域 <code>[vvar]、[vdso]，以及 [vsyscall]</code> 中包含有<mark>操作系统内核</mark>的**<code>代码</code><strong>和</strong><code>数据结构</code>**，它们主要提供了用户进程<code>可以直接与内核进行交互的</code><mark><strong>接口</strong></mark>。</p><ul><li>其中，[vvar] 中包含有<code>只读的内核数据</code>。</li><li>而另外的 [vdso] 与 [vsyscall] 则包含有用于<code>辅助操作系统，加速用户进程</code>执行某些系统调用过程的信息。</li></ul><h3 id="【最高】6-其他内核数据" tabindex="-1"><a class="header-anchor" href="#【最高】6-其他内核数据" aria-hidden="true">#</a> 【最高】6. 其他内核数据</h3><p><strong><mark>其他内核数据</mark></strong>：除此之外，在进程 VAS 的高地址处，还可能包含有<code>与当前进程相关的</code><mark><strong>各种数据结构</strong></mark>。</p><p>甚至，该区域内的某段虚拟内存页还会被直接映射到某段<code>被所有进程共享的</code>物理内存页上（比如用于 MMIO）。</p><blockquote><p>内核: 其实就是所有程序共享的内存, 即所有进程VAS中, 统一固定相同的位置.</p></blockquote><h2 id="vas-mmu-页-页表-虚拟页" tabindex="-1"><a class="header-anchor" href="#vas-mmu-页-页表-虚拟页" aria-hidden="true">#</a> +++++++&lt; VAS/MMU/页/页表/虚拟页</h2><p>VAS是完整私有，进程之间独立的虚拟空间。</p><ul><li>这是个更强调更接近内存的概念！</li></ul><p>MMU是CPU对VAS中各部分进行 [虚拟-&gt;物理] 地址翻译的元件。</p><ul><li>CPU执行多任务，多进程，涉及多个独立的VAS。</li><li>虚拟中连续 / 物理中可离散 / 关系分离</li></ul><p>“页”是大小单位，外存与内存之间传递数据，通常以“页”的方式。</p><ul><li>内存中的数据，是多个进程并发运行时，调度算法决定的常驻数据，即常驻内存的“页”有哪些。</li></ul><p>“页表”是每个进程私有的，描述了整个虚拟的VAS。</p><ul><li>“页表项”是对“页表”的划分。是在 [VAS对各部分的划分] 的基础上，继续对内容以“页”来划分，即“虚拟页”。</li><li>“页表”和“页表项”，主要还是关注“虚拟空间”和“虚拟页”，通过众多字段进行描述： <ul><li>(1)页表项的“有效位” <ul><li><code>A</code> 虚拟页已缓存在内存中</li><li>虚拟页未缓存/不在内存中 <ul><li><code>B</code> 缓存过/已初始化/已分配/有运行过的内容/只是调度算法没命中/非空闲页</li><li><code>C</code> 从未缓存过/压根还未分配/未进行初始化/没有内容运行过/空闲页</li></ul></li></ul></li><li>(2)页表项的“地址位” <ul><li><code>A</code> 起始位置/可直接访问</li><li><code>B</code> 起始位置/访问时产生&quot;缺页中断&quot; <ul><li>重新加载 &lt;-&gt; 换掉(VAS虚拟页中旧的内容)以更新可能的改动</li></ul></li><li><code>C</code> 为空/访问时产生&quot;缺页中断&quot; <ul><li>初始化加载 &lt;-&gt; 就是直接拷贝</li></ul></li></ul></li><li>(3)页表项的&quot;访问控制&quot; <ul><li>可读、可写、可执行。（内核则是/不可读/不可写/不可执行）</li><li>在程序尝试非法访问某块内存数据时<code>做出异常响应</code></li></ul></li></ul></li></ul><p>&quot;页表&quot;体积还是太大了，内存空间非常宝贵，因此采用“多级页表”按树形展开。在内存中仅存储“一级页表”这样就压缩了体积，不过与此同时逐级查询又增加了时间开销。因此在CPU的内存管理单元MMU中，增加了一个TLB硬件设备，作为缓冲器，加速 [虚拟-&gt;物理] 的地址翻译。</p><h2 id="使用页表维护虚拟页状态" tabindex="-1"><a class="header-anchor" href="#使用页表维护虚拟页状态" aria-hidden="true">#</a> <strong>使用页表维护虚拟页状态</strong></h2><p>可以看到，得益于虚拟内存机制的抽象，进程可以使用完全统一、独立的内存数据布局，<code>而不用考虑这些数据在真实物理内存中的具体存储细节</code>。那么，虚拟内存机制究竟是<code>如何对物理内存进行管理的呢</code>？接下来我们具体看看。</p><p>为了保证效率，操作系统通常会以==“页”<mark>为单位，来在磁盘与内存之间传递数据。而实际上，它也正是通过为<code>每一个进程</code>提供独立的</mark>“页表”==结构，来维护 VAS 中的虚拟页在对应物理内存中的映射状态的。</p><ul><li><code>页表本身被维护在物理内存中</code>，其内部由众多的==“页表项（Page Table Entry，PTE）”==组成。</li><li><code>进程 VAS 中的每个虚拟页</code>都对应于<code>页表中的某个 PTE</code>，而 PTE 中则包含有<code>用于描述该虚拟页状态的 众多字段</code>。</li><li>每一次 <mark>MMU (<strong>内存管理单元</strong>)</mark> 需要将一个虚拟地址翻译为物理地址时，它都会首先读取<mark>页表</mark>，以查询相关的 <mark>PTE 页表项</mark> 信息。</li><li>然后，再根据虚拟地址内<code>隐含的偏移信息</code>，找到对应页中的目标位置。</li></ul><blockquote><p><mark>每个进程</mark> 都有独立的 <mark>VAS 虚拟地址空间</mark>。</p><p><mark>每个进程</mark> 都有对应的一张 <mark>页表</mark>，负责维护该进程中 <code>VAS 虚拟地址空间</code> 与 <code>物理地址</code> 之间的映射关系。</p><p>运行时 <mark>CPU</mark> 通过 <mark>MMU</mark> 进行内存方面的操作，又通常是以<mark>页</mark>作为基础单位。</p><p>VAS 虚拟地址空间 + 以页作为基础单位 = <mark>虚拟页</mark>，又一一对应 <code>页表</code> 中的 <mark>页表项</mark>。</p></blockquote><h2 id="pte-页表项的字段信息" tabindex="-1"><a class="header-anchor" href="#pte-页表项的字段信息" aria-hidden="true">#</a> PTE 页表项的字段信息</h2><p>在简化的实现中，PTE 可能由<code>一个“有效位”字段</code>与<code>一个“地址”字段</code>组成。</p><h3 id="有效位" tabindex="-1"><a class="header-anchor" href="#有效位" aria-hidden="true">#</a> ## 有效位</h3><p>其中，<code>有效位</code>用于表明该虚拟页<code>是否已被缓存在物理内存中</code>。</p><p>虚拟页与物理页，之间一一对应关系，的几种状况。</p><ol><li><p>【<code>已缓存 在内存中 能直接快速对应</code>】若该位-<code>置位</code>，则地址字段中存放有该页在物理内存中的<code>起始位置</code>。</p></li><li><p>【<code>未缓存 不在内存中 缺页异常中断</code>】而在该位-<code>复位</code>的情况下，</p><ul><li><p>【<code>未分配 未缓存 为空</code>】若地址字段为空，则表明该虚拟页还未被分配。<br> 【该虚拟页<code>从来没读过 未初始化</code>，<mark>空闲页</mark>】</p></li><li><p>【<code>已分配 却未缓存 在磁盘中</code>】否则，地址字段中便保存有虚拟页内容在磁盘上的<code>起始位置</code>。<br> 【该虚拟页<code>已经读过 已初始化，只是调出了内存</code>，<mark>非空闲页</mark>】</p></li></ul></li></ol><h3 id="地址" tabindex="-1"><a class="header-anchor" href="#地址" aria-hidden="true">#</a> ## 地址</h3><p>当 <code>CPU</code> 需要访问某个虚拟地址上的数据时，通常会发生以下两种情况：</p><ul><li>MMU 查找进程页表，发现目标数据<code>已被缓存【内存中】</code>，进而直接通过 <code>PTE 中对应的物理地址</code>获取并返回所需要的数据；</li><li>MMU 查找进程页表，发现目标数据<code>未被缓存【不在内存中】</code>，此时它会触发一个“<code>缺页异常</code>”。 <ul><li>在第二种情况中，缺页异常将会调用<mark>内核</mark>中特定的<code>异常处理程序</code>，<br> 该程序会在<mark>物理内存</mark>中选择一个页，以用来承载当前虚拟地址所对应的物理数据。 <ul><li>其中，对于<code>空闲页</code>，【未初始化的虚拟页】<br> 内核会直接将虚拟页(VAS)对应的内容从磁盘拷贝到该物理页中；【初始化操作】</li><li>而对于<code>非空闲页</code>，【已初始化的虚拟页，但掉出了内存，还可能存在改动】<br> 若该页已经被修改，则内核会首先将它的内容换出，即更新到磁盘。然后，再将磁盘上的内容拷贝至这块物理页中。</li></ul></li></ul></li></ul><h2 id="cpu-mmu-页表-物理内存-磁盘" tabindex="-1"><a class="header-anchor" href="#cpu-mmu-页表-物理内存-磁盘" aria-hidden="true">#</a> CPU-MMU-页表-物理内存-磁盘</h2><p>这里你可以先暂缓脚步，通过下图来直观地理解 CPU、MMU、页表、物理内存，以及磁盘五者之间的协作关系。</p><p><mark>页表</mark>隔离了<mark>进程的 VAS</mark> 与<mark>物理内存</mark>，使得两者之间的映射关系变得更加自由。而在这种方式下，当不同进程使用<code>不同页表</code>维护其各自 <code>VAS 中虚拟页的映射</code>时，<code>多个进程之间</code>便可做到真正的<code>数据共享</code>。而我将在 29 讲中介绍的“<code>动态链接</code>”技术便以此为基础。不仅如此，<code>独立的 VAS 与页表</code>也使得进程之间的<code>私有内存</code>不会被相互访问。</p><p>另外，通过在 <mark>PTE</mark> 中增加用于<code>访问控制</code>的相关字段（如<code>可读、可写、可执行</code>），<mark>CPU</mark> 可以在程序尝试非法访问某块内存数据时<code>做出异常响应</code>。</p><img src="'+n+'" alt="img" style="zoom:25%;"><h2 id="使用多级页表压缩页表体积" tabindex="-1"><a class="header-anchor" href="#使用多级页表压缩页表体积" aria-hidden="true">#</a> <strong>使用多级页表压缩页表体积</strong></h2><blockquote><p>不压缩的话，页表所需要的存储就太大了。</p></blockquote><p>但是，上面介绍的一级页表有时却可能无法满足需求。试想，以目前常用的 64 位地址空间为例，假设页大小为已知最大的 2MiB，为保证完整映射，每个 PTE 大小为 8 字节。而为了能够在单一页表内维护进程整个 64 位 VAS 中所有虚拟页的信息，那么便需要为其匹配一个大小为 65535 GiB 的页表，而这显然是不现实的。因此，现代计算机通常会采用“<code>多级页表</code>”的方式，来优化页表的大小。</p><p>多级页表的思路很简单。以二级页表为例，假设在一个 32 位地址空间中，页大小为 4KiB，每个 PTE 大小为 4 字节。此时，MMU 在进行物理地址查询时，首先会根据虚拟地址中隐含的虚拟页号信息来查找一级页表内的目标 PTE，而一级页表中的每个 PTE，此时实际上负责映射 VAS 中的一个 4MiB 的片。</p><p><code>按照树的形式展开</code>，每个一级页表也都对应着一个独立的二级页表，二级页表中的每一个 PTE 则负责映射当前一级页表的 4MiB 的片中的某个 4KiB 的块。当一级页表查询完毕后，MMU 便可得到指向目标二级页表的地址。通过该地址，再联合虚拟地址中的另一部分虚拟页号信息，它便可找到目标数据所在物理内存的具体页。最后，结合虚拟地址中的页偏移信息，目标数据的最终物理地址便可被成功地“转换”出来。你可以通过下图来进一步理解上述流程：</p><img src="'+t+'" alt="img" style="zoom:25%;"><p>多级页表可以<code>节省内存空间</code>的两个最重要因素是：</p><ul><li>当一级页表中的某个 PTE 没有实际映射时，<code>其对应的二级页表便不会被创建</code>；【不再需要 腾出空间却维护一张空表】</li><li><code>只有一级页表才需要常驻内存</code>，二级页表可以仅在需要时再创建，或从磁盘调入。【不再需要 所有的映射都放到内存】</li></ul><p>实际上，上述二级页表的使用形式可以被推广到<code>任意的 N 级</code>。但总体来看，页表的级数并非越多越好，因为更多的页表级数也就意味着<code>更长的物理地址查询时间</code>。目前常见的<code>多级页表为 4 级</code>，而在 Ice Lake 等处理器中，也出现过 5 级页表。</p><blockquote><p>时间跟空间之间的平衡。</p></blockquote><h2 id="使用-tlb-加速-pte-查询" tabindex="-1"><a class="header-anchor" href="#使用-tlb-加速-pte-查询" aria-hidden="true">#</a> <strong>使用 TLB 加速 PTE 查询</strong></h2><p>多级页表虽然可以压缩页表占用的内存量，但用 MMU 进行页表的逐级查询，这个过程也并不是毫无成本的。</p><p>现实情况中，计算机通常会结合使用==名为“翻译后备缓冲器（Translation Lookaside Buffer，TLB）”的<strong>硬件设备</strong>==来加速这一流程。</p><p><mark>TLB</mark> 属于 MMU 的一部分，<code>它可以加快 MMU 根据虚拟地址查询 PTE 的过程</code>。你可以将 TLB 理解为一个简单的具有 N 行 M 列的矩阵，MMU 会从对应虚拟地址中提取出用于查询表项的 TLB 索引与 TLB 标记。这两个值可以联合起来使用，并定位到 TLB 中的一个具体单元格。而此时，若该单元格内有值，则 MMU 可以直接使用该值，来与虚拟地址中的其他信息一起组成最终的物理地址。否则，MMU 仍然需要通过逐级查询页表的方式来获取目标页的物理地址。</p><h2 id="再谈共享对象与私有对象" tabindex="-1"><a class="header-anchor" href="#再谈共享对象与私有对象" aria-hidden="true">#</a> <strong>再谈共享对象与私有对象</strong></h2><p>上面，我曾在“使用页表维护虚拟页状态”一节的最后提到，借助虚拟内存机制，<code>不同进程</code>之间可以<code>共享物理内存</code>上的同一段数据。这些数据在物理内存中实际存放时，可能并不是连续的。而借助于页表实现的“<code>虚拟页与物理页映射关系分离</code>”，我们可以确保 <code>CPU 能够按照连续的方式来使用这些数据</code>。</p><blockquote><p>虚拟中连续 / 物理中可离散 / 关系分离</p></blockquote><p>而当某个共享进程试图<code>对这些共享数据进行修改时</code>，操作系统便会通过==“写时复制（Copy-on-write）”==的方式，来将被变更数据所在的物理页进行复制，并通过修改页表，来让修改进程<code>可以私有化这部分数据</code>。</p><h2 id="总结" tabindex="-1"><a class="header-anchor" href="#总结" aria-hidden="true">#</a> <strong>总结</strong></h2><p>这一讲，我主要为你介绍了进程是如何在操作系统的控制下使用内存资源的。</p><p>在现代计算机中，内存和 CPU 芯片上的高速缓存一起构成了用于承载应用运行时数据的缓存系统。而这个缓存系统，在名为“虚拟内存”机制的帮助下，能够以一种更加优雅的方式运作。</p><p>虚拟内存机制为<code>每一个进程</code>都抽象出了<code>独立且私有的虚拟地址空间（VAS）</code>。VAS 中使用虚拟地址进行寻址，当 CPU 需要通过该地址访问内存中的某个数据时，芯片上的<code>内存管理单元（MMU）</code>会将该地址转换为对应的物理地址。不同的操作系统都会在 VAS 中为进程使用<code>相对统一的数据布局</code>方式，这样，<code>编译器</code>便可简化其构建应用的流程。</p><p>操作系统使用<code>名为“页表”的数据结构</code>来维护 VAS 中虚拟页与物理页之间的<code>映射关系</code>。通过查询<code>页表项（PTE）</code>的状态，操作系统可以直接获得目标数据所在页的物理地址，或是通过触发<code>缺页异常中断</code>，来让操作系统内核将目标数据从磁盘加载到物理内存中，然后再重新获取该地址。在这个过程中，内核可能会将物理内存中，某个已修改的非空闲页的内容换出到磁盘。</p><p>为了减小分配给每个进程的页表大小，现代计算机通常采用<code>多级页表</code>的方式来管理虚拟页与物理页的映射关系。而在这种方式下，由于需要查询的表项过多，计算机还会采用<code>名为 TLB 的硬件设备</code>，来缓存之前的表项查询结果，并加速下一次相同虚拟页的查询过程。</p><p>最后，虚拟内存机制使得多个进程<code>可以同时共享</code>物理内存中的某段数据，<code>而无需</code>将数据拷贝多份。但当某个进程试图修改这些共享数据时，操作系统会通过“<code>写时复制</code>”的方式来将被修改数据进行拷贝，并使其对修改进程<code>私有化</code>。</p><h2 id="思考题" tabindex="-1"><a class="header-anchor" href="#思考题" aria-hidden="true">#</a> <strong>思考题</strong></h2><p>试着查阅资料来了解一下，==为什么 Linux 进程 VAS 从地址 0x0 开始，直到 0x400000 的低地址段，没有存放任何数据？==欢迎在评论区告诉我你的发现。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p><h2 id="课后讨论" tabindex="-1"><a class="header-anchor" href="#课后讨论" aria-hidden="true">#</a> 课后讨论</h2><p><mark>为什么 Linux 进程 VAS 从地址 0x0 开始，直到 0x400000 的低地址段，没有存放任何数据？</mark></p><ol><li>为保证<code>空指针</code>可以触发访问缺失页的异常SIGSEGV，空出位于虚拟地址空间的最低部分，空出的虚拟地址部分不访问，就可以省下一个页大小的空间，原本空出的空间为4KB(0x0-0x1000)即可，考虑到大页机制时最小页为4MB，因此就空出4MB的空间(0x0-0x00400000),所以VAS的真实使用地址从0x400000开始。</li><li>位于虚拟地址空间的最低部分，未赋予物理地址。任何对它的引用都是非法的，用于捕捉使用空指针和小整型值指针引用内存的异常情况。</li></ol>',114),p=[l];function u(h,m){return o(),a("div",null,p)}const b=e(i,[["render",u],["__file","E26-进程内存空间管理.html.vue"]]);export{b as default};
